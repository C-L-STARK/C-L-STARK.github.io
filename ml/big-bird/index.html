
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="FastDoc is a website that you can get started with FastX AI in minutes.">
      
      
      
        <link rel="canonical" href="https://doc.fastx-ai.com/ml/big-bird/">
      
      
        <link rel="prev" href="../beating-gaia/">
      
      
        <link rel="next" href="../blip-2/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>深入理解 BigBird 的块稀疏注意力 - FastDocs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="深入理解 BigBird 的块稀疏注意力 - FastDocs" >
      
        <meta  property="og:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  property="og:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/big-bird.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://doc.fastx-ai.com/ml/big-bird/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="深入理解 BigBird 的块稀疏注意力 - FastDocs" >
      
        <meta  name="twitter:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  name="twitter:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/big-bird.png" >
      
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#bigbird" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
              </button>
            
            
<p style="text-align: center">
  Welcome to <span style="font-size: bold">FastDocs</span>! Just feel free to start read docs!
</p>

          </div>
          
            <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="FastDocs" class="md-header__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FastDocs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              深入理解 BigBird 的块稀疏注意力
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  主页

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../backend/" class="md-tabs__link">
        
  
    
  
  后端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../web/" class="md-tabs__link">
        
  
    
  
  前端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../client/" class="md-tabs__link">
        
  
    
  
  客户端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../pc/" class="md-tabs__link">
        
  
    
  
  桌面端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../big-data/" class="md-tabs__link">
        
  
    
  
  大数据

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_58_llm_extreme_quantization/" class="md-tabs__link">
          
  
    
  
  人工智能

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../ops/" class="md-tabs__link">
        
  
    
  
  运维

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  博客

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../resume/" class="md-tabs__link">
        
  
    
  
  简历模板

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="FastDocs" class="md-nav__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FastDocs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../backend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    后端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../web/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../client/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    客户端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    桌面端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../big-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大数据
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    人工智能
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            人工智能
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_58_llm_extreme_quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning LLMs to 1.58bit: extreme quantization made easy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2023-in-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023, 开源大模型之年
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3d-assets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手把手教你使用人工智能生成 3D 素材
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4bit-transformers-bitsandbytes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Llama2-for-non-engineers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非工程师指南：训练 LLaMA 2 聊天机器人
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Lora-for-sequence-classification-with-Roberta-Llama-Mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在灾难推文分析场景上比较用 LoRA 微调 Roberta、Llama 2 和 Mistral 的过程及表现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../_policy-ntia-rfc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能政策@🤗：回应美国国家电信和信息管理局（ NTIA ）关于人工智能问责制的评论请求
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerate-v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate 1.0.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerated-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何成功将 🤗 API 客户的 transformer 模型推理速度加快 100 倍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    授权调用：介绍 Transformers 智能体 2.0  
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aivsai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 大战 AI，一个深度强化学习多智能体竞赛系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../arena-tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS 擂台: 文本转语音模型的自由搏击场
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../asr-diarization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 推理终端搭建强大的“语音识别 + 说话人分割 + 投机解码”工作流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation-support-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    英特尔 Gaudi 加速辅助生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    辅助生成：低延迟文本生成的新方向
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audioldm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AudioLDM 2，加速⚡️！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer 模型能够有效地进行时间序列预测 (使用 Autoformer)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beating-gaia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers 代码智能体成功刷榜 GAIA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    深入理解 BigBird 的块稀疏注意力
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    深入理解 BigBird 的块稀疏注意力
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      引言
    </span>
  </a>
  
    <nav class="md-nav" aria-label="引言">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      应该关注哪些词元？
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      图解全局、滑动、随机注意力的概念
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bigbird_1" class="md-nav__link">
    <span class="md-ellipsis">
      BigBird 块稀疏注意力
    </span>
  </a>
  
    <nav class="md-nav" aria-label="BigBird 块稀疏注意力">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      全局注意力
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      滑动注意力
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      随机注意力
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      实现
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      时间和内存复杂度
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#itc-etc" class="md-nav__link">
    <span class="md-ellipsis">
      ITC 与 ETC
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transformers-bigbird" class="md-nav__link">
    <span class="md-ellipsis">
      在 🤗Transformers 中使用 BigBird
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      下一步
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      尾注
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BLIP-2 零样本“图生文”
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化故事: BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-pytorch-scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DeepSpeed 和 Accelerate 进行超快 BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-megatron-deepspeed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    千亿参数开源大模型 BLOOM 背后的技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Habana Gaudi2 加速视觉语言模型 BridgeTower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chat-templates/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天模板：无声性能杀手的终结
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-ai-expansion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中国 AI 出海现状概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-language-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中文博客正式发布！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cloudflare-workers-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为 Hugging Face 用户带来无服务器 GPU 推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codellama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Llama：Llama 2 学会写代码了！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../community-datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据好合：Argilla 和 Hugging Face Spaces 赋能社区合力构建更好的数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../constrained-beam-search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 🤗 Transformers 中使用约束波束搜索引导文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🧨 Diffusers 实现 ControlNet 高速推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cosmopedia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cosmopedia：如何为大语言模型预训练构建大规模合成数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cost-efficient-rag-applications-with-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用英特尔 Gaudi 2 和至强 CPU 构建经济高效的企业级 RAG 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cv_state/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中计算机视觉的现状
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../daily-papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 论文平台 Daily Papers 功能全解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dedup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCode 背后的大规模数据去重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep-learning-with-proteins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    蛋白质深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepspeed-to-fsdp-and-back/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 DeepSpeed 到 FSDP，再回到 Hugging Face Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-deepfloydif-using-bentoml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BentoML 部署 🤗 Hugging Face 上的模型：DeepFloyd IF 实战
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-with-openvino/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Optimum-Intel 和 OpenVINO GenAI 优化和部署模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dialog-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    是什么让对话代理有用？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffusers-turns-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Diffusers 一岁啦 !
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docmatix - 超大文档视觉问答数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../document-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加速 Document AI (文档智能) 发展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo-trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DPO 微调 Llama 2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo_vlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为视觉语言多模态模型进行偏好优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dreambooth/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Diffusers 通过 Dreambooth 技术来训练 Stable Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic_speculation_lookahead/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的辅助生成: 动态推测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../elixir-bumblebee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 GPT2 到 Stable Diffusion：Elixir 社区迎来了 Hugging Face
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用于显著提高检索速度和降低成本的二进制和标量嵌入量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encoder-decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Transformers 的编码器-解码器模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encrypted-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 FHE 实现加密大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开发 Diffusers 库的道德行为指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    道德与社会问题简报 #3: Hugging Face 上的道德开放性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ethics and Society Newsletter #4: Bias in Text-to-Image Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon-180b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 180B 登陆 Hugging Face Hub 🔥
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 登陆 Hugging Face 生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falconmamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon Mamba: 首个高效的无注意力机制 7B 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-tune-whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 为多语种语音识别任务微调 Whisper 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    揭秘 FineVideo 数据集构建的背后的秘密
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune-florence2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调 Florence-2 - 微软的尖端视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../game-jam-first-edition-results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首届开源 AI 游戏挑战赛事结果
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gaussian-splatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3D 高斯点染简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-july-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 最新发布： Gemma 2 2B, ShieldGemma 和 Gemma Scope
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 微调 Gemma 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Gemma: Google 最新推出开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 发布最新开放大语言模型 Gemma 2，现已登陆 Hugging Face Hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generative-ai-models-on-intel-cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    越小越好：Q8-Chat，在英特尔至强 CPU 上体验高效的生成式 AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started-habana/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Habana Gaudi 的 Transformers 入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../google-cloud-model-garden/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Google Cloud 上轻松部署开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptq-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 AutoGPTQ 和 transformers 让大语言模型更轻量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio 5 现已发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-lite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio-Lite: 完全在浏览器里运行的无服务器 Gradio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-reload/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Gradio 的“热重载”模式快速开发 AI 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphml-classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Transformers 进行图分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-benchmark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的训练和推理：对比 Habana Gaudi®2 和英伟达 A100 80GB
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型快速推理：在 Habana Gaudi2 上推理 BLOOMZ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hf-bitsandbytes-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模 Transformer 模型 8 比特矩阵乘简介 - 基于 Hugging Face Transformers、Accelerate 以及 bitsandbytes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../how-to-generate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何生成文本：通过 Transformers 用不同的解码方法生成文本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hugging-face-wiz-security-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 Wiz Research 合作提高人工智能安全性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../huggy-lingo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Huggy Lingo：利用机器学习改进 Hugging Face Hub 上的语言元数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IDEFICS 简介：最先进视觉语言模型的开源复现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Idefics2 简介：为社区而生的强大 8B 视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在免费版 Google Colab 上使用 🧨 diffusers 运行 IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../image-similarity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Hugging Face Datasets 和 Transformers 的图像相似性搜索
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-endpoints-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Hugging Face 推理端点部署 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 提供的推理（Inference）解决方案
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infini-attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一次失败的实验——无限注意力，我们为什么坚持实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../informer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Informer 进行多元概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../instruction-tuning-sd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 InstructPix2Pix 对 Stable Diffusion 进行指令微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-fast-embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用 🤗 Optimum Intel 和 fastRAG 在 CPU 上优化文本嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-protein-language-model-protst/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 Gaudi 2 上加速蛋白质语言模型 ProtST
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 推理 | 使用英特尔 Sapphire Rapids 加速 PyTorch Transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用英特尔 Sapphire Rapids 加速 PyTorch Transformers 模型（第一部分）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-starcoder-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Optimum Intel 在英特尔至强上加速 StarCoder：Q8/Q4 及投机解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intro-graphml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一文带你入门图机器学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introducing-csearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Transformers 中使用对比搜索生成可媲美人类水平的文本🤗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-to-ggml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ggml 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    万事通，专精部分领域的多功能 Transformer 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kv-cache-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 KV 缓存量化解锁长文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face x LangChain：全新 LangChain 合作伙伴包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../large-language-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型：新的摩尔定律？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lcm_lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LCM LoRA 4 步完成 SDXL 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-bigcodebench/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCodeBench: 继 HumanEval 之后的新一代代码生成基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-decodingtrust/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    来自 AI Secure 实验室的 LLM 安全排行榜简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-medicalllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源医疗大模型排行榜：健康领域大模型基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-patronus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    企业场景排行榜简介：现实世界用例排行榜
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 2 来袭 - 在 Hugging Face 上玩转它
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Llama 3：Meta 的新一代开源大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 3.1：405B/70B/8B 模型的多语言与长上下文能力解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    现在 Llama 具备视觉能力并可以在你的设备上运行 - 欢迎使用 Llama 3.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../long-range-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    长程 transformer 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LoRA 进行 Stable Diffusion 的高效参数微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mask2former/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用图像分割任务：使用 Mask2Former 和 OneFormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matryoshka/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🪆 俄罗斯套娃嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何使用 Megatron-LM 训练语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Mixtral - 当前 Hugging Face 上最先进的 MoE 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于AI进行游戏开发：5天！创建一个农场游戏！第1部分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ChatGPT 启发游戏创意｜基于 AI 5 天创建一个农场游戏，第 2 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 制作 3D 素材｜基于 AI 5 天创建一个农场游戏，第 3 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    制作 2D 素材｜基于 AI 5 天创建一个农场游戏，第 4 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 设计游戏剧情 | 基于 AI 5 天创建一个农场游戏，完结篇！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mms_adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调用于多语言 ASR 的 MMS 适配器模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合专家模型（MoE）详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-lora-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 多-LoRA：部署一次，搞定 30 个模型的推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../noob_intro_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face Transformers 萌新完全指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-drop/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开放 LLM 排行榜：深入研究 DROP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-mmlu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open LLM 排行榜近况
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础大模型能像人类一样标注数据吗？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-source-llms-as-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源大语言模型作为 LangChain 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimize-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向生产的 LLM 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizing-bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 优化 Bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimum-onnxruntime-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimum + ONNX Runtime: 更容易、更快地训练你的 Hugging Face 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../os-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 的文本生成和大语言模型的开源生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview-quantization-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Transformers 中原生支持的量化方案概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../packing-with-FA2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过打包 Flash Attention 来提升 Hugging Face 训练效率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../paligemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PaliGemma 正式发布 — Google 最新发布的前沿开放视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../password-git-deprecation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hub 上的 Git 操作不再支持使用密码验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 PEFT：在低资源硬件上对十亿规模模型进行参数高效微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../personal-copilot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    个人编程助手：训练你自己的编码助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi2-intel-meteor-lake/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    笔记本电脑上的聊天机器人：在英特尔 Meteor Lake 上运行 Phi-2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../presidio-pii-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hub 上使用 Presidio 进行自动 PII 检测实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../putting_rl_back_in_rlhf_with_rloo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将强化学习重新引入 RLHF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pycharm-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 PyCharm 深度集成：轻松引入丰富的 AI 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-ddp-accelerate-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 PyTorch DDP 到 Accelerate 到 Trainer，轻松掌握分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 完全分片数据并行技术加速大模型训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Quanto 和 Diffusers 的内存高效 transformer 扩散模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quanto：PyTorch 量化工具包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ram-efficient-pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch FSDP 微调 Llama 2 70B
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../red-teaming/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为大语言模型建立红队对抗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reformer 模型 - 突破语言建模的极限
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HF Hub 现已加入存储区域功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../researcher-dataset-sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hugging Face Hub 分享你的开源数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 背后的“功臣”——RLHF 技术详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RWKV -- transformer 与 RNN 的强强联合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ryght-case-study/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ryght 在 Hugging Face 专家助力下赋能医疗保健和生命科学之旅
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../safecoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    推介 SafeCoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sc2-instruct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3.5 Large 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd_distillation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源 SD-Small 和 SD-Tiny 知识蒸馏代码与权重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sdxl_lora_advanced_script/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    全世界 LoRA 训练脚本，联合起来!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-absa/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFitABSA：基于 SetFit 的少样本、方面级情感分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-optimum-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔至强 CPU 上使用 🤗 Optimum Intel 实现超快 SetFit 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFit: 高效的无提示少样本学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../smollm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SmolLM：一个超快速、超高性能的小模型集合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speecht5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 SpeechT5 进行语音合成、识别和更多功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sql-console/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为数据集而生的 SQL 控制台
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-finetuning-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-inference-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上加速 Stable Diffusion 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用Diffusers来实现Stable Diffusion 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stackllama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    “StackLLaMA”: 用 RLHF 训练 LLaMA 的手把手教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starchat-alpha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 StarCoder 创建一个编程助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder：最先进的代码大模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2 及 The Stack v2 数据集正式发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthetic-data-save-costs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    合成数据：利用开源技术节约资金、时间和减少碳排放
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthid-text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SynthID Text：在 AI 生成文本中应用不可见水印的新技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t2i-sdxl-adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 SDXL 上用 T2I-Adapter 实现高效可控的文生图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text-to-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解文生视频模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../textgen-pipe-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于英特尔® Gaudi® 2 AI 加速器的文本生成流水线
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tgi-benchmarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the-age-of-ml-as-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    机器学习即代码的时代已经到来
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the_n_implementation_details_of_rlhf_with_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PPO 算法进行 RLHF 的 N 步实现细节
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../time-series-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 进行概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-dgx-cloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 NVIDIA DGX Cloud上使用 H100 GPU 轻松训练模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-optimize-sd-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 NNCF 和 🤗 Optimum 面向 Intel CPU 对 Stable Diffusion 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-sentence-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Sentence Transformers v3 训练和微调嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-your-controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 diffusers 训练你自己的 ControlNet 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers-design-philosophy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    〜不要〜重复自己
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-ddpo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DDPO 在 TRL 中微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trufflesecurity-partnership/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 TruffleHog 成为合作伙伴，实现风险信息预警
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unified-tool-use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对 LLM 工具使用进行统一
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何安装和使用 Hugging Face Unity API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 Unity 游戏中集成 AI 语音识别？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-in-spaces/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 🤗 Space 上托管 Unity 游戏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../universal_assisted_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用辅助生成：使用任意辅助模型加速解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vertex-colored-to-textured-mesh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    顶点着色网格转换为 UV 映射的纹理化网格
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_language_pretraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入了解视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit-align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kakao Brain 的开源 ViT、ALIGN 和 COYO 文字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vlms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    视觉语言模型详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../watermarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能水印技术入门：工具与技巧
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper-speculative-decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用推测解码使 Whisper 实现 2 倍的推理加速
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../winning-aimo-progress-prize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NuminaMath 是如何荣膺首届 AIMO 进步奖的？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xethub-joins-hf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XetHub 加入 Hugging Face!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../zero-shot-vqa-docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LAVE：使用 LLM 对 Docmatix 进行零样本 VQA 评估 - 我们还需要微调吗？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运维
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../blog/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    博客
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../resume/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简历模板
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/C-L-STARK/C-L-STARK.github.io/edit/master/docs/ml/big-bird.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2zm-2.3 6.35c.22-.21.22-.56 0-.77L15.42 7.3a.53.53 0 0 0-.77 0l-1 1 2.05 2.05zM7 14.94V17h2.06l6.06-6.06-2.06-2.06z"/></svg>
    </a>
  
  


<h1 id="bigbird">深入理解 BigBird 的块稀疏注意力<a class="headerlink" href="#bigbird" title="Permanent link">&para;</a></h1>
<h2 id="_1">引言<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>基于 transformer 的模型已被证明对很多 NLP 任务都非常有用。然而，<span class="arithmatex">\(O(n^2)\)</span> 的时间和内存复杂度 (其中 <span class="arithmatex">\(n\)</span> 是序列长度) 使得在长序列 (<span class="arithmatex">\(n &gt; 512\)</span>) 上应用它们变得非常昂贵，因而大大限制了其应用。最近的几篇论文，如 <code>Longformer</code> 、<code>Performer</code> 、<code>Reformer</code> 、<code>簇状注意力</code> 都试图通过对完整注意力矩阵进行近似来解决这个问题。如果你不熟悉这些模型，可以查看 🤗 之前的 <a href="https://huggingface.co/blog/zh/long-range-transformers">博文</a>。</p>
<p><code>BigBird</code> (由 <a href="https://arxiv.org/abs/2007.14062">该论文</a> 引入) 是解决这个问题的最新模型之一。 <code>BigBird</code> 依赖于 <strong>块稀疏注意力</strong> 而不是普通注意力 ( <em>即</em> BERT 的注意力)，与 BERT 相比，这一新算法能以低得多的计算成本处理长达 <strong>4096</strong> 的序列。在涉及很长序列的各种任务上，该模型都实现了 SOTA，例如长文档摘要、长上下文问答。</p>
<p><strong>RoBERTa 架构的 BigBird</strong> 模型现已集成入 🤗 transformers 中。本文的目的是让读者 <strong>深入</strong> 了解 BigBird 的实现，并让读者能在 🤗 transformers 中轻松使用 BigBird。但是，在更深入之前，一定记住 <code>BigBird</code> 注意力只是 <code>BERT</code> 完全注意力的一个近似，因此我们并不纠结于让它比 <code>BERT</code> 完全注意力 <strong>更好</strong>，而是致力于让它更有效率。有了它，transformer 模型就可以作用于更长的序列，因为 BERT 的二次方内存需求很快会变得难以为继。简而言之，如果我们有 <span class="arithmatex">\(\infty\)</span> 计算和 <span class="arithmatex">\(\infty\)</span> 时间，那么用 BERT 注意力就好了，完全没必要用本文讨论的块稀疏注意力。</p>
<p>如果你想知道为什么在处理较长序列时需要更多计算，那么本文正合你意！</p>
<hr />
<p>在使用标准的 <code>BERT</code> 类注意力时可能会遇到以下几个主要问题:</p>
<ul>
<li>每个词元真的都必须关注所有其他词元吗？</li>
<li>为什么不只计算重要词元的注意力？</li>
<li>如何决定哪些词元重要？</li>
<li>如何以高效的方式处理少量词元？</li>
</ul>
<hr />
<p>本文，我们将尝试回答这些问题。</p>
<h3 id="_2">应该关注哪些词元？<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h3>
<p>下面，我们将以句子 <code>BigBird is now available in HuggingFace for extractive Question Answering</code> 为例来说明注意力是如何工作的。在 <code>BERT</code> 这类的注意力机制中，每个词元都简单粗暴地关注所有其他词元。从数学上来讲，这意味着每个查询的词元 $ \text{query-token} \in {\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering}} $,
将关注每个键词元 <span class="arithmatex">\(\text{key-tokens} = \left[\text{BigBird},\text{is},\text{now},\text{available},\text{in},\text{HuggingFace},\text{for},\text{extractive},\text{question},\text{answering} \right]\)</span>。</p>
<p>我们考虑一下 <code>每个查询词元应如何明智地选择它实际上应该关注的键词元</code> 这个问题，下面我们通过编写伪代码的方式来整理思考过程。</p>
<p>假设 <code>available</code> 是当前查询词元，我们来构建一个合理的、需要关注的键词元列表。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="c1"># 以下面的句子为例</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">example</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;BigBird&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;now&#39;</span><span class="p">,</span> <span class="s1">&#39;available&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;HuggingFace&#39;</span><span class="p">,</span> <span class="s1">&#39;for&#39;</span><span class="p">,</span> <span class="s1">&#39;extractive&#39;</span><span class="p">,</span> <span class="s1">&#39;question&#39;</span><span class="p">,</span> <span class="s1">&#39;answering&#39;</span><span class="p">]</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="c1"># 假设当前需要计算 &#39;available&#39; 这个词的表征</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">query_token</span> <span class="o">=</span> <span class="s1">&#39;available&#39;</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a><span class="c1"># 初始化一个空集合，用于放 &#39;available&#39; 这个词的键词元</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="n">key_tokens</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># =&gt; 目前，&#39;available&#39; 词元不关注任何词元</span>
</span></code></pre></div>
<p>邻近词元当然很重要，因为在一个句子 (单词序列) 中，当前词高度依赖于前后的邻近词。<code>滑动注意力</code> 即基于该直觉。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="c1"># 考虑滑动窗大小为 3, 即将 &#39;available&#39; 的左边一个词和右边一个词纳入考量</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a><span class="c1"># 左词: &#39;now&#39;; 右词: &#39;in&#39;</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">sliding_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;now&quot;</span><span class="p">,</span> <span class="s2">&quot;available&quot;</span><span class="p">,</span> <span class="s2">&quot;in&quot;</span><span class="p">]</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="c1"># 用以上词元更新集合</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="n">key_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sliding_tokens</span><span class="p">)</span>
</span></code></pre></div>
<p><strong>长程依赖关系:</strong> 对某些任务而言，捕获词元间的长程关系至关重要。 <em>例如</em> ，在问答类任务中，模型需要将上下文的每个词元与整个问题进行比较，以便能够找出上下文的哪一部分对正确答案有用。如果大多数上下文词元仅关注其他上下文词元，而不关注问题，那么模型从不太重要的上下文词元中过滤重要的上下文词元就会变得更加困难。</p>
<p><code>BigBird</code> 提出了两种允许长程注意力依赖的方法，这两种方法都能保证计算效率。</p>
<ul>
<li><strong>全局词元:</strong> 引入一些词元，这些词元将关注每个词元并且被每个词元关注。例如，对 <em>“HuggingFace is building nice libraries for easy NLP”</em> ，现在假设 <em>'building'</em> 被定义为全局词元，而对某些任务而言，模型需要知道 <em>'NLP'</em> 和 <em>'HuggingFace'</em> 之间的关系 (注意: 这 2 个词元位于句子的两端); 现在让 <em>'building'</em> 在全局范围内关注所有其他词元，会对模型将 <em>'NLP'</em> 与 <em>'HuggingFace'</em> 关联起来有帮助。</li>
</ul>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="c1"># 我们假设第一个和最后一个词元是全局的，则有:</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="n">global_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;BigBird&quot;</span><span class="p">,</span> <span class="s2">&quot;answering&quot;</span><span class="p">]</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="c1"># 将全局词元加入到集合中</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">key_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">global_tokens</span><span class="p">)</span>
</span></code></pre></div>
<ul>
<li><strong>随机词元:</strong> 随机选择一些词元，这些词元将通过关注其他词元来传输信息，而那些词元又可以传输信息到其他词元。这可以降低直接从一个词元到另一个词元的信息传输成本。</li>
</ul>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="c1"># 现在，我们可以从句子中随机选择 `r` 个词元。这里，假设 `r` 为 1， 选择了 `is` 这个词元</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">random_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;is&quot;</span><span class="p">]</span> <span class="c1"># 注意: 这个是完全随机选择的，因此可以是任意词元。</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="c1"># 将随机词元加入到集合中</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="n">key_tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">random_tokens</span><span class="p">)</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="c1"># 现在看下 `key_tokens` 集合中有哪些词元</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="n">key_tokens</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="p">{</span><span class="s1">&#39;now&#39;</span><span class="p">,</span> <span class="s1">&#39;is&#39;</span><span class="p">,</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span> <span class="s1">&#39;answering&#39;</span><span class="p">,</span> <span class="s1">&#39;available&#39;</span><span class="p">,</span> <span class="s1">&#39;BigBird&#39;</span><span class="p">}</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a><span class="c1"># 至此，查询词 &#39;available&#39; 仅关注集合中的这些词元，而不用关心全部</span>
</span></code></pre></div>
<p>这样，查询词元仅关注所有词元的一个子集，该子集能够产生完全注意力值的一个不错的近似。相同的方法将用于所有其他查询词元。但请记住，这里的重点是尽可能有效地接近 <code>BERT</code> 的完全注意力。BERT 那种简单地让每个查询词元关注所有键词元的做法可以建模为一系列矩阵乘法，从而在现代硬件 (如 GPU) 上进行高效计算。然而，滑动、全局和随机注意力的组合似乎意味着稀疏矩阵乘法，这在现代硬件上很难高效实现。<code>BigBird</code> 的主要贡献之一是提出了 <code>块稀疏</code> 注意力机制，该机制可以高效计算滑动、全局和随机注意力。我们来看看吧！</p>
<h3 id="_3">图解全局、滑动、随机注意力的概念<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h3>
<p>首先，我们借助图来帮助理解“全局”、“滑动”和“随机”注意力，并尝试理解这三种注意力机制的组合是如何较好地近似标准 BERT 类注意力的。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/global.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://huggingface.co/blog/assets/18_big_bird/global.png" width=250 height=250></a>
<a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/sliding.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://huggingface.co/blog/assets/18_big_bird/sliding.png" width=250 height=250></a>
<a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/random.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://huggingface.co/blog/assets/18_big_bird/random.png" width=250 height=250></a> <br></p>
<p><em>上图分别把“全局”(左) 、“滑动”(中) 和“随机”(右) 连接建模成一个图。每个节点对应一个词元，每条边代表一个注意力分数。如果 2 个词元之间没有边连接，则其注意力分数为 0。</em></p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/graph.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://huggingface.co/blog/assets/18_big_bird/graph.gif" /></a></p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/full.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://huggingface.co/blog/assets/18_big_bird/full.png" width=230 height=230></a></p>
<p><strong>BigBird 块稀疏注意力</strong> 是滑动连接、全局连接和随机连接 (总共 10 个连接) 的组合，如上图左侧动图所示。而 <strong>完全注意力</strong> 图 (右侧) 则是有全部 15 个连接 (注意: 总共有 6 个节点)。你可以简单地将完全注意力视为所有词元都是全局词元 <span class="arithmatex">\({}^1\)</span>。</p>
<p><strong>完全注意力:</strong> 模型可以直接在单个层中将信息从一个词元传输到另一个词元，因为每个词元都会对每个其他词元进行查询，并且受到其他每个词元的关注。我们考虑一个与上图类似的例子，如果模型需要将 <em>'going'</em> 与 <em>'now'</em> 关联起来，它可以简单地在单层中执行此操作，因为它们两个是有直接连接的。</p>
<p><strong>块稀疏注意力:</strong> 如果模型需要在两个节点 (或词元) 之间共享信息，则对于某些词元，信息将必须经过路径中的各个其他节点; 因为不是所有节点都有直接连接的。
<em>例如</em> ，假设模型需要将 <code>going</code> 与 <code>now</code> 关联起来，那么如果仅存在滑动注意力，则这两个词元之间的信息流由路径 <code>going -&gt; am -&gt; i -&gt; now</code> 来定义，也就是说它必须经过 2 个其他词元。因此，我们可能需要多个层来捕获序列的全部信息，而正常的注意力可以在单层中捕捉到这一点。在极端情况下，这可能意味着需要与输入词元一样多的层。然而，如果我们引入一些全局词元，信息可以通过以下路径传播 <code>going -&gt; i -&gt; now</code> ，这可以帮助缩短路径。如果我们再另外引入随机连接，它就可以通过 <code>going -&gt; am -&gt; now</code> 传播。借助随机连接和全局连接，信息可以非常快速地 (只需几层) 从一个词元传输到下一个词元。</p>
<p>如果我们有很多全局词元，那么我们可能不需要随机连接，因为信息可以通过多个短路径传播。这就是在使用 BigBird 的变体 (称为 ETC) 时设置 <code>num_random_tokens = 0</code> 的动机 (稍后部分将会详细介绍)。</p>
<p><span class="arithmatex">\({}^1\)</span> 在这些图中，我们假设注意力矩阵是对称的 <strong>即</strong> <span class="arithmatex">\(\mathbf{A} _{ij} = \mathbf{A}_ {ji}\)</span> 因为在图中如果某个词元 <strong>A</strong> 关注 <strong>B</strong>，那么 <strong>B</strong> 也会关注 <strong>A</strong>。从下一节所示的注意力矩阵图中可以看出，这个假设对于 BigBird 中的大多数词元都成立。</p>
<table>
<thead>
<tr>
<th>注意力类型</th>
<th>全局词元</th>
<th>滑动词元</th>
<th>随机词元</th>
</tr>
</thead>
<tbody>
<tr>
<td>原始完全注意力</td>
<td><code>n</code></td>
<td>0</td>
<td>0</td>
</tr>
<tr>
<td>块稀疏注意力</td>
<td>2 x <code>block_size</code></td>
<td>3 x <code>block_size</code></td>
<td><code>num_random_blocks</code> x <code>block_size</code></td>
</tr>
</tbody>
</table>
<p>原始完全注意力即 <code>BERT</code> 的注意力，而块稀疏注意力则是 <code>BigBird</code> 的注意力。想知道 <code>block_size</code> 是什么？请继续阅读下文。<em>现在，为简单起见，将其视为 1。</em></p>
<h2 id="bigbird_1">BigBird 块稀疏注意力<a class="headerlink" href="#bigbird_1" title="Permanent link">&para;</a></h2>
<p>BigBird 块稀疏注意力是我们上文讨论的内容的高效实现。每个词元都关注某些 <strong>全局词元</strong> 、 <strong>滑动词元</strong> 和 <strong>随机词元</strong>，而不管其他 <strong>所有</strong> 词元。作者分别实现了每类查询注意力矩阵，并使用了一个很酷的技巧来加速 GPU 和 TPU 上的训练/推理。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/attn.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/attn.png" /></a></p>
<p><em>注意: 在上图的顶部有 2 个额外的句子。正如你所注意到的，两个句子中的每个词元都只是交换了一个位置。这就是滑动注意力的实现方式。当 <code>q[i]</code> 与 <code>k[i,0:3]</code> 相乘时，我们会得到 <code>q[i]</code> 的滑动注意力分数 (其中<code>i</code> 是序列中元素的索引)。</em></p>
<p>你可以在 <a href="https://github.com/vasudevgupta7/transformers/blob/5f2d6a0c93ca2017961199aa04a344b9b779d454/src/transformers/models/big_bird/modeling_big_bird.py#L513">这儿</a> 找到 <code>block_sparse</code> 注意力的具体实现。现在看起来可能非常可怕😨😨，但这篇文章肯定会让你轻松理解它。</p>
<h3 id="_4">全局注意力<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>对于全局注意力而言，每个查询词元关注序列中的所有其他词元，并且被其他每个词元关注。我们假设 <code>Vasudev</code> (第一个词元) 和 <code>them</code> (最后一个词元) 是全局的 (如上图所示)。你可以看到这些词元直接连接到所有其他词元 (蓝色框)。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="c1"># 伪代码</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="n">Q</span> <span class="o">-&gt;</span> <span class="n">Query</span> <span class="n">martix</span> <span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="n">K</span> <span class="o">-&gt;</span> <span class="n">Key</span> <span class="n">matrix</span> <span class="p">(</span><span class="n">seq_length</span><span class="p">,</span> <span class="n">head_dim</span><span class="p">)</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="c1"># 第一个和最后一个词元关注所有其他词元</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="c1"># 第一个和最后一个词元也被其他所有词元关注</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span></code></pre></div>
<h3 id="_5">滑动注意力<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h3>
<p>键词元序列被复制两次，其中一份每个词元向右移动一步，另一份每个词元向左移动一步。现在，如果我们将查询序列向量乘以这 3 个序列向量，我们将覆盖所有滑动词元。计算复杂度就是 <code>O(3n) = O(n)</code> 。参考上图，橙色框代表滑动注意力。你可以在图的顶部看到 3 个序列，其中 2 个序列各移动了一个词元 (1 个向左，1 个向右)。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="c1"># 我们想做的</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">]]</span> <span class="k">for</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="c1"># 高效的代码实现 (👇 乘法为点乘)</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="n">x</span> <span class="p">[</span><span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">]]</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="n">x</span> <span class="p">[</span><span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a><span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span> <span class="n">x</span> <span class="p">[</span><span class="n">K</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">K</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">K</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="c1"># 每个序列被乘 3 词， 即 `window_size = 3`。为示意，仅列出主要计算，省略了一些计算。</span>
</span></code></pre></div>
<h3 id="_6">随机注意力<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>随机注意力确保每个查询词元也会关注一些随机词元。对实现而言，这意味着模型随机选取一些词元并计算它们的注意力分数。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="c1"># r1, r2, r 为随机索引; 注意 r1, r2, r 每行取值不同 👇</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="n">Q</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="n">r1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="n">r2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">r</span><span class="p">]]</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="o">.</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a><span class="o">.</span>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="o">.</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="n">Q</span><span class="p">[</span><span class="n">n</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span> <span class="n">x</span> <span class="p">[</span><span class="n">Q</span><span class="p">[</span><span class="n">r1</span><span class="p">],</span> <span class="n">Q</span><span class="p">[</span><span class="n">r2</span><span class="p">],</span> <span class="o">......</span><span class="p">,</span> <span class="n">Q</span><span class="p">[</span><span class="n">r</span><span class="p">]]</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="c1"># 不用管第 0 个和第 n-1 个词元，因为它们已经是全局词元了。</span>
</span></code></pre></div>
<p><strong>注意:</strong> 当前的实现进一步将序列划分为块，并且每个符号都依块而定义而非依词元而定义。我们在下一节中会更详细地讨论这个问题。</p>
<h3 id="_7">实现<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h3>
<p><strong>回顾:</strong> 在常规 BERT 注意力中，一系列词元，即 <span class="arithmatex">\(X = x_1, x_2, …., x_n\)</span> 通过线性层投影到 <span class="arithmatex">\(Q，K，V\)</span>，并基于它们计算注意力分数 <span class="arithmatex">\(Z\)</span>，公式为 <span class="arithmatex">\(Z=Softmax(QK^T)\)</span>。使用 BigBird 块稀疏注意力时，我们使用相同的算法，但仅针对一些选定的查询和键向量进行计算。</p>
<p>我们来看看 BigBird 块稀疏注意力是如何实现的。首先，我们用 <span class="arithmatex">\(b、r、s、g\)</span> 分别代表 <code>block_size</code> 、<code>num_random_blocks</code> 、<code>num_sliding_blocks</code> 、<code>num_global_blocks</code> 。我们以 <span class="arithmatex">\(b=4，r=1，g=2，s=3，d=5\)</span> 为例来说明 BigBird 块稀疏注意力的机制部分，如下所示:</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/intro.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://huggingface.co/blog/assets/18_big_bird/intro.png" width=500 height=250></a></p>
<p><span class="arithmatex">\({q} _{1}、{q}_ {2}、{q} _{3:n-2}、{q}_ {n-1}、{q}_{n}\)</span> 的注意力分数分别计算如下:</p>
<hr />
<p><span class="arithmatex">\(\mathbf{q}_{1}\)</span> 的注意力分数由 <span class="arithmatex">\(a_1\)</span> 表示，其中 <span class="arithmatex">\(a_1=Softmax(q_1 * K^T)\)</span>，即为第一块中的所有词元与序列中的所有其他词元之间的注意力分数。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/q1.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/q1.png" /></a></p>
<p><span class="arithmatex">\(q_1\)</span> 表示第 1 块，<span class="arithmatex">\(g_i\)</span> 表示第 <span class="arithmatex">\(i\)</span> 块。我们仅在 <span class="arithmatex">\(q_1\)</span> 和  <span class="arithmatex">\(g\)</span> (即所有键) 之间执行正常的注意力操作。</p>
<hr />
<p>为了计算第二块中词元的注意力分数，我们收集前三块、最后一块和第五块。然后我们可以计算 <span class="arithmatex">\(a_2 = Softmax(q_2 * concat(k_1, k_2, k_3, k_5, k_7))\)</span>。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/q2.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/q2.png" /></a></p>
<p><em>这里，我用 <span class="arithmatex">\(g，r，s\)</span> 表示词元只是为了明确地表示它们的性质 (即是全局、随机还是滑动词元)，只用 <span class="arithmatex">\(k\)</span> 无法表示他们各自的性质。</em></p>
<hr />
<p>为了计算 <span class="arithmatex">\({q} _{3:n-2}\)</span> 的注意力分数，我们先收集相应的全局、滑动、随机键向量，并基于它们正常计算 <span class="arithmatex">\({q}_ {3:n-2}\)</span> 上的注意力。请注意，正如前面滑动注意力部分所讨论的，滑动键是使用特殊的移位技巧来收集的。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/q_middle.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/q_middle.png" /></a></p>
<hr />
<p>为了计算倒数第二块 (即 <span class="arithmatex">\({q} _{n-1}\)</span>) 中词元的注意力分数，我们收集第一块、最后三块和第三块的键向量。然后我们用公式 <span class="arithmatex">\({a}_ {n-1} = Softmax({q}_{n-1} * concat(k_1, k_3, k_5, k_6, k_7))\)</span> 进行计算。这和计算 <span class="arithmatex">\(q_2\)</span> 非常相似。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/qlast_sec.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/qlast_sec.png" /></a></p>
<hr />
<p>最后一块 <span class="arithmatex">\(\mathbf{q}_{n}\)</span> 的注意力分数由 <span class="arithmatex">\(a_n\)</span> 表示，其中 <span class="arithmatex">\(a_n=Softmax(q_n * K^T)\)</span>，只不过是最后一块中的所有词元与序列中的所有其他词元之间的注意力分数。这与我们对 <span class="arithmatex">\(q_1\)</span> 所做的非常相似。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/qlast.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/qlast.png" /></a></p>
<hr />
<p>我们将上面的矩阵组合起来得到最终的注意力矩阵。该注意力矩阵可用于获取所有词元的表征。</p>
<p><a class="glightbox" href="https://huggingface.co/blog/assets/18_big_bird/block-sparse-attn.gif" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="BigBird 块稀疏注意力" src="https://huggingface.co/blog/assets/18_big_bird/block-sparse-attn.gif" /></a></p>
<p><em>上图中 <code>蓝色 -&gt; 全局块</code> 、<code>红色 -&gt; 随机块</code> 、<code>橙色 -&gt; 滑动块</code> 。在前向传播过程中，我们不存储“白色”块，而是直接为每个单独的部分计算加权值矩阵 (即每个词元的表示)，如上所述。</em></p>
<p>现在，我们已经介绍了块稀疏注意力最难的部分，即它的实现。希望对你更好地理解实际代码有帮助。现在你可以深入研究代码了，在此过程中你可以将代码的每个部分与上面的某个部分联系起来以助于理解。</p>
<h2 id="_8">时间和内存复杂度<a class="headerlink" href="#_8" title="Permanent link">&para;</a></h2>
<table>
<thead>
<tr>
<th>注意力类型</th>
<th>序列长度</th>
<th>时间和内存复杂度</th>
</tr>
</thead>
<tbody>
<tr>
<td>原始完全注意力</td>
<td>512</td>
<td><code>T</code></td>
</tr>
<tr>
<td></td>
<td>1024</td>
<td>4 x <code>T</code></td>
</tr>
<tr>
<td></td>
<td>4096</td>
<td>64 x <code>T</code></td>
</tr>
<tr>
<td>块稀疏注意力</td>
<td>1024</td>
<td>2 x <code>T</code></td>
</tr>
<tr>
<td></td>
<td>4096</td>
<td>8 x <code>T</code></td>
</tr>
</tbody>
</table>
<p><em>BERT 注意力和 BigBird 块稀疏注意力的时间和空间复杂度之比较。</em></p>
<details>
<summary> 展开以了解复杂度的计算过程。</summary>

<div class="language-md highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a>BigBird 时间复杂度 = O(w x n + r x n + g x n)
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a>BERT 时间复杂度 = O(n^2)
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a>假设:
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    w = 3 x 64
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    r = 3 x 64
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a>    g = 2 x 64
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>当序列长度为 512 时
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a>=&gt; <span class="gs">**BERT 时间复杂度 = 512^2**</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>当序列长度为 1024 时
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a>=&gt; BERT 时间复杂度 = (2 x 512)^2
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>=&gt; <span class="gs">**BERT 时间复杂度 = 4 x 512^2**</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>=&gt; BigBird 时间复杂度 = (8 x 64) x (2 x 512)
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a>=&gt; <span class="gs">**BigBird 时间复杂度 = 2 x 512^2**</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>当序列长度为 4096 时
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a>=&gt; BERT 时间复杂度 = (8 x 512)^2
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a>=&gt; <span class="gs">**BERT 时间复杂度 = 64 x 512^2**</span>
</span><span id="__span-7-22"><a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a>
</span><span id="__span-7-23"><a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a>=&gt; BigBird 时间复杂度 = (8 x 64) x (8 x 512)
</span><span id="__span-7-24"><a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a>=&gt; BigBird 时间复杂度 = 8 x (512 x 512)
</span><span id="__span-7-25"><a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a>=&gt; <span class="gs">**BigBird 时间复杂度 = 8 x 512^2**</span>
</span></code></pre></div>

</details>

<h2 id="itc-etc">ITC 与 ETC<a class="headerlink" href="#itc-etc" title="Permanent link">&para;</a></h2>
<p>BigBird 模型可以使用 2 种不同的策略进行训练: <strong>ITC</strong> 和 <strong>ETC</strong>。 ITC (internal transformer construction，内部 transformer 构建) 就是我们上面讨论的。在 ETC (extended transformer construction，扩展 transformer 构建) 中，会有更多的全局词元，以便它们关注所有词元或者被所有词元关注。</p>
<p>ITC 需要的计算量较小，因为很少有词元是全局的，同时模型可以捕获足够的全局信息 (也可以借助随机注意力)。而 ETC 对于需要大量全局词元的任务非常有帮助，例如对 <strong>问答</strong> 类任务而言，整个问题应该被所有上下文关注，以便能够将上下文正确地与问题相关联。</p>
<p><em><strong>注意:</strong> BigBird 论文显示，在很多 ETC 实验中，随机块的数量设置为 0。考虑到我们上文图解部分的讨论，这是合理的。</em></p>
<p>下表总结了 ITC 和 ETC:</p>
<table>
<thead>
<tr>
<th></th>
<th>ITC</th>
<th>ETC</th>
</tr>
</thead>
<tbody>
<tr>
<td>全局注意力的注意力矩阵</td>
<td>\( A = \begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \end{bmatrix} \)</td>
<td>\( B = \begin{bmatrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; &amp; &amp; &amp; &amp; &amp; 1 \ 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 \end{bmatrix} \)</td>
</tr>
<tr>
<td>全局词元</td>
<td>2 x <code>block_size</code></td>
<td><code>extra_tokens</code> + 2 x <code>block_size</code></td>
</tr>
<tr>
<td>随机词元</td>
<td><code>num_random_blocks</code> x <code>block_size</code></td>
<td><code>num_random_blocks</code> x <code>block_size</code></td>
</tr>
<tr>
<td>滑动词元</td>
<td>3 x <code>block_size</code></td>
<td>3 x <code>block_size</code></td>
</tr>
</tbody>
</table>
<h2 id="transformers-bigbird">在  🤗Transformers 中使用 BigBird<a class="headerlink" href="#transformers-bigbird" title="Permanent link">&para;</a></h2>
<p>你可以像使用任何其他 🤗 模型一样使用 <code>BigBirdModel</code> 。我们看一下代码:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BigBirdModel</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a><span class="c1"># 从预训练 checkpoint 中加载 bigbird 模型</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BigBirdModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/bigbird-roberta-base&quot;</span><span class="p">)</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a><span class="c1"># 使用默认配置初始化模型，如 attention_type = &quot;block_sparse&quot;，num_random_blocks = 3，block_size = 64</span>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a><span class="c1"># 你也可以按照自己的需要改变这些参数。这 3 个参数只改变每个查询词元关注的词元数。</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BigBirdModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/bigbird-roberta-base&quot;</span><span class="p">,</span> <span class="n">num_random_blocks</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a><span class="c1"># 通过把 attention_type 设成 `original_full`，BigBird 就会用复杂度为 n^2 的完全注意力。此时，BigBird 与 BERT 相似度为 99.9%。</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BigBirdModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/bigbird-roberta-base&quot;</span><span class="p">,</span> <span class="n">attention_type</span><span class="o">=</span><span class="s2">&quot;original_full&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>截至现在， <strong>🤗 Hub</strong> 中总共有 <strong>3 个 BigBird checkpoint</strong>: <a href="https://huggingface.co/google/bigbird-roberta-base"><code>bigbird-roberta-base</code></a>，<a href="https://huggingface.co/google/bigbird-roberta-large"><code>bigbird-roberta-large</code></a> 以及 <a href="https://huggingface.co/google/bigbird-base-trivia-itc"><code>bigbird-base-trivia-itc</code></a>。前两个检查点是使用 <code>masked_lm 损失</code> 预训练 <code>BigBirdForPretraining</code> 而得; 而最后一个是在 <code>trivia-qa</code> 数据集上微调 <code>BigBirdForQuestionAnswering</code> 而得。</p>
<p>让我们看一下如果用你自己喜欢的 PyTorch 训练器，最少需要多少代码就可以使用 🤗 的 BigBird 模型来微调你自己的任务。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="c1"># 以问答任务为例</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">BigBirdForQuestionAnswering</span><span class="p">,</span> <span class="n">BigBirdTokenizer</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="c1"># 我们用预训练权重初始化 bigbird 模型，并随机初始化其头分类器</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BigBirdForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/bigbird-roberta-base&quot;</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">num_random_blocks</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">BigBirdTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;google/bigbird-roberta-base&quot;</span><span class="p">)</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-9-13"><a id="__codelineno-9-13" name="__codelineno-9-13" href="#__codelineno-9-13"></a>
</span><span id="__span-9-14"><a id="__codelineno-9-14" name="__codelineno-9-14" href="#__codelineno-9-14"></a><span class="n">dataset</span> <span class="o">=</span> <span class="s2">&quot;torch.utils.data.DataLoader object&quot;</span>
</span><span id="__span-9-15"><a id="__codelineno-9-15" name="__codelineno-9-15" href="#__codelineno-9-15"></a><span class="n">optimizer</span> <span class="o">=</span> <span class="s2">&quot;torch.optim object&quot;</span>
</span><span id="__span-9-16"><a id="__codelineno-9-16" name="__codelineno-9-16" href="#__codelineno-9-16"></a><span class="n">epochs</span> <span class="o">=</span> <span class="o">...</span>
</span><span id="__span-9-17"><a id="__codelineno-9-17" name="__codelineno-9-17" href="#__codelineno-9-17"></a>
</span><span id="__span-9-18"><a id="__codelineno-9-18" name="__codelineno-9-18" href="#__codelineno-9-18"></a><span class="c1"># 最简训练循环</span>
</span><span id="__span-9-19"><a id="__codelineno-9-19" name="__codelineno-9-19" href="#__codelineno-9-19"></a><span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
</span><span id="__span-9-20"><a id="__codelineno-9-20" name="__codelineno-9-20" href="#__codelineno-9-20"></a>    <span class="k">for</span> <span class="n">batch</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">:</span>
</span><span id="__span-9-21"><a id="__codelineno-9-21" name="__codelineno-9-21" href="#__codelineno-9-21"></a>        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span><span id="__span-9-22"><a id="__codelineno-9-22" name="__codelineno-9-22" href="#__codelineno-9-22"></a>        <span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">}</span>
</span><span id="__span-9-23"><a id="__codelineno-9-23" name="__codelineno-9-23" href="#__codelineno-9-23"></a>
</span><span id="__span-9-24"><a id="__codelineno-9-24" name="__codelineno-9-24" href="#__codelineno-9-24"></a>        <span class="c1"># 前向</span>
</span><span id="__span-9-25"><a id="__codelineno-9-25" name="__codelineno-9-25" href="#__codelineno-9-25"></a>        <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span>
</span><span id="__span-9-26"><a id="__codelineno-9-26" name="__codelineno-9-26" href="#__codelineno-9-26"></a>
</span><span id="__span-9-27"><a id="__codelineno-9-27" name="__codelineno-9-27" href="#__codelineno-9-27"></a>        <span class="c1"># 后向</span>
</span><span id="__span-9-28"><a id="__codelineno-9-28" name="__codelineno-9-28" href="#__codelineno-9-28"></a>        <span class="n">output</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span><span id="__span-9-29"><a id="__codelineno-9-29" name="__codelineno-9-29" href="#__codelineno-9-29"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span><span id="__span-9-30"><a id="__codelineno-9-30" name="__codelineno-9-30" href="#__codelineno-9-30"></a>        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span><span id="__span-9-31"><a id="__codelineno-9-31" name="__codelineno-9-31" href="#__codelineno-9-31"></a>
</span><span id="__span-9-32"><a id="__codelineno-9-32" name="__codelineno-9-32" href="#__codelineno-9-32"></a><span class="c1"># 将最终权重存至本地目录</span>
</span><span id="__span-9-33"><a id="__codelineno-9-33" name="__codelineno-9-33" href="#__codelineno-9-33"></a><span class="n">model</span><span class="o">.</span><span class="n">save_pretrained</span><span class="p">(</span><span class="s2">&quot;&lt;YOUR-WEIGHTS-DIR&gt;&quot;</span><span class="p">)</span>
</span><span id="__span-9-34"><a id="__codelineno-9-34" name="__codelineno-9-34" href="#__codelineno-9-34"></a>
</span><span id="__span-9-35"><a id="__codelineno-9-35" name="__codelineno-9-35" href="#__codelineno-9-35"></a><span class="c1"># 将权重推到 🤗 Hub 中</span>
</span><span id="__span-9-36"><a id="__codelineno-9-36" name="__codelineno-9-36" href="#__codelineno-9-36"></a><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">ModelHubMixin</span>
</span><span id="__span-9-37"><a id="__codelineno-9-37" name="__codelineno-9-37" href="#__codelineno-9-37"></a><span class="n">ModelHubMixin</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="s2">&quot;&lt;YOUR-WEIGHTS-DIR&gt;&quot;</span><span class="p">,</span> <span class="n">model_id</span><span class="o">=</span><span class="s2">&quot;&lt;YOUR-FINETUNED-ID&gt;&quot;</span><span class="p">)</span>
</span><span id="__span-9-38"><a id="__codelineno-9-38" name="__codelineno-9-38" href="#__codelineno-9-38"></a>
</span><span id="__span-9-39"><a id="__codelineno-9-39" name="__codelineno-9-39" href="#__codelineno-9-39"></a><span class="c1"># 使用微调后的模型，以用于推理</span>
</span><span id="__span-9-40"><a id="__codelineno-9-40" name="__codelineno-9-40" href="#__codelineno-9-40"></a><span class="n">question</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;How are you doing?&quot;</span><span class="p">,</span> <span class="s2">&quot;How is life going?&quot;</span><span class="p">]</span>
</span><span id="__span-9-41"><a id="__codelineno-9-41" name="__codelineno-9-41" href="#__codelineno-9-41"></a><span class="n">context</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&lt;some big context having ans-1&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;some big context having ans-2&gt;&quot;</span><span class="p">]</span>
</span><span id="__span-9-42"><a id="__codelineno-9-42" name="__codelineno-9-42" href="#__codelineno-9-42"></a><span class="n">batch</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">context</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span>
</span><span id="__span-9-43"><a id="__codelineno-9-43" name="__codelineno-9-43" href="#__codelineno-9-43"></a><span class="n">batch</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">batch</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">batch</span><span class="p">}</span>
</span><span id="__span-9-44"><a id="__codelineno-9-44" name="__codelineno-9-44" href="#__codelineno-9-44"></a>
</span><span id="__span-9-45"><a id="__codelineno-9-45" name="__codelineno-9-45" href="#__codelineno-9-45"></a><span class="n">model</span> <span class="o">=</span> <span class="n">BigBirdForQuestionAnswering</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;&lt;YOUR-FINETUNED-ID&gt;&quot;</span><span class="p">)</span>
</span><span id="__span-9-46"><a id="__codelineno-9-46" name="__codelineno-9-46" href="#__codelineno-9-46"></a><span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-9-47"><a id="__codelineno-9-47" name="__codelineno-9-47" href="#__codelineno-9-47"></a><span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
</span><span id="__span-9-48"><a id="__codelineno-9-48" name="__codelineno-9-48" href="#__codelineno-9-48"></a>    <span class="n">start_logits</span><span class="p">,</span> <span class="n">end_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="o">**</span><span class="n">batch</span><span class="p">)</span><span class="o">.</span><span class="n">to_tuple</span><span class="p">()</span>
</span><span id="__span-9-49"><a id="__codelineno-9-49" name="__codelineno-9-49" href="#__codelineno-9-49"></a>    <span class="c1"># 这里，你可以使用自己的策略对 start_logits，end_logits 进行解码</span>
</span><span id="__span-9-50"><a id="__codelineno-9-50" name="__codelineno-9-50" href="#__codelineno-9-50"></a>
</span><span id="__span-9-51"><a id="__codelineno-9-51" name="__codelineno-9-51" href="#__codelineno-9-51"></a><span class="c1"># 注意:</span>
</span><span id="__span-9-52"><a id="__codelineno-9-52" name="__codelineno-9-52" href="#__codelineno-9-52"></a><span class="c1"># 该代码段仅用于展示即使你想用自己的 PyTorch 训练器微调 BigBrid，这也是相当容易的。</span>
</span><span id="__span-9-53"><a id="__codelineno-9-53" name="__codelineno-9-53" href="#__codelineno-9-53"></a><span class="c1"># 我会建议使用 🤗 Trainer，它更简单，功能也更多。</span>
</span></code></pre></div>
<p>使用 BigBird 时，需要记住以下几点:</p>
<ul>
<li>序列长度必须是块大小的倍数，即 <code>seqlen % block_size = 0</code> 。你不必担心，因为如果 batch 的序列长度不是 <code>block_size</code> 的倍数，🤗 transformers 会自动填充至最近的整数倍。</li>
<li>目前，Hugging Face 的实现 <strong>尚不支持 ETC</strong>，因此只有第一个和最后一个块是全局的。</li>
<li>当前实现不支持 <code>num_random_blocks = 0</code> 。</li>
<li>论文作者建议当序列长度 &lt; 1024 时设置 <code>attention_type = "original_full"</code> 。</li>
<li>必须满足: <code>seq_length &gt; global_token + random_tokens + moving_tokens + buffer_tokens</code> ，其中 <code>global_tokens = 2 x block_size</code> 、 <code>sliding_tokens = 3 x block_size</code> 、 <code>random_tokens = num_random_blocks x block_size</code> 且 <code>buffer_tokens = num_random_blocks x block_size</code> 。如果你不能满足这一点，🤗 transformers 会自动将 <code>attention_type</code> 切换为 <code>original_full</code> 并告警。</li>
<li>当使用 BigBird 作为解码器 (或使用 <code>BigBirdForCasualLM</code> ) 时， <code>attention_type</code> 应该是 <code>original_full</code> 。但你不用担心，🤗 transformers 会自动将 <code>attention_type</code> 切换为 <code>original_full</code> ，以防你忘记这样做。</li>
</ul>
<h2 id="_9">下一步<a class="headerlink" href="#_9" title="Permanent link">&para;</a></h2>
<p><a href="https://github.com/patrickvonplaten">@patrickvonplaten</a> 建了一个非常酷的 <a href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Evaluating_Big_Bird_on_TriviaQA.ipynb">笔记本</a>，以展示如何在 <code>trivia-qa</code> 数据集上评估 <code>BigBirdForQuestionAnswering</code> 。你可以随意用这个笔记本来玩玩 BigBird。</p>
<p><strong>BigBird 版的 Pegasus</strong> 模型很快就会面世，你可将它们用于 <strong>长文档摘要</strong> 💥。</p>
<h2 id="_10">尾注<a class="headerlink" href="#_10" title="Permanent link">&para;</a></h2>
<p>你可在 <a href="https://github.com/google-research/bigbird/blob/master/bigbird/core/attention.py">此处</a> 找到 <strong>块稀疏注意力矩阵</strong> 的原始实现。🤗 版的实现在 <a href="https://github.com/huggingface/transformers/tree/master/src/transformers/models/big_bird">这儿</a>。</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9 3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3 3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3 3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.54 5.54 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13zM0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9-.59.68-.95 1.62-.95 2.65V20zm24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65 2.56.34 4.45 1.51 4.45 2.9z"/></svg>
      
    </span>
    <nav>
      
    </nav>
  </span>

    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank" rel="noopener">feedback form</a>.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../beating-gaia/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Transformers 代码智能体成功刷榜 GAIA">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Transformers 代码智能体成功刷榜 GAIA
              </div>
            </div>
          </a>
        
        
          
          <a href="../blip-2/" class="md-footer__link md-footer__link--next" aria-label="Next: 使用 BLIP-2 零样本“图生文”">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                使用 BLIP-2 零样本“图生文”
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 - 2024 FastX-AI
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
    
    
    
    <a href="https://fastx-ai.com" target="_blank" rel="noopener me" title="fastx-ai" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:x.stark.dylan@gmail.com" target="_blank" rel="noopener" title="send me an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 112c-8.8 0-16 7.2-16 16v22.1l172.5 141.6c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16zM48 212.2V384c0 8.8 7.2 16 16 16h384c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0zM0 128c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64z"/></svg>
    </a>
  
    
    
    
    
    <a href="/contact" target="_blank" rel="noopener" title="contact us" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 4H7a5 5 0 0 0-5 5v11h18a2 2 0 0 0 2-2V9a5 5 0 0 0-5-5m-7 14H4V9a3 3 0 0 1 3-3 3 3 0 0 1 3 3zm9-3h-2v-2h-4v-2h6zM9 11H5V9h4z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.prune", "content.action.edit", "content.code.copy", "content.code.annotate", "content.tabs.link", "content.tooltips", "header.autohide", "announce.dismiss", "search.suggest", "search.highlight", "search.share", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
<!-- Add scripts that need to run before here -->

      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
<!-- Add scripts that need to run afterwards here -->

  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>