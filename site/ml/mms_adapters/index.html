
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="FastDoc is a website that you can get started with FastX AI in minutes.">
      
      
      
        <link rel="canonical" href="https://doc.fastx-ai.com/ml/mms_adapters/">
      
      
        <link rel="prev" href="../ml-for-games-5/">
      
      
        <link rel="next" href="../moe/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>微调用于多语言 ASR 的 MMS 适配器模型 - FastDocs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="微调用于多语言 ASR 的 MMS 适配器模型 - FastDocs" >
      
        <meta  property="og:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  property="og:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/mms_adapters.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://doc.fastx-ai.com/ml/mms_adapters/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="微调用于多语言 ASR 的 MMS 适配器模型 - FastDocs" >
      
        <meta  name="twitter:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  name="twitter:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/mms_adapters.png" >
      
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#asr-mms" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
              </button>
            
            
<p style="text-align: center">
  Welcome to <span style="font-size: bold">FastDocs</span>! Just feel free to start read docs!
</p>

          </div>
          
            <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="FastDocs" class="md-header__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FastDocs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              微调用于多语言 ASR 的 MMS 适配器模型
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  主页

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../backend/" class="md-tabs__link">
        
  
    
  
  后端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../web/" class="md-tabs__link">
        
  
    
  
  前端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../client/" class="md-tabs__link">
        
  
    
  
  客户端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../pc/" class="md-tabs__link">
        
  
    
  
  桌面端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../big-data/" class="md-tabs__link">
        
  
    
  
  大数据

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_58_llm_extreme_quantization/" class="md-tabs__link">
          
  
    
  
  人工智能

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../ops/" class="md-tabs__link">
        
  
    
  
  运维

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  博客

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../resume/" class="md-tabs__link">
        
  
    
  
  简历模板

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="FastDocs" class="md-nav__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FastDocs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../backend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    后端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../web/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../client/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    客户端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    桌面端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../big-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大数据
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    人工智能
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            人工智能
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_58_llm_extreme_quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning LLMs to 1.58bit: extreme quantization made easy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2023-in-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023, 开源大模型之年
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3d-assets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手把手教你使用人工智能生成 3D 素材
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4bit-transformers-bitsandbytes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Llama2-for-non-engineers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非工程师指南：训练 LLaMA 2 聊天机器人
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Lora-for-sequence-classification-with-Roberta-Llama-Mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在灾难推文分析场景上比较用 LoRA 微调 Roberta、Llama 2 和 Mistral 的过程及表现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../_policy-ntia-rfc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能政策@🤗：回应美国国家电信和信息管理局（ NTIA ）关于人工智能问责制的评论请求
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerate-v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate 1.0.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerated-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何成功将 🤗 API 客户的 transformer 模型推理速度加快 100 倍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    授权调用：介绍 Transformers 智能体 2.0  
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aivsai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 大战 AI，一个深度强化学习多智能体竞赛系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../arena-tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS 擂台: 文本转语音模型的自由搏击场
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../asr-diarization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 推理终端搭建强大的“语音识别 + 说话人分割 + 投机解码”工作流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation-support-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    英特尔 Gaudi 加速辅助生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    辅助生成：低延迟文本生成的新方向
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audioldm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AudioLDM 2，加速⚡️！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer 模型能够有效地进行时间序列预测 (使用 Autoformer)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beating-gaia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers 代码智能体成功刷榜 GAIA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../big-bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解 BigBird 的块稀疏注意力
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BLIP-2 零样本“图生文”
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化故事: BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-pytorch-scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DeepSpeed 和 Accelerate 进行超快 BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-megatron-deepspeed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    千亿参数开源大模型 BLOOM 背后的技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Habana Gaudi2 加速视觉语言模型 BridgeTower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chat-templates/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天模板：无声性能杀手的终结
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-ai-expansion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中国 AI 出海现状概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-language-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中文博客正式发布！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cloudflare-workers-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为 Hugging Face 用户带来无服务器 GPU 推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codellama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Llama：Llama 2 学会写代码了！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../community-datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据好合：Argilla 和 Hugging Face Spaces 赋能社区合力构建更好的数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../constrained-beam-search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 🤗 Transformers 中使用约束波束搜索引导文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🧨 Diffusers 实现 ControlNet 高速推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cosmopedia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cosmopedia：如何为大语言模型预训练构建大规模合成数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cost-efficient-rag-applications-with-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用英特尔 Gaudi 2 和至强 CPU 构建经济高效的企业级 RAG 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cv_state/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中计算机视觉的现状
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../daily-papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 论文平台 Daily Papers 功能全解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dedup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCode 背后的大规模数据去重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep-learning-with-proteins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    蛋白质深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepspeed-to-fsdp-and-back/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 DeepSpeed 到 FSDP，再回到 Hugging Face Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-deepfloydif-using-bentoml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BentoML 部署 🤗 Hugging Face 上的模型：DeepFloyd IF 实战
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-with-openvino/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Optimum-Intel 和 OpenVINO GenAI 优化和部署模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dialog-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    是什么让对话代理有用？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffusers-turns-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Diffusers 一岁啦 !
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docmatix - 超大文档视觉问答数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../document-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加速 Document AI (文档智能) 发展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo-trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DPO 微调 Llama 2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo_vlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为视觉语言多模态模型进行偏好优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dreambooth/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Diffusers 通过 Dreambooth 技术来训练 Stable Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic_speculation_lookahead/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的辅助生成: 动态推测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../elixir-bumblebee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 GPT2 到 Stable Diffusion：Elixir 社区迎来了 Hugging Face
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用于显著提高检索速度和降低成本的二进制和标量嵌入量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encoder-decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Transformers 的编码器-解码器模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encrypted-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 FHE 实现加密大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开发 Diffusers 库的道德行为指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    道德与社会问题简报 #3: Hugging Face 上的道德开放性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ethics and Society Newsletter #4: Bias in Text-to-Image Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon-180b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 180B 登陆 Hugging Face Hub 🔥
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 登陆 Hugging Face 生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falconmamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon Mamba: 首个高效的无注意力机制 7B 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-tune-whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 为多语种语音识别任务微调 Whisper 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    揭秘 FineVideo 数据集构建的背后的秘密
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune-florence2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调 Florence-2 - 微软的尖端视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../game-jam-first-edition-results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首届开源 AI 游戏挑战赛事结果
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gaussian-splatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3D 高斯点染简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-july-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 最新发布： Gemma 2 2B, ShieldGemma 和 Gemma Scope
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 微调 Gemma 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Gemma: Google 最新推出开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 发布最新开放大语言模型 Gemma 2，现已登陆 Hugging Face Hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generative-ai-models-on-intel-cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    越小越好：Q8-Chat，在英特尔至强 CPU 上体验高效的生成式 AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started-habana/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Habana Gaudi 的 Transformers 入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../google-cloud-model-garden/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Google Cloud 上轻松部署开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptq-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 AutoGPTQ 和 transformers 让大语言模型更轻量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio 5 现已发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-lite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio-Lite: 完全在浏览器里运行的无服务器 Gradio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-reload/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Gradio 的“热重载”模式快速开发 AI 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphml-classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Transformers 进行图分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-benchmark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的训练和推理：对比 Habana Gaudi®2 和英伟达 A100 80GB
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型快速推理：在 Habana Gaudi2 上推理 BLOOMZ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hf-bitsandbytes-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模 Transformer 模型 8 比特矩阵乘简介 - 基于 Hugging Face Transformers、Accelerate 以及 bitsandbytes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../how-to-generate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何生成文本：通过 Transformers 用不同的解码方法生成文本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hugging-face-wiz-security-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 Wiz Research 合作提高人工智能安全性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../huggy-lingo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Huggy Lingo：利用机器学习改进 Hugging Face Hub 上的语言元数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IDEFICS 简介：最先进视觉语言模型的开源复现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Idefics2 简介：为社区而生的强大 8B 视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在免费版 Google Colab 上使用 🧨 diffusers 运行 IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../image-similarity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Hugging Face Datasets 和 Transformers 的图像相似性搜索
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-endpoints-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Hugging Face 推理端点部署 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 提供的推理（Inference）解决方案
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infini-attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一次失败的实验——无限注意力，我们为什么坚持实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../informer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Informer 进行多元概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../instruction-tuning-sd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 InstructPix2Pix 对 Stable Diffusion 进行指令微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-fast-embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用 🤗 Optimum Intel 和 fastRAG 在 CPU 上优化文本嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-protein-language-model-protst/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 Gaudi 2 上加速蛋白质语言模型 ProtST
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 推理 | 使用英特尔 Sapphire Rapids 加速 PyTorch Transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用英特尔 Sapphire Rapids 加速 PyTorch Transformers 模型（第一部分）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-starcoder-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Optimum Intel 在英特尔至强上加速 StarCoder：Q8/Q4 及投机解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intro-graphml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一文带你入门图机器学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introducing-csearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Transformers 中使用对比搜索生成可媲美人类水平的文本🤗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-to-ggml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ggml 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    万事通，专精部分领域的多功能 Transformer 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kv-cache-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 KV 缓存量化解锁长文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face x LangChain：全新 LangChain 合作伙伴包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../large-language-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型：新的摩尔定律？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lcm_lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LCM LoRA 4 步完成 SDXL 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-bigcodebench/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCodeBench: 继 HumanEval 之后的新一代代码生成基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-decodingtrust/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    来自 AI Secure 实验室的 LLM 安全排行榜简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-medicalllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源医疗大模型排行榜：健康领域大模型基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-patronus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    企业场景排行榜简介：现实世界用例排行榜
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 2 来袭 - 在 Hugging Face 上玩转它
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Llama 3：Meta 的新一代开源大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 3.1：405B/70B/8B 模型的多语言与长上下文能力解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    现在 Llama 具备视觉能力并可以在你的设备上运行 - 欢迎使用 Llama 3.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../long-range-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    长程 transformer 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LoRA 进行 Stable Diffusion 的高效参数微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mask2former/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用图像分割任务：使用 Mask2Former 和 OneFormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matryoshka/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🪆 俄罗斯套娃嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何使用 Megatron-LM 训练语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Mixtral - 当前 Hugging Face 上最先进的 MoE 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于AI进行游戏开发：5天！创建一个农场游戏！第1部分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ChatGPT 启发游戏创意｜基于 AI 5 天创建一个农场游戏，第 2 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 制作 3D 素材｜基于 AI 5 天创建一个农场游戏，第 3 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    制作 2D 素材｜基于 AI 5 天创建一个农场游戏，第 4 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 设计游戏剧情 | 基于 AI 5 天创建一个农场游戏，完结篇！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    微调用于多语言 ASR 的 MMS 适配器模型
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    微调用于多语言 ASR 的 MMS 适配器模型
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      保护世界语言多样性
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mms" class="md-nav__link">
    <span class="md-ellipsis">
      微调 MMS
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      训练自适应权重
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#notebook" class="md-nav__link">
    <span class="md-ellipsis">
      Notebook 设置
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      准备数据、分词器、特征提取器
    </span>
  </a>
  
    <nav class="md-nav" aria-label="准备数据、分词器、特征提取器">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#wav2vec2ctctokenizer" class="md-nav__link">
    <span class="md-ellipsis">
      创建 Wav2Vec2CTCTokenizer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#wav2vec2featureextractor" class="md-nav__link">
    <span class="md-ellipsis">
      创建 Wav2Vec2FeatureExtractor
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      预处理数据
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      训练
    </span>
  </a>
  
    <nav class="md-nav" aria-label="训练">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#trainer" class="md-nav__link">
    <span class="md-ellipsis">
      设置 Trainer
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      训练
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合专家模型（MoE）详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-lora-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 多-LoRA：部署一次，搞定 30 个模型的推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../noob_intro_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face Transformers 萌新完全指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-drop/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开放 LLM 排行榜：深入研究 DROP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-mmlu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open LLM 排行榜近况
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础大模型能像人类一样标注数据吗？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-source-llms-as-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源大语言模型作为 LangChain 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimize-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向生产的 LLM 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizing-bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 优化 Bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimum-onnxruntime-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimum + ONNX Runtime: 更容易、更快地训练你的 Hugging Face 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../os-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 的文本生成和大语言模型的开源生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview-quantization-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Transformers 中原生支持的量化方案概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../packing-with-FA2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过打包 Flash Attention 来提升 Hugging Face 训练效率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../paligemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PaliGemma 正式发布 — Google 最新发布的前沿开放视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../password-git-deprecation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hub 上的 Git 操作不再支持使用密码验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 PEFT：在低资源硬件上对十亿规模模型进行参数高效微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../personal-copilot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    个人编程助手：训练你自己的编码助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi2-intel-meteor-lake/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    笔记本电脑上的聊天机器人：在英特尔 Meteor Lake 上运行 Phi-2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../presidio-pii-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hub 上使用 Presidio 进行自动 PII 检测实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../putting_rl_back_in_rlhf_with_rloo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将强化学习重新引入 RLHF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pycharm-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 PyCharm 深度集成：轻松引入丰富的 AI 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-ddp-accelerate-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 PyTorch DDP 到 Accelerate 到 Trainer，轻松掌握分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 完全分片数据并行技术加速大模型训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Quanto 和 Diffusers 的内存高效 transformer 扩散模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quanto：PyTorch 量化工具包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ram-efficient-pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch FSDP 微调 Llama 2 70B
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../red-teaming/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为大语言模型建立红队对抗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reformer 模型 - 突破语言建模的极限
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HF Hub 现已加入存储区域功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../researcher-dataset-sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hugging Face Hub 分享你的开源数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 背后的“功臣”——RLHF 技术详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RWKV -- transformer 与 RNN 的强强联合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ryght-case-study/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ryght 在 Hugging Face 专家助力下赋能医疗保健和生命科学之旅
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../safecoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    推介 SafeCoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sc2-instruct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3.5 Large 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd_distillation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源 SD-Small 和 SD-Tiny 知识蒸馏代码与权重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sdxl_lora_advanced_script/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    全世界 LoRA 训练脚本，联合起来!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-absa/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFitABSA：基于 SetFit 的少样本、方面级情感分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-optimum-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔至强 CPU 上使用 🤗 Optimum Intel 实现超快 SetFit 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFit: 高效的无提示少样本学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../smollm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SmolLM：一个超快速、超高性能的小模型集合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speecht5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 SpeechT5 进行语音合成、识别和更多功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sql-console/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为数据集而生的 SQL 控制台
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-finetuning-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-inference-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上加速 Stable Diffusion 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用Diffusers来实现Stable Diffusion 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stackllama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    “StackLLaMA”: 用 RLHF 训练 LLaMA 的手把手教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starchat-alpha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 StarCoder 创建一个编程助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder：最先进的代码大模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2 及 The Stack v2 数据集正式发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthetic-data-save-costs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    合成数据：利用开源技术节约资金、时间和减少碳排放
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthid-text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SynthID Text：在 AI 生成文本中应用不可见水印的新技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t2i-sdxl-adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 SDXL 上用 T2I-Adapter 实现高效可控的文生图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text-to-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解文生视频模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../textgen-pipe-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于英特尔® Gaudi® 2 AI 加速器的文本生成流水线
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tgi-benchmarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the-age-of-ml-as-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    机器学习即代码的时代已经到来
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the_n_implementation_details_of_rlhf_with_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PPO 算法进行 RLHF 的 N 步实现细节
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../time-series-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 进行概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-dgx-cloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 NVIDIA DGX Cloud上使用 H100 GPU 轻松训练模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-optimize-sd-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 NNCF 和 🤗 Optimum 面向 Intel CPU 对 Stable Diffusion 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-sentence-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Sentence Transformers v3 训练和微调嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-your-controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 diffusers 训练你自己的 ControlNet 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers-design-philosophy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    〜不要〜重复自己
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-ddpo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DDPO 在 TRL 中微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trufflesecurity-partnership/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 TruffleHog 成为合作伙伴，实现风险信息预警
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unified-tool-use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对 LLM 工具使用进行统一
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何安装和使用 Hugging Face Unity API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 Unity 游戏中集成 AI 语音识别？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-in-spaces/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 🤗 Space 上托管 Unity 游戏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../universal_assisted_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用辅助生成：使用任意辅助模型加速解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vertex-colored-to-textured-mesh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    顶点着色网格转换为 UV 映射的纹理化网格
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_language_pretraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入了解视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit-align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kakao Brain 的开源 ViT、ALIGN 和 COYO 文字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vlms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    视觉语言模型详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../watermarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能水印技术入门：工具与技巧
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper-speculative-decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用推测解码使 Whisper 实现 2 倍的推理加速
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../winning-aimo-progress-prize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NuminaMath 是如何荣膺首届 AIMO 进步奖的？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xethub-joins-hf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XetHub 加入 Hugging Face!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../zero-shot-vqa-docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LAVE：使用 LLM 对 Docmatix 进行零样本 VQA 评估 - 我们还需要微调吗？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运维
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../blog/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    博客
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../resume/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简历模板
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/C-L-STARK/C-L-STARK.github.io/edit/master/docs/ml/mms_adapters.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2zm-2.3 6.35c.22-.21.22-.56 0-.77L15.42 7.3a.53.53 0 0 0-.77 0l-1 1 2.05 2.05zM7 14.94V17h2.06l6.06-6.06-2.06-2.06z"/></svg>
    </a>
  
  


<h1 id="asr-mms"><strong>微调用于多语言 ASR 的 MMS 适配器模型</strong><a class="headerlink" href="#asr-mms" title="Permanent link">&para;</a></h1>
<p><a target="_blank" href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Fine_Tune_MMS_on_Common_Voice.ipynb">
    <a class="glightbox" href="https://colab.research.google.com/assets/colab-badge.svg" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
</a></p>
<p><strong>新内容 (06/2023)</strong>: 这篇博文受到 <a href="https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2">“在多语言 ASR 上微调 XLS-R”</a> 的强烈启发，可以看作是它的改进版本。</p>
<p><strong>Wav2Vec2</strong> 是自动语音识别 (ASR) 的预训练模型，由 <em>Alexei Baevski、Michael Auli</em> 和 <em>Alex Conneau</em> 于 <a href="https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/">2020 年 9 月</a> 发布。其在最流行的 ASR 英语数据集之一 <a href="https://huggingface.co/datasets/librispeech_asr">LibriSpeech</a> 上展示了 Wav2Vec2 的强大性能后不久， <em>Facebook AI</em> 就推出了 Wav2Vec2 的两个多语言版本，称为 <a href="https://arxiv.org/abs/2006.13979">XLSR</a> 和 <a href="https://ai.facebook.com/blog/-xlm-r-state-of-the-art-cross-lingual-understanding-through-self-supervision/">XLM-R</a>，能够识别多达 128 种语言的语音。XLSR 代表 <em>跨语言语音表示</em> ，指的是模型学习跨多种语言有用的语音表示的能力。</p>
<p>Meta AI 的最新版本，<a href="https://ai.facebook.com/blog/multilingual-model-speech-recognition/"><strong>大规模多语言语音 (MMS)</strong></a>，由 <em>Vineel Pratap、Andros Tjandra、Bowen Shi</em> 等人编写。将多语言语音表示提升到一个新的水平。通过发布的各种 <a href="https://huggingface.co/models?other=mms">语言识别、语音识别和文本转语音检查点</a>，可以识别、转录和生成超过 1,100 多种口语。</p>
<p>在这篇博文中，我们展示了 MMS 的适配器训练如何在短短 10-20 分钟的微调后实现惊人的低单词错误率。</p>
<p>对于资源匮乏的语言，我们 <strong>强烈</strong> 建议使用 MMS 的适配器训练，而不是像 <a href="https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2">“在多语言 ASR 上微调 XLS-R”</a> 中那样微调整个模型。</p>
<p>在我们的实验中，MMS 的适配器训练不仅内存效率更高、更稳健，而且对于低资源语言也能产生更好的性能。对于中到高资源语言，微调整个检查点而不是使用适配器层仍然是有利的。</p>
<p><a class="glightbox" href="/blog/assets/151_mms/mms_map.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="wav2vec2_structure" src="/blog/assets/151_mms/mms_map.png" /></a></p>
<h2 id="_1"><strong>保护世界语言多样性</strong><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>根据 https://www.ethnologue.com/ 的数据，大约 3000 种语言 (即所有“现存”语言的 40%) 由于母语人士越来越少而濒临灭绝。这种趋势只会在日益全球化的世界中持续下去。</p>
<p><strong>MMS</strong> 能够转录许多濒临灭绝的语言，例如 <em>Ari</em> 或 <em>Kaivi</em> 。未来，MMS 可以通过帮助剩余的使用者创建书面记录并用母语进行交流，这在保持语言活力方面发挥至关重要的作用。</p>
<p>为了适应 1000 多个不同的词汇表，<strong>MMS</strong> 使用适配器 (Adapters) - 一种仅训练一小部分模型权重的训练方法。</p>
<p>适配器层就像语言桥梁一样，使模型能够在解读另一种语言时利用一种语言的知识。</p>
<h2 id="mms"><strong>微调 MMS</strong><a class="headerlink" href="#mms" title="Permanent link">&para;</a></h2>
<p><strong>MMS</strong> 无监督检查点使用 <strong>1,400</strong> 多种语言的超过 <strong>50 万</strong> 小时的音频进行了预训练，参数范围从 3 亿到 10 亿不等。</p>
<p>你可以在 🤗 Hub 上找到 3 亿个参数 (300M) 和 10 亿个参数 (1B) 模型大小的仅预训练检查点:</p>
<ul>
<li><a href="https://huggingface.co/facebook/mms-300m"><strong><code>mms-300m</code></strong></a></li>
<li><a href="https://huggingface.co/facebook/mms-1b"><strong><code>mms-1b</code></strong></a></li>
</ul>
<p><em>注意</em> : 如果你想微调基本模型，可以按照 <a href="https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2">“在多语言 ASR 上微调 XLS-R”</a> 中所示的完全相同的方式进行操作。</p>
<p>与 <a href="http://jalammar.github.io/illustrated-bert/">BERT 的掩码语言建模目标</a> 类似，MMS 通过随机遮蔽特征向量来学习上下文语音表示，然后在自监督预训练期间将其传递到 Transformer 网络。</p>
<p>对于 ASR，预训练 <a href="https://huggingface.co/facebook/mms-1b">MMS-1B 检查点</a> 通过联合词汇输出层以监督方式对 1000 多种语言进行了进一步微调。最后一步，联合词汇输出层被丢弃，并保留特定于语言的适配器层。每个适配器层 <strong>仅</strong> 包含约 2.5M 权重，由每个注意力块的小型线性投影层以及特定于语言的词汇输出层组成。</p>
<p>已发布针对语音识别 (ASR) 进行微调的三个 <strong>MMS</strong> 检查点。它们分别包括 102、1107 和 1162 个适配器权重 (每种语言一个):</p>
<ul>
<li><a href="https://huggingface.co/facebook/mms-1b-fl102"><strong><code>mms-1b-fl102</code></strong></a></li>
<li><a href="https://huggingface.co/facebook/mms-1b-l1107"><strong><code>mms-1b-l1107</code></strong></a></li>
<li><a href="https://huggingface.co/facebook/mms-1b-all"><strong><code>mms-1b-all</code></strong></a></li>
</ul>
<p>你可以看到基本模型 (像往常一样) 保存为文件 <a href="https://huggingface.co/facebook/mms-1b-all/blob/main/model.safetensors"><code>model.safetensors</code></a>，但此外这些存储库还存储了许多适配器权重， <em>例如</em> 针对法国的 <a href="https://huggingface.co/facebook/mms-1b-all/blob/main/adapter.fra.safetensors"><code>adapter.fra.safetensors</code></a>。</p>
<p>Hugging Face 文档很好地 <a href="https://huggingface.co/docs/transformers/main/en/model_doc/mms#loading">解释了如何使用此类检查点进行推理</a>，因此在这篇博文中，我们将重点学习如何基于任何已发布的 ASR 检查点有效地训练高性能适配器模型。</p>
<h2 id="_2">训练自适应权重<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>在机器学习中，适配器是一种用于微调预训练模型同时保持原始模型参数不变的方法。他们通过在模型的现有层之间插入小型可训练模块 (称为 <a href="https://arxiv.org/pdf/1902.00751.pdf">适配器层</a>) 来实现此目的，然后使模型适应特定任务，而无需进行大量的重新训练。</p>
<p>适配器在语音识别，尤其是 <strong>说话人识别</strong> 方面有着悠久的历史。在说话人识别中，适配器已被有效地用于调整预先存在的模型，以识别单个说话人的特质，正如 <a href="https://www.isca-speech.org/archive_v0/archive_papers/icslp_1996/i96_1832.pdf">Gales 和 Woodland (1996)</a> 以及 <a href="https://www.cs.cmu.edu/~ymiao/pub/tasl_sat.pdf">Miao 等人 (2014)</a> 的工作中所强调的那样。与训练完整模型相比，这种方法不仅大大降低了计算要求，而且使得特定于说话者的调整更好、更灵活。</p>
<p><strong>MMS</strong> 中完成的工作利用了跨不同语言的语音识别适配器的想法。对少量适配器权重进行了微调，以掌握每种目标语言独特的语音和语法特征。因此，MMS 使单个大型基础模型 (<em>例如</em> <a href="https://huggingface.co/facebook/mms-1b-all"><strong>mms-1b-all</strong></a> 模型检查点) 和 1000 多个小型适配器层 (每个 2.5M 权重 <strong>mms-1b-all</strong>) 能够理解和转录多种语言。这极大地减少了为每种语言开发不同模型的计算需求。</p>
<p>棒极了！现在我们了解其动机和理论，下面让我们研究一下 <strong>mms-1b-all</strong> 🔥的适配器权重微调</p>
<h2 id="notebook">Notebook 设置<a class="headerlink" href="#notebook" title="Permanent link">&para;</a></h2>
<p>正如之前在 <a href="https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2">“多语言 ASR 上微调 XLS-R”</a> 博客文章中所做的那样，我们在 <a href="https://huggingface.co/datasets/common_voice">Common Voice</a> 的低资源 ASR 数据集上微调模型，该数据集仅包含 <em>ca.</em> 4 小时经过验证的训练数据。</p>
<p>就像 Wav2Vec2 或 XLS-R 一样，MMS 使用连接时序分类 (CTC) 进行微调，CTC 是一种用于训练神经网络解决序列到序列问题 (例如 ASR 和手写识别) 的算法。</p>
<p>有关 CTC 算法的更多详细信息，我强烈建议阅读 Awni Hannun 的写得很好的一篇博客文章 <a href="https://distill.pub/2017/ctc/"><em>Sequence Modeling with CTC (2017)</em></a>。</p>
<p>在我们开始之前，让我们安装 <code>datasets</code> 和 <code>transformers</code>。此外，我们需要 <code>torchaudio</code> 来加载音频文件，以及使用 <a href="https://huggingface.co/metrics/wer">字错误率 (WER)</a> 指标 <span class="arithmatex">\( {}^1 \)</span> 评估我们微调后的模型，因此也需要安装 <code>jiwer</code>。</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>%%capture
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>!pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>pip
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a>!pip<span class="w"> </span>install<span class="w"> </span>datasets<span class="o">[</span>audio<span class="o">]</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a>!pip<span class="w"> </span>install<span class="w"> </span>evaluate
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a>!pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/huggingface/transformers.git
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>!pip<span class="w"> </span>install<span class="w"> </span>jiwer
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>!pip<span class="w"> </span>install<span class="w"> </span>accelerate
</span></code></pre></div>
<p>我们强烈建议你在训练时将训练检查点直接上传到 <a href="https://huggingface.co/">🤗 Hub</a>。Hub 存储库内置了版本控制，因此你可以确保在训练期间不会丢失任何模型检查点。</p>
<p>为此，你必须存储来自 Hugging Face 网站的身份验证令牌 (如果你还没有注册，请在 <a href="https://huggingface.co/join">此处</a> 注册！)</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span> <span class="nn">huggingface_hub</span> <span class="kn">import</span> <span class="n">notebook_login</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">notebook_login</span><span class="p">()</span>
</span></code></pre></div>
<h2 id="_3">准备数据、分词器、特征提取器<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>ASR 模型将语音转录为文本，这意味着我们需要一个将语音信号处理为模型输入格式 (例如特征向量) 的特征提取器，以及一个将模型输出格式处理为文本的分词器。</p>
<p>在🤗 Transformers 中，MMS 模型同时伴随着一个名为 <a href="https://huggingface.co/transformers/master/model_doc/wav2vec2.html#wav2vec2featureextractor">Wav2Vec2FeatureExtractor</a> 的特征提取器和一个名为 <a href="https://huggingface.co/transformers/master/model_doc/wav2vec2.html#wav2vec2ctctokenizer">Wav2Vec2CTCTokenizer</a> 的分词器。</p>
<p>我们首先创建标记生成器，将预测的输出类解码为输出转录。</p>
<h3 id="wav2vec2ctctokenizer">创建 <code>Wav2Vec2CTCTokenizer</code><a class="headerlink" href="#wav2vec2ctctokenizer" title="Permanent link">&para;</a></h3>
<p>微调的 MMS 模型，例如 <a href="https://huggingface.co/facebook/mms-1b-all"><strong>mms-1b-all</strong></a> 已经有一个伴随模型检查点的 <a href="https://huggingface.co/facebook/mms-1b-all/blob/main/tokenizer_config.json">分词器</a>。然而，由于我们想要在某种语言的特定低资源数据上微调模型，因此建议完全删除分词器和词汇输出层，并根据训练数据本身创建新的。</p>
<p>在 CTC 上微调的类似 Wav2Vec2 的模型通过一次前向传递来转录音频文件，首先将音频输入处理为一系列经过处理的上下文表示，然后使用最终的词汇输出层将每个上下文表示分类为表示该字符的字符转录。</p>
<p>该层的输出大小对应于词汇表中的标记数量，我们将从用于微调的标记数据集中提取该词汇表。因此，第一步，我们将查看所选的 Common Voice 数据集，并根据转录定义词汇表。</p>
<p>对于本 notebook，我们将使用 <a href="https://huggingface.co/datasets/mozilla-foundation/common_voice_6_1">Common Voice</a> 的 6.1 土耳其语数据集。土耳其语对应于语言代码 <code>"tr"</code>。</p>
<p>太好了，现在我们可以使用 🤗 Datasets 的简单 API 来下载数据了。数据集名称是 <code>"mozilla-foundation/common_voice_6_1"</code>，配置名称对应于语言代码，在我们的例子中是 <code>"tr"</code>。</p>
<p><strong>注意</strong>: 在下载数据集之前，你必须登录你的 Hugging Face 帐户，进入 <a href="https://huggingface.co/datasets/mozilla-foundation/common_voice_6_1">数据集存储库页</a> 面并单击“同意并访问存储库”来访问它</p>
<p>Common Voice 有许多不同的分割，其中包括 <code>invalidated</code>，它指的是未被评为“足够干净”而被认为有用的数据。在此 notebook 中，我们将仅使用拆分的 <code>"train"</code>, <code>"validation"</code> 和 <code>"test"</code> 。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">load_dataset</span><span class="p">,</span> <span class="n">load_metric</span><span class="p">,</span> <span class="n">Audio</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">common_voice_train</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mozilla-foundation/common_voice_6_1&quot;</span><span class="p">,</span> <span class="s2">&quot;tr&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train+validation&quot;</span><span class="p">,</span> <span class="n">use_auth_token</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="n">common_voice_test</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mozilla-foundation/common_voice_6_1&quot;</span><span class="p">,</span> <span class="s2">&quot;tr&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">use_auth_token</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>许多 ASR 数据集仅提供每个音频数组 (<code>'audio'</code>) 和文件 (<code>'path'</code>) 的目标文本 (<code>'sentence'</code>)。实际上，Common Voice 提供了关于每个音频文件的更多信息，例如 <code>'accent'</code> 等。为了使 notebook 尽可能通用，我们仅考虑用于微调的转录文本。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="n">common_voice_train</span> <span class="o">=</span> <span class="n">common_voice_train</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;accent&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;client_id&quot;</span><span class="p">,</span> <span class="s2">&quot;down_votes&quot;</span><span class="p">,</span> <span class="s2">&quot;gender&quot;</span><span class="p">,</span> <span class="s2">&quot;locale&quot;</span><span class="p">,</span> <span class="s2">&quot;segment&quot;</span><span class="p">,</span> <span class="s2">&quot;up_votes&quot;</span><span class="p">])</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="n">common_voice_test</span> <span class="o">=</span> <span class="n">common_voice_test</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;accent&quot;</span><span class="p">,</span> <span class="s2">&quot;age&quot;</span><span class="p">,</span> <span class="s2">&quot;client_id&quot;</span><span class="p">,</span> <span class="s2">&quot;down_votes&quot;</span><span class="p">,</span> <span class="s2">&quot;gender&quot;</span><span class="p">,</span> <span class="s2">&quot;locale&quot;</span><span class="p">,</span> <span class="s2">&quot;segment&quot;</span><span class="p">,</span> <span class="s2">&quot;up_votes&quot;</span><span class="p">])</span>
</span></code></pre></div>
<p>让我们编写一个简短的函数来显示数据集的一些随机样本，并运行它几次以了解转录的感觉。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">ClassLabel</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="kn">import</span> <span class="nn">random</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="k">def</span> <span class="nf">show_random_elements</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">num_examples</span><span class="o">=</span><span class="mi">10</span><span class="p">):</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a>    <span class="k">assert</span> <span class="n">num_examples</span> <span class="o">&lt;=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">),</span> <span class="s2">&quot;Can&#39;t pick more elements than there are in the dataset.&quot;</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a>    <span class="n">picks</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_examples</span><span class="p">):</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a>        <span class="n">pick</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a>        <span class="k">while</span> <span class="n">pick</span> <span class="ow">in</span> <span class="n">picks</span><span class="p">:</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a>            <span class="n">pick</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>        <span class="n">picks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pick</span><span class="p">)</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="n">picks</span><span class="p">])</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>    <span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">to_html</span><span class="p">()))</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="n">show_random_elements</span><span class="p">(</span><span class="n">common_voice_train</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;path&quot;</span><span class="p">,</span> <span class="s2">&quot;audio&quot;</span><span class="p">]),</span> <span class="n">num_examples</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>Oylar<span class="w"> </span>teker<span class="w"> </span>teker<span class="w"> </span>elle<span class="w"> </span>sayılacak.
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>Son<span class="w"> </span>olaylar<span class="w"> </span>endişe<span class="w"> </span>seviyesini<span class="w"> </span>yükseltti.
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a>Tek<span class="w"> </span>bir<span class="w"> </span>kart<span class="w"> </span>hepsinin<span class="w"> </span>kapılarını<span class="w"> </span>açıyor.
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>Blogcular<span class="w"> </span>da<span class="w"> </span>tam<span class="w"> </span>bundan<span class="w"> </span>bahsetmek<span class="w"> </span>istiyor.
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a>Bu<span class="w"> </span>Aralık<span class="w"> </span>iki<span class="w"> </span>bin<span class="w"> </span>onda<span class="w"> </span>oldu.
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a>Fiyatın<span class="w"> </span>altmış<span class="w"> </span>altı<span class="w"> </span>milyon<span class="w"> </span>avro<span class="w"> </span>olduğu<span class="w"> </span>bildirildi.
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a>Ardından<span class="w"> </span>da<span class="w"> </span>silahlı<span class="w"> </span>çatışmalar<span class="w"> </span>çıktı.
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="s2">&quot;Romanya&#39;da kurumlar gelir vergisi oranı yüzde on altı.&quot;</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a>Bu<span class="w"> </span>konuda<span class="w"> </span>neden<span class="w"> </span>bu<span class="w"> </span>kadar<span class="w"> </span>az<span class="w"> </span>şey<span class="w"> </span>söylendiğini<span class="w"> </span>açıklayabilir<span class="w"> </span>misiniz?
</span></code></pre></div>
<p>好吧！转录看起来相当干净。翻译完转录的句子后，这种语言似乎更多地对应于书面文本，而不是嘈杂的对话。考虑到 <a href="https://huggingface.co/datasets/common_voice">Common Voice</a> 是一个众包阅读语音语料库，这也解释的通。</p>
<p>我们可以看到，转录文本中包含一些特殊字符，如 <code>,.?!;:</code>。没有语言模型，要将语音块分类为这些特殊字符就更难了，因为它们并不真正对应于一个特征性的声音单元。例如，字母 <code>"s"</code> 有一个或多或少清晰的声音，而特殊字符 <code>"."</code> 则没有。此外，为了理解语音信号的含义，通常不需要在转录中包含特殊字符。</p>
<p>让我们简单地删除所有对单词的含义没有贡献并且不能真正用声音表示的字符，并对文本进行规范化。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">import</span> <span class="nn">re</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="n">chars_to_remove_regex</span> <span class="o">=</span> <span class="s1">&#39;[\,\?\.\!\-\;\:</span><span class="se">\&quot;</span><span class="s1">\“\%\‘\”\�</span><span class="se">\&#39;</span><span class="s1">]&#39;</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="k">def</span> <span class="nf">remove_special_characters</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">chars_to_remove_regex</span><span class="p">,</span> <span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>    <span class="k">return</span> <span class="n">batch</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="n">common_voice_train</span> <span class="o">=</span> <span class="n">common_voice_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">remove_special_characters</span><span class="p">)</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a><span class="n">common_voice_test</span> <span class="o">=</span> <span class="n">common_voice_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">remove_special_characters</span><span class="p">)</span>
</span></code></pre></div>
<p>我们再看看处理后的文本标签。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="n">show_random_elements</span><span class="p">(</span><span class="n">common_voice_train</span><span class="o">.</span><span class="n">remove_columns</span><span class="p">([</span><span class="s2">&quot;path&quot;</span><span class="p">,</span><span class="s2">&quot;audio&quot;</span><span class="p">]))</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a>i̇kinci<span class="w"> </span>tur<span class="w"> </span>müzakereler<span class="w"> </span>eylül<span class="w"> </span>ayında<span class="w"> </span>başlayacak
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a>jani<span class="w"> </span>ve<span class="w"> </span>babası<span class="w"> </span>bu<span class="w"> </span>düşüncelerinde<span class="w"> </span>yalnız<span class="w"> </span>değil
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a>onurun<span class="w"> </span>gözlerindeki<span class="w"> </span>büyü
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a>bandiç<span class="w"> </span>oyların<span class="w"> </span>yüzde<span class="w"> </span>kırk<span class="w"> </span>sekiz<span class="w"> </span>virgül<span class="w"> </span>elli<span class="w"> </span>dördünü<span class="w"> </span>topladı
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a>bu<span class="w"> </span>imkansız
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a>bu<span class="w"> </span>konu<span class="w"> </span>açık<span class="w"> </span>değildir
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a>cinayet<span class="w"> </span>kamuoyunu<span class="w"> </span>şiddetle<span class="w"> </span>sarstı
</span><span id="__span-10-8"><a id="__codelineno-10-8" name="__codelineno-10-8" href="#__codelineno-10-8"></a>kentin<span class="w"> </span>sokakları<span class="w"> </span>iki<span class="w"> </span>metre<span class="w"> </span>su<span class="w"> </span>altında<span class="w"> </span>kaldı
</span><span id="__span-10-9"><a id="__codelineno-10-9" name="__codelineno-10-9" href="#__codelineno-10-9"></a>muhalefet<span class="w"> </span>partileri<span class="w"> </span>hükümete<span class="w"> </span>karşı<span class="w"> </span>ciddi<span class="w"> </span>bir<span class="w"> </span>mücadele<span class="w"> </span>ortaya<span class="w"> </span>koyabiliyorlar<span class="w"> </span>mı
</span><span id="__span-10-10"><a id="__codelineno-10-10" name="__codelineno-10-10" href="#__codelineno-10-10"></a>festivale<span class="w"> </span>tüm<span class="w"> </span>dünyadan<span class="w"> </span>elli<span class="w"> </span>film<span class="w"> </span>katılıyor
</span></code></pre></div>
<p>好！这看起来更好了。我们已经从转录中删除了大多数特殊字符，并将它们规范化为仅小写。</p>
<p>在完成预处理之前，咨询目标语言的母语人士总是有益的，以查看文本是否可以进一步简化。
对于这篇博客文章，<a href="https://twitter.com/mervenoyann">Merve</a> 很友好地快速查看了一下，并指出带帽子的字符 (如 <code>â</code>) 在土耳其语中已经不再使用，可以用它们的无帽子等效物 (例如 <code>a</code>) 替换。</p>
<p>这意味着我们应该将像 <code>"yargı sistemi hâlâ sağlıksız"</code> 这样的句子替换为 <code>"yargı sistemi hala sağlıksız"</code>。</p>
<p>让我们再写一个简短的映射函数来进一步简化文本标签。记住 - 文本标签越简单，模型学习预测这些标签就越容易。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-11-1"><a id="__codelineno-11-1" name="__codelineno-11-1" href="#__codelineno-11-1"></a><span class="k">def</span> <span class="nf">replace_hatted_characters</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="__span-11-2"><a id="__codelineno-11-2" name="__codelineno-11-2" href="#__codelineno-11-2"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[â]&#39;</span><span class="p">,</span> <span class="s1">&#39;a&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span>
</span><span id="__span-11-3"><a id="__codelineno-11-3" name="__codelineno-11-3" href="#__codelineno-11-3"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[î]&#39;</span><span class="p">,</span> <span class="s1">&#39;i&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span>
</span><span id="__span-11-4"><a id="__codelineno-11-4" name="__codelineno-11-4" href="#__codelineno-11-4"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[ô]&#39;</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span>
</span><span id="__span-11-5"><a id="__codelineno-11-5" name="__codelineno-11-5" href="#__codelineno-11-5"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[û]&#39;</span><span class="p">,</span> <span class="s1">&#39;u&#39;</span><span class="p">,</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span>
</span><span id="__span-11-6"><a id="__codelineno-11-6" name="__codelineno-11-6" href="#__codelineno-11-6"></a>    <span class="k">return</span> <span class="n">batch</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-12-1"><a id="__codelineno-12-1" name="__codelineno-12-1" href="#__codelineno-12-1"></a><span class="n">common_voice_train</span> <span class="o">=</span> <span class="n">common_voice_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">replace_hatted_characters</span><span class="p">)</span>
</span><span id="__span-12-2"><a id="__codelineno-12-2" name="__codelineno-12-2" href="#__codelineno-12-2"></a><span class="n">common_voice_test</span> <span class="o">=</span> <span class="n">common_voice_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">replace_hatted_characters</span><span class="p">)</span>
</span></code></pre></div>
<p>在 CTC 中，将语音块分类为字母是很常见的，所以我们在这里也做同样的事情。让我们提取训练和测试数据中所有不同的字母，并从这组字母中构建我们的词汇表。</p>
<p>我们编写一个映射函数，将所有转录连接成一个长转录，然后将字符串转换为一组字符。将参数传递 <code>batched=True</code> 给 <code>map(...)</code> 函数非常重要，以便映射函数可以立即访问所有转录。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-13-1"><a id="__codelineno-13-1" name="__codelineno-13-1" href="#__codelineno-13-1"></a><span class="k">def</span> <span class="nf">extract_all_chars</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="__span-13-2"><a id="__codelineno-13-2" name="__codelineno-13-2" href="#__codelineno-13-2"></a>  <span class="n">all_text</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span>
</span><span id="__span-13-3"><a id="__codelineno-13-3" name="__codelineno-13-3" href="#__codelineno-13-3"></a>  <span class="n">vocab</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">all_text</span><span class="p">))</span>
</span><span id="__span-13-4"><a id="__codelineno-13-4" name="__codelineno-13-4" href="#__codelineno-13-4"></a>  <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;vocab&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">vocab</span><span class="p">],</span> <span class="s2">&quot;all_text&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">all_text</span><span class="p">]}</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-14-1"><a id="__codelineno-14-1" name="__codelineno-14-1" href="#__codelineno-14-1"></a><span class="n">vocab_train</span> <span class="o">=</span> <span class="n">common_voice_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">extract_all_chars</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keep_in_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">common_voice_train</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
</span><span id="__span-14-2"><a id="__codelineno-14-2" name="__codelineno-14-2" href="#__codelineno-14-2"></a><span class="n">vocab_test</span> <span class="o">=</span> <span class="n">common_voice_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">extract_all_chars</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">keep_in_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">common_voice_test</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
</span></code></pre></div>
<p>现在，我们创建训练数据集和测试数据集中所有不同字母的并集，并将结果列表转换为枚举字典。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-15-1"><a id="__codelineno-15-1" name="__codelineno-15-1" href="#__codelineno-15-1"></a><span class="n">vocab_list</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">vocab_train</span><span class="p">[</span><span class="s2">&quot;vocab&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span> <span class="o">|</span> <span class="nb">set</span><span class="p">(</span><span class="n">vocab_test</span><span class="p">[</span><span class="s2">&quot;vocab&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-16-1"><a id="__codelineno-16-1" name="__codelineno-16-1" href="#__codelineno-16-1"></a><span class="n">vocab_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">v</span><span class="p">:</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">vocab_list</span><span class="p">))}</span>
</span><span id="__span-16-2"><a id="__codelineno-16-2" name="__codelineno-16-2" href="#__codelineno-16-2"></a><span class="n">vocab_dict</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-17-1"><a id="__codelineno-17-1" name="__codelineno-17-1" href="#__codelineno-17-1"></a><span class="w">    </span><span class="o">{</span><span class="s1">&#39; &#39;</span>:<span class="w"> </span><span class="m">0</span>,
</span><span id="__span-17-2"><a id="__codelineno-17-2" name="__codelineno-17-2" href="#__codelineno-17-2"></a><span class="w">     </span><span class="s1">&#39;a&#39;</span>:<span class="w"> </span><span class="m">1</span>,
</span><span id="__span-17-3"><a id="__codelineno-17-3" name="__codelineno-17-3" href="#__codelineno-17-3"></a><span class="w">     </span><span class="s1">&#39;b&#39;</span>:<span class="w"> </span><span class="m">2</span>,
</span><span id="__span-17-4"><a id="__codelineno-17-4" name="__codelineno-17-4" href="#__codelineno-17-4"></a><span class="w">     </span><span class="s1">&#39;c&#39;</span>:<span class="w"> </span><span class="m">3</span>,
</span><span id="__span-17-5"><a id="__codelineno-17-5" name="__codelineno-17-5" href="#__codelineno-17-5"></a><span class="w">     </span><span class="s1">&#39;d&#39;</span>:<span class="w"> </span><span class="m">4</span>,
</span><span id="__span-17-6"><a id="__codelineno-17-6" name="__codelineno-17-6" href="#__codelineno-17-6"></a><span class="w">     </span><span class="s1">&#39;e&#39;</span>:<span class="w"> </span><span class="m">5</span>,
</span><span id="__span-17-7"><a id="__codelineno-17-7" name="__codelineno-17-7" href="#__codelineno-17-7"></a><span class="w">     </span><span class="s1">&#39;f&#39;</span>:<span class="w"> </span><span class="m">6</span>,
</span><span id="__span-17-8"><a id="__codelineno-17-8" name="__codelineno-17-8" href="#__codelineno-17-8"></a><span class="w">     </span><span class="s1">&#39;g&#39;</span>:<span class="w"> </span><span class="m">7</span>,
</span><span id="__span-17-9"><a id="__codelineno-17-9" name="__codelineno-17-9" href="#__codelineno-17-9"></a><span class="w">     </span><span class="s1">&#39;h&#39;</span>:<span class="w"> </span><span class="m">8</span>,
</span><span id="__span-17-10"><a id="__codelineno-17-10" name="__codelineno-17-10" href="#__codelineno-17-10"></a><span class="w">     </span><span class="s1">&#39;i&#39;</span>:<span class="w"> </span><span class="m">9</span>,
</span><span id="__span-17-11"><a id="__codelineno-17-11" name="__codelineno-17-11" href="#__codelineno-17-11"></a><span class="w">     </span><span class="s1">&#39;j&#39;</span>:<span class="w"> </span><span class="m">10</span>,
</span><span id="__span-17-12"><a id="__codelineno-17-12" name="__codelineno-17-12" href="#__codelineno-17-12"></a><span class="w">     </span><span class="s1">&#39;k&#39;</span>:<span class="w"> </span><span class="m">11</span>,
</span><span id="__span-17-13"><a id="__codelineno-17-13" name="__codelineno-17-13" href="#__codelineno-17-13"></a><span class="w">     </span><span class="s1">&#39;l&#39;</span>:<span class="w"> </span><span class="m">12</span>,
</span><span id="__span-17-14"><a id="__codelineno-17-14" name="__codelineno-17-14" href="#__codelineno-17-14"></a><span class="w">     </span><span class="s1">&#39;m&#39;</span>:<span class="w"> </span><span class="m">13</span>,
</span><span id="__span-17-15"><a id="__codelineno-17-15" name="__codelineno-17-15" href="#__codelineno-17-15"></a><span class="w">     </span><span class="s1">&#39;n&#39;</span>:<span class="w"> </span><span class="m">14</span>,
</span><span id="__span-17-16"><a id="__codelineno-17-16" name="__codelineno-17-16" href="#__codelineno-17-16"></a><span class="w">     </span><span class="s1">&#39;o&#39;</span>:<span class="w"> </span><span class="m">15</span>,
</span><span id="__span-17-17"><a id="__codelineno-17-17" name="__codelineno-17-17" href="#__codelineno-17-17"></a><span class="w">     </span><span class="s1">&#39;p&#39;</span>:<span class="w"> </span><span class="m">16</span>,
</span><span id="__span-17-18"><a id="__codelineno-17-18" name="__codelineno-17-18" href="#__codelineno-17-18"></a><span class="w">     </span><span class="s1">&#39;q&#39;</span>:<span class="w"> </span><span class="m">17</span>,
</span><span id="__span-17-19"><a id="__codelineno-17-19" name="__codelineno-17-19" href="#__codelineno-17-19"></a><span class="w">     </span><span class="s1">&#39;r&#39;</span>:<span class="w"> </span><span class="m">18</span>,
</span><span id="__span-17-20"><a id="__codelineno-17-20" name="__codelineno-17-20" href="#__codelineno-17-20"></a><span class="w">     </span><span class="s1">&#39;s&#39;</span>:<span class="w"> </span><span class="m">19</span>,
</span><span id="__span-17-21"><a id="__codelineno-17-21" name="__codelineno-17-21" href="#__codelineno-17-21"></a><span class="w">     </span><span class="s1">&#39;t&#39;</span>:<span class="w"> </span><span class="m">20</span>,
</span><span id="__span-17-22"><a id="__codelineno-17-22" name="__codelineno-17-22" href="#__codelineno-17-22"></a><span class="w">     </span><span class="s1">&#39;u&#39;</span>:<span class="w"> </span><span class="m">21</span>,
</span><span id="__span-17-23"><a id="__codelineno-17-23" name="__codelineno-17-23" href="#__codelineno-17-23"></a><span class="w">     </span><span class="s1">&#39;v&#39;</span>:<span class="w"> </span><span class="m">22</span>,
</span><span id="__span-17-24"><a id="__codelineno-17-24" name="__codelineno-17-24" href="#__codelineno-17-24"></a><span class="w">     </span><span class="s1">&#39;w&#39;</span>:<span class="w"> </span><span class="m">23</span>,
</span><span id="__span-17-25"><a id="__codelineno-17-25" name="__codelineno-17-25" href="#__codelineno-17-25"></a><span class="w">     </span><span class="s1">&#39;x&#39;</span>:<span class="w"> </span><span class="m">24</span>,
</span><span id="__span-17-26"><a id="__codelineno-17-26" name="__codelineno-17-26" href="#__codelineno-17-26"></a><span class="w">     </span><span class="s1">&#39;y&#39;</span>:<span class="w"> </span><span class="m">25</span>,
</span><span id="__span-17-27"><a id="__codelineno-17-27" name="__codelineno-17-27" href="#__codelineno-17-27"></a><span class="w">     </span><span class="s1">&#39;z&#39;</span>:<span class="w"> </span><span class="m">26</span>,
</span><span id="__span-17-28"><a id="__codelineno-17-28" name="__codelineno-17-28" href="#__codelineno-17-28"></a><span class="w">     </span><span class="s1">&#39;ç&#39;</span>:<span class="w"> </span><span class="m">27</span>,
</span><span id="__span-17-29"><a id="__codelineno-17-29" name="__codelineno-17-29" href="#__codelineno-17-29"></a><span class="w">     </span><span class="s1">&#39;ë&#39;</span>:<span class="w"> </span><span class="m">28</span>,
</span><span id="__span-17-30"><a id="__codelineno-17-30" name="__codelineno-17-30" href="#__codelineno-17-30"></a><span class="w">     </span><span class="s1">&#39;ö&#39;</span>:<span class="w"> </span><span class="m">29</span>,
</span><span id="__span-17-31"><a id="__codelineno-17-31" name="__codelineno-17-31" href="#__codelineno-17-31"></a><span class="w">     </span><span class="s1">&#39;ü&#39;</span>:<span class="w"> </span><span class="m">30</span>,
</span><span id="__span-17-32"><a id="__codelineno-17-32" name="__codelineno-17-32" href="#__codelineno-17-32"></a><span class="w">     </span><span class="s1">&#39;ğ&#39;</span>:<span class="w"> </span><span class="m">31</span>,
</span><span id="__span-17-33"><a id="__codelineno-17-33" name="__codelineno-17-33" href="#__codelineno-17-33"></a><span class="w">     </span><span class="s1">&#39;ı&#39;</span>:<span class="w"> </span><span class="m">32</span>,
</span><span id="__span-17-34"><a id="__codelineno-17-34" name="__codelineno-17-34" href="#__codelineno-17-34"></a><span class="w">     </span><span class="s1">&#39;ş&#39;</span>:<span class="w"> </span><span class="m">33</span>,
</span><span id="__span-17-35"><a id="__codelineno-17-35" name="__codelineno-17-35" href="#__codelineno-17-35"></a><span class="w">     </span><span class="s1">&#39;̇&#39;</span>:<span class="w"> </span><span class="m">34</span><span class="o">}</span>
</span></code></pre></div>
<p>很酷，我们看到字母表中的所有字母都出现在数据集中 (这并不令人惊讶)，我们还提取了特殊字符 <code>""</code> 和  <code>'</code>。请注意，我们没有排除这些特殊字符，因为模型必须学会预测单词何时结束，否则预测将始终是一系列字母，这将使得不可能将单词彼此分开。</p>
<p>人们应该始终记住，在训练模型之前，预处理是一个非常重要的步骤。例如，我们不希望我们的模型仅仅因为我们忘记规范化数据而区分 <code>a</code> 和 <code>A</code>。<code>a</code> 和 <code>A</code> 之间的区别根本不取决于字母的“声音”，而更多地取决于语法规则 - 例如，在句子开头使用大写字母。因此，删除大写字母和非大写字母之间的差异是明智的，这样模型在学习转录语音时就更容易了。</p>
<p>为了更清楚地表明 <code>" "</code> 具有自己的标记类别，我们给它一个更明显的字符 <code>|</code>。此外，我们还添加了一个“未知”标记，以便模型以后能够处理 Common Voice 训练集中未遇到的字符。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-18-1"><a id="__codelineno-18-1" name="__codelineno-18-1" href="#__codelineno-18-1"></a><span class="n">vocab_dict</span><span class="p">[</span><span class="s2">&quot;|&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">vocab_dict</span><span class="p">[</span><span class="s2">&quot; &quot;</span><span class="p">]</span>
</span><span id="__span-18-2"><a id="__codelineno-18-2" name="__codelineno-18-2" href="#__codelineno-18-2"></a><span class="k">del</span> <span class="n">vocab_dict</span><span class="p">[</span><span class="s2">&quot; &quot;</span><span class="p">]</span>
</span></code></pre></div>
<p>最后，我们还添加了一个对应于 CTC 的“空白标记”的填充标记。 “空白标记”是 CTC 算法的核心组成部分。欲了解更多信息，请查看 <a href="https://distill.pub/2017/ctc/">此处</a> 的“对齐”部分。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-19-1"><a id="__codelineno-19-1" name="__codelineno-19-1" href="#__codelineno-19-1"></a><span class="n">vocab_dict</span><span class="p">[</span><span class="s2">&quot;[UNK]&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab_dict</span><span class="p">)</span>
</span><span id="__span-19-2"><a id="__codelineno-19-2" name="__codelineno-19-2" href="#__codelineno-19-2"></a><span class="n">vocab_dict</span><span class="p">[</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab_dict</span><span class="p">)</span>
</span><span id="__span-19-3"><a id="__codelineno-19-3" name="__codelineno-19-3" href="#__codelineno-19-3"></a><span class="nb">len</span><span class="p">(</span><span class="n">vocab_dict</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-20-1"><a id="__codelineno-20-1" name="__codelineno-20-1" href="#__codelineno-20-1"></a><span class="w">    </span><span class="m">37</span>
</span></code></pre></div>
<p>很酷，现在我们的词汇表已经完成，包含 37 个标记，这意味着我们将作为适配器权重的一部分添加在预训练的 MMS 检查点顶部的线性层将具有 37 的输出维度。</p>
<p>由于单个 MMS 检查点可以为多种语言提供定制权重，因此分词器也可以包含多个词汇表。因此，我们需要嵌套我们的 <code>vocab_dict</code>，以便将来可能向词汇表中添加更多语言。字典应该嵌套使用适配器权重的名称，并在分词器配置中以 <a href="https://huggingface.co/docs/transformers/model_doc/wav2vec2#transformers.Wav2Vec2CTCTokenizer.target_lang"><code>target_lang</code></a> 的名称保存。</p>
<p>让我们像原始的 <a href="https://huggingface.co/facebook/mms-1b-all"><strong><code>mms-1b-all</code></strong></a> 检查点一样使用 ISO-639-3 语言代码。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-21-1"><a id="__codelineno-21-1" name="__codelineno-21-1" href="#__codelineno-21-1"></a><span class="n">target_lang</span> <span class="o">=</span> <span class="s2">&quot;tur&quot;</span>
</span></code></pre></div>
<p>让我们定义一个空字典，我们可以在其中添加刚刚创建的词汇表</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-22-1"><a id="__codelineno-22-1" name="__codelineno-22-1" href="#__codelineno-22-1"></a><span class="n">new_vocab_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">target_lang</span><span class="p">:</span> <span class="n">vocab_dict</span><span class="p">}</span>
</span></code></pre></div>
<p><strong>注意</strong>: 如果你想使用此 notebook 将新的适配器层添加到 <em>现有模型仓库</em> ，请确保 <strong>不要</strong> 创建一个空的新词汇表，而是重用已经存在的词汇表。为此，你应该取消注释以下单元格，并将 <code>"patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab"</code> 替换为你要添加适配器权重的模型仓库 ID。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-23-1"><a id="__codelineno-23-1" name="__codelineno-23-1" href="#__codelineno-23-1"></a><span class="c1"># from transformers import Wav2Vec2CTCTokenizer</span>
</span><span id="__span-23-2"><a id="__codelineno-23-2" name="__codelineno-23-2" href="#__codelineno-23-2"></a>
</span><span id="__span-23-3"><a id="__codelineno-23-3" name="__codelineno-23-3" href="#__codelineno-23-3"></a><span class="c1"># mms_adapter_repo = &quot;patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab&quot; # make sure to replace this path with a repo to which you want to add your new adapter weights</span>
</span><span id="__span-23-4"><a id="__codelineno-23-4" name="__codelineno-23-4" href="#__codelineno-23-4"></a>
</span><span id="__span-23-5"><a id="__codelineno-23-5" name="__codelineno-23-5" href="#__codelineno-23-5"></a><span class="c1"># tokenizer = Wav2Vec2CTCTokenizer.from_pretrained(mms_adapter_repo)</span>
</span><span id="__span-23-6"><a id="__codelineno-23-6" name="__codelineno-23-6" href="#__codelineno-23-6"></a><span class="c1"># new_vocab = tokenizer.vocab</span>
</span><span id="__span-23-7"><a id="__codelineno-23-7" name="__codelineno-23-7" href="#__codelineno-23-7"></a>
</span><span id="__span-23-8"><a id="__codelineno-23-8" name="__codelineno-23-8" href="#__codelineno-23-8"></a><span class="c1"># new_vocab[target_lang] = vocab_dict</span>
</span></code></pre></div>
<p>现在让我们将词汇表保存为 json 文件。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-24-1"><a id="__codelineno-24-1" name="__codelineno-24-1" href="#__codelineno-24-1"></a><span class="kn">import</span> <span class="nn">json</span>
</span><span id="__span-24-2"><a id="__codelineno-24-2" name="__codelineno-24-2" href="#__codelineno-24-2"></a><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vocab.json&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">vocab_file</span><span class="p">:</span>
</span><span id="__span-24-3"><a id="__codelineno-24-3" name="__codelineno-24-3" href="#__codelineno-24-3"></a>    <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">new_vocab_dict</span><span class="p">,</span> <span class="n">vocab_file</span><span class="p">)</span>
</span></code></pre></div>
<p>最后一步，我们使用 json 文件将词汇表加载到类的实例中 <code>Wav2Vec2CTCTokenizer</code>。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-25-1"><a id="__codelineno-25-1" name="__codelineno-25-1" href="#__codelineno-25-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Wav2Vec2CTCTokenizer</span>
</span><span id="__span-25-2"><a id="__codelineno-25-2" name="__codelineno-25-2" href="#__codelineno-25-2"></a>
</span><span id="__span-25-3"><a id="__codelineno-25-3" name="__codelineno-25-3" href="#__codelineno-25-3"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Wav2Vec2CTCTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;./&quot;</span><span class="p">,</span> <span class="n">unk_token</span><span class="o">=</span><span class="s2">&quot;[UNK]&quot;</span><span class="p">,</span> <span class="n">pad_token</span><span class="o">=</span><span class="s2">&quot;[PAD]&quot;</span><span class="p">,</span> <span class="n">word_delimiter_token</span><span class="o">=</span><span class="s2">&quot;|&quot;</span><span class="p">,</span> <span class="n">target_lang</span><span class="o">=</span><span class="n">target_lang</span><span class="p">)</span>
</span></code></pre></div>
<p>如果想要在本 notebook 的微调模型中重用刚刚创建的分词器，强烈建议将 <code>tokenizer</code> 上传到 <a href="https://huggingface.co/">🤗 Hub</a>。让我们将上传文件的仓库命名为 <code>"wav2vec2-large-mms-1b-turkish-colab"</code>:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-26-1"><a id="__codelineno-26-1" name="__codelineno-26-1" href="#__codelineno-26-1"></a><span class="n">repo_name</span> <span class="o">=</span> <span class="s2">&quot;wav2vec2-large-mms-1b-turkish-colab&quot;</span>
</span></code></pre></div>
<p>并将分词器上传到 <a href="https://huggingface.co/">🤗 Hub</a>。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-27-1"><a id="__codelineno-27-1" name="__codelineno-27-1" href="#__codelineno-27-1"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">(</span><span class="n">repo_name</span><span class="p">)</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-28-1"><a id="__codelineno-28-1" name="__codelineno-28-1" href="#__codelineno-28-1"></a><span class="w">    </span>CommitInfo<span class="o">(</span><span class="nv">commit_url</span><span class="o">=</span><span class="s1">&#39;https://huggingface.co/patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab/commit/48cccbfd6059aa6ce655e9d94b8358ba39536cb7&#39;</span>,<span class="w"> </span><span class="nv">commit_message</span><span class="o">=</span><span class="s1">&#39;Upload tokenizer&#39;</span>,<span class="w"> </span><span class="nv">commit_description</span><span class="o">=</span><span class="s1">&#39;&#39;</span>,<span class="w"> </span><span class="nv">oid</span><span class="o">=</span><span class="s1">&#39;48cccbfd6059aa6ce655e9d94b8358ba39536cb7&#39;</span>,<span class="w"> </span><span class="nv">pr_url</span><span class="o">=</span>None,<span class="w"> </span><span class="nv">pr_revision</span><span class="o">=</span>None,<span class="w"> </span><span class="nv">pr_num</span><span class="o">=</span>None<span class="o">)</span>
</span></code></pre></div>
<p>太好了，你可以在下面看到刚刚创建的存储库 <code>https://huggingface.co/&lt;your-username&gt;/wav2vec2-large-mms-1b-tr-colab</code></p>
<h3 id="wav2vec2featureextractor">创建 <code>Wav2Vec2FeatureExtractor</code><a class="headerlink" href="#wav2vec2featureextractor" title="Permanent link">&para;</a></h3>
<p>语音是一个连续的信号，要被计算机处理，首先必须离散化，这通常被称为 <strong>采样</strong>。采样率在这里起着重要的作用，它定义了每秒测量语音信号的数据点数。因此，采用更高的采样率采样会更好地近似 <em>真实</em> 语音信号，但也需要每秒更多的值。</p>
<p>预训练检查点期望其输入数据与其训练数据的分布大致相同。两个不同采样率采样的相同语音信号具有非常不同的分布，例如，将采样率加倍会导致数据点数量加倍。因此，在微调 ASR 模型的预训练检查点之前，必须验证用于预训练模型的数据的采样率与用于微调模型的数据集的采样率是否匹配。 <code>Wav2Vec2FeatureExtractor</code> 对象需要以下参数才能实例化:</p>
<ul>
<li><code>feature_size</code>: 语音模型以特征向量序列作为输入。虽然这个序列的长度显然会变化，但特征大小不应该变化。在 Wav2Vec2 的情况下，特征大小为 1，因为该模型是在原始语音信号上训练的 <span class="arithmatex">\( {}^2 \)</span>。</li>
<li><code>sampling_rate</code>: 模型训练时使用的采样率。</li>
<li><code>padding_value</code>: 对于批量推理，较短的输入需要用特定值填充</li>
<li><code>do_normalize</code>: 输入是否应该进行 <em>零均值单位方差</em> 归一化。通常，语音模型在归一化输入时表现更好</li>
<li><code>return_attention_mask</code>: 模型是否应该使用 <code>attention_mask</code> 进行批量推理。通常情况下，XLS-R 模型检查点应该 <strong>始终</strong> 使用 <code>attention_mask</code></li>
</ul>
<div class="language-python highlight"><pre><span></span><code><span id="__span-29-1"><a id="__codelineno-29-1" name="__codelineno-29-1" href="#__codelineno-29-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Wav2Vec2FeatureExtractor</span>
</span><span id="__span-29-2"><a id="__codelineno-29-2" name="__codelineno-29-2" href="#__codelineno-29-2"></a>
</span><span id="__span-29-3"><a id="__codelineno-29-3" name="__codelineno-29-3" href="#__codelineno-29-3"></a><span class="n">feature_extractor</span> <span class="o">=</span> <span class="n">Wav2Vec2FeatureExtractor</span><span class="p">(</span><span class="n">feature_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16000</span><span class="p">,</span> <span class="n">padding_value</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">do_normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>太好了，MMS 的特征提取管道已经完全定义！</p>
<p>为了提高用户友好性，特征提取器和分词器被 <em>封装</em> 到一个 <code>Wav2Vec2Processor</code> 类中，这样只需要一个 <code>model</code> 和  <code>processor</code> 对象。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-30-1"><a id="__codelineno-30-1" name="__codelineno-30-1" href="#__codelineno-30-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Wav2Vec2Processor</span>
</span><span id="__span-30-2"><a id="__codelineno-30-2" name="__codelineno-30-2" href="#__codelineno-30-2"></a>
</span><span id="__span-30-3"><a id="__codelineno-30-3" name="__codelineno-30-3" href="#__codelineno-30-3"></a><span class="n">processor</span> <span class="o">=</span> <span class="n">Wav2Vec2Processor</span><span class="p">(</span><span class="n">feature_extractor</span><span class="o">=</span><span class="n">feature_extractor</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
</span></code></pre></div>
<p>接下来，我们可以准备数据集。</p>
<h3 id="_4">预处理数据<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h3>
<p>到目前为止，我们还没有看过语音信号的实际值，只看过转录。除了 <code>sentence</code>，我们的数据集还包括另外两个列名 <code>path</code> 和  <code>audio</code>。 <code>path</code> 表示音频文件的绝对路径， <code>audio</code> 表示已经加载的音频数据。MMS 期望输入格式为 16kHz 的一维数组。这意味着音频文件必须加载并重新采样。</p>
<p>值得庆幸的是，当列名为 <code>audio</code> 时， <code>datasets</code> 会自动完成这一操作。让我们试试。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-31-1"><a id="__codelineno-31-1" name="__codelineno-31-1" href="#__codelineno-31-1"></a><span class="n">common_voice_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">]</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-32-1"><a id="__codelineno-32-1" name="__codelineno-32-1" href="#__codelineno-32-1"></a><span class="w">    </span><span class="o">{</span><span class="s1">&#39;path&#39;</span>:<span class="w"> </span><span class="s1">&#39;/root/.cache/huggingface/datasets/downloads/extracted/71ba9bd154da9d8c769b736301417178729d2b87b9e00cda59f6450f742ed778/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_17346025.mp3&#39;</span>,
</span><span id="__span-32-2"><a id="__codelineno-32-2" name="__codelineno-32-2" href="#__codelineno-32-2"></a><span class="w">     </span><span class="s1">&#39;array&#39;</span>:<span class="w"> </span>array<span class="o">([</span><span class="w"> </span><span class="m">0</span>.00000000e+00,<span class="w"> </span>-2.98378618e-13,<span class="w"> </span>-1.59835903e-13,<span class="w"> </span>...,
</span><span id="__span-32-3"><a id="__codelineno-32-3" name="__codelineno-32-3" href="#__codelineno-32-3"></a><span class="w">            </span>-2.01663317e-12,<span class="w"> </span>-1.87991593e-12,<span class="w"> </span>-1.17969588e-12<span class="o">])</span>,
</span><span id="__span-32-4"><a id="__codelineno-32-4" name="__codelineno-32-4" href="#__codelineno-32-4"></a><span class="w">     </span><span class="s1">&#39;sampling_rate&#39;</span>:<span class="w"> </span><span class="m">48000</span><span class="o">}</span>
</span></code></pre></div>
<p>在上面的示例中，我们可以看到音频数据以 48kHz 的采样率加载，而模型期望的是 16kHz，正如我们所见。我们可以通过使用 <a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=cast_column#datasets.DatasetDict.cast_column"><code>cast_column</code></a> 将音频特征设置为正确的采样率:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-33-1"><a id="__codelineno-33-1" name="__codelineno-33-1" href="#__codelineno-33-1"></a><span class="n">common_voice_train</span> <span class="o">=</span> <span class="n">common_voice_train</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>
</span><span id="__span-33-2"><a id="__codelineno-33-2" name="__codelineno-33-2" href="#__codelineno-33-2"></a><span class="n">common_voice_test</span> <span class="o">=</span> <span class="n">common_voice_test</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>
</span></code></pre></div>
<p>我们再来看一下 <code>"audio"</code>。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-34-1"><a id="__codelineno-34-1" name="__codelineno-34-1" href="#__codelineno-34-1"></a><span class="n">common_voice_train</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">]</span>
</span></code></pre></div>
<div class="language-text highlight"><pre><span></span><code><span id="__span-35-1"><a id="__codelineno-35-1" name="__codelineno-35-1" href="#__codelineno-35-1"></a>{&#39;path&#39;: &#39;/root/.cache/huggingface/datasets/downloads/extracted/71ba9bd154da9d8c769b736301417178729d2b87b9e00cda59f6450f742ed778/cv-corpus-6.1-2020-12-11/tr/clips/common_voice_tr_17346025.mp3&#39;,
</span><span id="__span-35-2"><a id="__codelineno-35-2" name="__codelineno-35-2" href="#__codelineno-35-2"></a> &#39;array&#39;: array([ 9.09494702e-13, -6.13908924e-12, -1.09139364e-11, ...,
</span><span id="__span-35-3"><a id="__codelineno-35-3" name="__codelineno-35-3" href="#__codelineno-35-3"></a>         1.81898940e-12, 4.54747351e-13, 3.63797881e-12]),
</span><span id="__span-35-4"><a id="__codelineno-35-4" name="__codelineno-35-4" href="#__codelineno-35-4"></a> &#39;sampling_rate&#39;: 16000}
</span></code></pre></div>
<p>这似乎奏效了！让我们通过打印语音输入的形状、转录内容和相应的采样率来最后检查数据是否准备正确。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-36-1"><a id="__codelineno-36-1" name="__codelineno-36-1" href="#__codelineno-36-1"></a><span class="n">rand_int</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">common_voice_train</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-36-2"><a id="__codelineno-36-2" name="__codelineno-36-2" href="#__codelineno-36-2"></a>
</span><span id="__span-36-3"><a id="__codelineno-36-3" name="__codelineno-36-3" href="#__codelineno-36-3"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Target text:&quot;</span><span class="p">,</span> <span class="n">common_voice_train</span><span class="p">[</span><span class="n">rand_int</span><span class="p">][</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span>
</span><span id="__span-36-4"><a id="__codelineno-36-4" name="__codelineno-36-4" href="#__codelineno-36-4"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input array shape:&quot;</span><span class="p">,</span> <span class="n">common_voice_train</span><span class="p">[</span><span class="n">rand_int</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</span><span id="__span-36-5"><a id="__codelineno-36-5" name="__codelineno-36-5" href="#__codelineno-36-5"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sampling rate:&quot;</span><span class="p">,</span> <span class="n">common_voice_train</span><span class="p">[</span><span class="n">rand_int</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;sampling_rate&quot;</span><span class="p">])</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-37-1"><a id="__codelineno-37-1" name="__codelineno-37-1" href="#__codelineno-37-1"></a><span class="w">    </span>Target<span class="w"> </span>text:<span class="w"> </span>bağış<span class="w"> </span>anlaşması<span class="w"> </span>bir<span class="w"> </span>ağustosta<span class="w"> </span>imzalandı
</span><span id="__span-37-2"><a id="__codelineno-37-2" name="__codelineno-37-2" href="#__codelineno-37-2"></a><span class="w">    </span>Input<span class="w"> </span>array<span class="w"> </span>shape:<span class="o">(</span><span class="m">70656</span>,<span class="o">)</span>
</span><span id="__span-37-3"><a id="__codelineno-37-3" name="__codelineno-37-3" href="#__codelineno-37-3"></a><span class="w">    </span>Sampling<span class="w"> </span>rate:<span class="w"> </span><span class="m">16000</span>
</span></code></pre></div>
<p>很好！一切看起来都很棒 - 数据是一维数组，采样率始终对应于 16kHz，并且目标文本已标准化。</p>
<p>最后，我们可以利用 <code>Wav2Vec2Processor</code> 将数据处理成 <code>Wav2Vec2ForCTC</code> 训练所需的格式。为此，让我们利用 Dataset 的 <a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=map#datasets.DatasetDict.map"><code>map(...)</code></a> 函数。</p>
<p>首先，我们通过调用 <code>batch["audio"]</code> 来加载并重新采样音频数据。<br />
其次，我们从加载的音频文件中提取 <code>input_values</code>。在我们的情况下， <code>Wav2Vec2Processor</code> 只规范化数据。然而，对于其他语音模型，这一步可能包括更复杂的特征提取，例如 <a href="https://en.wikipedia.org/wiki/Mel-frequency_cepstrum">Log-Mel 特征提取</a>。<br />
第三，我们将转录编码为标签 id。</p>
<p><strong>注意</strong>: 这个映射函数是一个很好的例子，说明了如何使用 <code>Wav2Vec2Processor</code> 类。在“正常”情况下，调用 <code>processor(...)</code> 会重定向到 <code>Wav2Vec2FeatureExtractor</code> 的调用方法。然而，当将处理器封装到 <code>as_target_processor</code> 上下文中时，同一个方法会重定向到 <code>Wav2Vec2CTCTokenizer</code> 的调用方法。
欲了解更多信息，请查看 <a href="https://huggingface.co/transformers/master/model_doc/wav2vec2.html#transformers.Wav2Vec2Processor.__call__">文档</a>。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-38-1"><a id="__codelineno-38-1" name="__codelineno-38-1" href="#__codelineno-38-1"></a><span class="k">def</span> <span class="nf">prepare_dataset</span><span class="p">(</span><span class="n">batch</span><span class="p">):</span>
</span><span id="__span-38-2"><a id="__codelineno-38-2" name="__codelineno-38-2" href="#__codelineno-38-2"></a>    <span class="n">audio</span> <span class="o">=</span> <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;audio&quot;</span><span class="p">]</span>
</span><span id="__span-38-3"><a id="__codelineno-38-3" name="__codelineno-38-3" href="#__codelineno-38-3"></a>
</span><span id="__span-38-4"><a id="__codelineno-38-4" name="__codelineno-38-4" href="#__codelineno-38-4"></a>    <span class="c1"># batched output is &quot;un-batched&quot;</span>
</span><span id="__span-38-5"><a id="__codelineno-38-5" name="__codelineno-38-5" href="#__codelineno-38-5"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_values&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">audio</span><span class="p">[</span><span class="s2">&quot;array&quot;</span><span class="p">],</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="n">audio</span><span class="p">[</span><span class="s2">&quot;sampling_rate&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">input_values</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-38-6"><a id="__codelineno-38-6" name="__codelineno-38-6" href="#__codelineno-38-6"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_length&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;input_values&quot;</span><span class="p">])</span>
</span><span id="__span-38-7"><a id="__codelineno-38-7" name="__codelineno-38-7" href="#__codelineno-38-7"></a>
</span><span id="__span-38-8"><a id="__codelineno-38-8" name="__codelineno-38-8" href="#__codelineno-38-8"></a>    <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">text</span><span class="o">=</span><span class="n">batch</span><span class="p">[</span><span class="s2">&quot;sentence&quot;</span><span class="p">])</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-38-9"><a id="__codelineno-38-9" name="__codelineno-38-9" href="#__codelineno-38-9"></a>    <span class="k">return</span> <span class="n">batch</span>
</span></code></pre></div>
<p>让我们将数据准备功能应用到所有示例中。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-39-1"><a id="__codelineno-39-1" name="__codelineno-39-1" href="#__codelineno-39-1"></a><span class="n">common_voice_train</span> <span class="o">=</span> <span class="n">common_voice_train</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_dataset</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">common_voice_train</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
</span><span id="__span-39-2"><a id="__codelineno-39-2" name="__codelineno-39-2" href="#__codelineno-39-2"></a><span class="n">common_voice_test</span> <span class="o">=</span> <span class="n">common_voice_test</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">prepare_dataset</span><span class="p">,</span> <span class="n">remove_columns</span><span class="o">=</span><span class="n">common_voice_test</span><span class="o">.</span><span class="n">column_names</span><span class="p">)</span>
</span></code></pre></div>
<p><strong>注意</strong>: <code>datasets</code> 自动处理音频加载和重新采样。如果你希望实现自己的定制数据加载/采样，请随意使用该 <code>"path"</code> 列并忽略该 <code>"audio"</code> 列。</p>
<p>太棒了，现在我们准备开始训练了！</p>
<h2 id="_5">训练<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h2>
<p>数据已经处理好，我们准备开始设置训练流程。我们将使用 🤗 的 <a href="https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer">Trainer</a>，为此我们基本上需要做以下几件事:</p>
<ul>
<li>定义一个数据整理器。与大多数 NLP 模型不同，MMS 的输入长度比输出长度大得多。例如，输入长度为 50000 的样本的输出长度不超过 100。鉴于输入大小较大，动态填充训练批次更为高效，这意味着所有训练样本只应填充到其批次中最长的样本，而不是整体最长的样本。因此，微调 MMS 需要一个特殊的填充数据整理器，我们将在下面定义它</li>
<li>评估指标。在训练过程中，模型应该根据字错误率进行评估。我们应该相应地定义一个 <code>compute_metrics</code> 函数</li>
<li>加载预训练检查点。我们需要加载预训练检查点并正确配置它进行训练。</li>
<li>定义训练配置。</li>
</ul>
<p>在微调模型之后，我们将正确地在测试数据上评估它，并验证它是否确实学会了正确转录语音。</p>
<h3 id="trainer">设置 Trainer<a class="headerlink" href="#trainer" title="Permanent link">&para;</a></h3>
<p>让我们从定义数据整理器开始。数据整理器的代码是从 <a href="https://github.com/huggingface/transformers/blob/7e61d56a45c19284cfda0cee8995fb552f6b1f4e/examples/pytorch/speech-recognition/run_speech_recognition_ctc.py#L219">这个示例</a> 中复制的。</p>
<p>不详细讲述，与常见的数据整理器不同，这个数据整理器分别对待 <code>input_values</code> 和  <code>labels</code>，因此对它们应用两个单独的填充函数 (再次利用 MMS 处理器的上下文管理器)。这是必要的，因为在语音识别中，输入和输出属于不同的模态，因此它们不应该被相同的填充函数处理。
与常见的数据整理器类似，标签中的填充标记用 <code>-100</code> 填充，以便在计算损失时 <strong>不</strong> 考虑这些标记。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-40-1"><a id="__codelineno-40-1" name="__codelineno-40-1" href="#__codelineno-40-1"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-40-2"><a id="__codelineno-40-2" name="__codelineno-40-2" href="#__codelineno-40-2"></a>
</span><span id="__span-40-3"><a id="__codelineno-40-3" name="__codelineno-40-3" href="#__codelineno-40-3"></a><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">field</span>
</span><span id="__span-40-4"><a id="__codelineno-40-4" name="__codelineno-40-4" href="#__codelineno-40-4"></a><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>
</span><span id="__span-40-5"><a id="__codelineno-40-5" name="__codelineno-40-5" href="#__codelineno-40-5"></a>
</span><span id="__span-40-6"><a id="__codelineno-40-6" name="__codelineno-40-6" href="#__codelineno-40-6"></a><span class="nd">@dataclass</span>
</span><span id="__span-40-7"><a id="__codelineno-40-7" name="__codelineno-40-7" href="#__codelineno-40-7"></a><span class="k">class</span> <span class="nc">DataCollatorCTCWithPadding</span><span class="p">:</span>
</span><span id="__span-40-8"><a id="__codelineno-40-8" name="__codelineno-40-8" href="#__codelineno-40-8"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-40-9"><a id="__codelineno-40-9" name="__codelineno-40-9" href="#__codelineno-40-9"></a><span class="sd">    Data collator that will dynamically pad the inputs received.</span>
</span><span id="__span-40-10"><a id="__codelineno-40-10" name="__codelineno-40-10" href="#__codelineno-40-10"></a><span class="sd">    Args:</span>
</span><span id="__span-40-11"><a id="__codelineno-40-11" name="__codelineno-40-11" href="#__codelineno-40-11"></a><span class="sd">        processor (:class:`~transformers.Wav2Vec2Processor`)</span>
</span><span id="__span-40-12"><a id="__codelineno-40-12" name="__codelineno-40-12" href="#__codelineno-40-12"></a><span class="sd">            The processor used for proccessing the data.</span>
</span><span id="__span-40-13"><a id="__codelineno-40-13" name="__codelineno-40-13" href="#__codelineno-40-13"></a><span class="sd">        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):</span>
</span><span id="__span-40-14"><a id="__codelineno-40-14" name="__codelineno-40-14" href="#__codelineno-40-14"></a><span class="sd">            Select a strategy to pad the returned sequences (according to the model&#39;s padding side and padding index)</span>
</span><span id="__span-40-15"><a id="__codelineno-40-15" name="__codelineno-40-15" href="#__codelineno-40-15"></a><span class="sd">            among:</span>
</span><span id="__span-40-16"><a id="__codelineno-40-16" name="__codelineno-40-16" href="#__codelineno-40-16"></a><span class="sd">            *:obj:`True` or :obj:`&#39;longest&#39;`: Pad to the longest sequence in the batch (or no padding if only a single</span>
</span><span id="__span-40-17"><a id="__codelineno-40-17" name="__codelineno-40-17" href="#__codelineno-40-17"></a><span class="sd">              sequence if provided).</span>
</span><span id="__span-40-18"><a id="__codelineno-40-18" name="__codelineno-40-18" href="#__codelineno-40-18"></a><span class="sd">            *:obj:`&#39;max_length&#39;`: Pad to a maximum length specified with the argument :obj:`max_length` or to the</span>
</span><span id="__span-40-19"><a id="__codelineno-40-19" name="__codelineno-40-19" href="#__codelineno-40-19"></a><span class="sd">              maximum acceptable input length for the model if that argument is not provided.</span>
</span><span id="__span-40-20"><a id="__codelineno-40-20" name="__codelineno-40-20" href="#__codelineno-40-20"></a><span class="sd">            *:obj:`False` or :obj:`&#39;do_not_pad&#39;` (default): No padding (i.e., can output a batch with sequences of</span>
</span><span id="__span-40-21"><a id="__codelineno-40-21" name="__codelineno-40-21" href="#__codelineno-40-21"></a><span class="sd">              different lengths).</span>
</span><span id="__span-40-22"><a id="__codelineno-40-22" name="__codelineno-40-22" href="#__codelineno-40-22"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-40-23"><a id="__codelineno-40-23" name="__codelineno-40-23" href="#__codelineno-40-23"></a>
</span><span id="__span-40-24"><a id="__codelineno-40-24" name="__codelineno-40-24" href="#__codelineno-40-24"></a>    <span class="n">processor</span><span class="p">:</span> <span class="n">Wav2Vec2Processor</span>
</span><span id="__span-40-25"><a id="__codelineno-40-25" name="__codelineno-40-25" href="#__codelineno-40-25"></a>    <span class="n">padding</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">bool</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-40-26"><a id="__codelineno-40-26" name="__codelineno-40-26" href="#__codelineno-40-26"></a>
</span><span id="__span-40-27"><a id="__codelineno-40-27" name="__codelineno-40-27" href="#__codelineno-40-27"></a>    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">features</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
</span><span id="__span-40-28"><a id="__codelineno-40-28" name="__codelineno-40-28" href="#__codelineno-40-28"></a>        <span class="c1"># split inputs and labels since they have to be of different lenghts and need</span>
</span><span id="__span-40-29"><a id="__codelineno-40-29" name="__codelineno-40-29" href="#__codelineno-40-29"></a>        <span class="c1"># different padding methods</span>
</span><span id="__span-40-30"><a id="__codelineno-40-30" name="__codelineno-40-30" href="#__codelineno-40-30"></a>        <span class="n">input_features</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;input_values&quot;</span><span class="p">:</span> <span class="n">feature</span><span class="p">[</span><span class="s2">&quot;input_values&quot;</span><span class="p">]}</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>
</span><span id="__span-40-31"><a id="__codelineno-40-31" name="__codelineno-40-31" href="#__codelineno-40-31"></a>        <span class="n">label_features</span> <span class="o">=</span> <span class="p">[{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">feature</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]}</span> <span class="k">for</span> <span class="n">feature</span> <span class="ow">in</span> <span class="n">features</span><span class="p">]</span>
</span><span id="__span-40-32"><a id="__codelineno-40-32" name="__codelineno-40-32" href="#__codelineno-40-32"></a>
</span><span id="__span-40-33"><a id="__codelineno-40-33" name="__codelineno-40-33" href="#__codelineno-40-33"></a>        <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
</span><span id="__span-40-34"><a id="__codelineno-40-34" name="__codelineno-40-34" href="#__codelineno-40-34"></a>            <span class="n">input_features</span><span class="p">,</span>
</span><span id="__span-40-35"><a id="__codelineno-40-35" name="__codelineno-40-35" href="#__codelineno-40-35"></a>            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
</span><span id="__span-40-36"><a id="__codelineno-40-36" name="__codelineno-40-36" href="#__codelineno-40-36"></a>            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
</span><span id="__span-40-37"><a id="__codelineno-40-37" name="__codelineno-40-37" href="#__codelineno-40-37"></a>        <span class="p">)</span>
</span><span id="__span-40-38"><a id="__codelineno-40-38" name="__codelineno-40-38" href="#__codelineno-40-38"></a>
</span><span id="__span-40-39"><a id="__codelineno-40-39" name="__codelineno-40-39" href="#__codelineno-40-39"></a>        <span class="n">labels_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">processor</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
</span><span id="__span-40-40"><a id="__codelineno-40-40" name="__codelineno-40-40" href="#__codelineno-40-40"></a>            <span class="n">labels</span><span class="o">=</span><span class="n">label_features</span><span class="p">,</span>
</span><span id="__span-40-41"><a id="__codelineno-40-41" name="__codelineno-40-41" href="#__codelineno-40-41"></a>            <span class="n">padding</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">padding</span><span class="p">,</span>
</span><span id="__span-40-42"><a id="__codelineno-40-42" name="__codelineno-40-42" href="#__codelineno-40-42"></a>            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
</span><span id="__span-40-43"><a id="__codelineno-40-43" name="__codelineno-40-43" href="#__codelineno-40-43"></a>        <span class="p">)</span>
</span><span id="__span-40-44"><a id="__codelineno-40-44" name="__codelineno-40-44" href="#__codelineno-40-44"></a>
</span><span id="__span-40-45"><a id="__codelineno-40-45" name="__codelineno-40-45" href="#__codelineno-40-45"></a>        <span class="c1"># replace padding with -100 to ignore loss correctly</span>
</span><span id="__span-40-46"><a id="__codelineno-40-46" name="__codelineno-40-46" href="#__codelineno-40-46"></a>        <span class="n">labels</span> <span class="o">=</span> <span class="n">labels_batch</span><span class="p">[</span><span class="s2">&quot;input_ids&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">labels_batch</span><span class="o">.</span><span class="n">attention_mask</span><span class="o">.</span><span class="n">ne</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mi">100</span><span class="p">)</span>
</span><span id="__span-40-47"><a id="__codelineno-40-47" name="__codelineno-40-47" href="#__codelineno-40-47"></a>
</span><span id="__span-40-48"><a id="__codelineno-40-48" name="__codelineno-40-48" href="#__codelineno-40-48"></a>        <span class="n">batch</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">labels</span>
</span><span id="__span-40-49"><a id="__codelineno-40-49" name="__codelineno-40-49" href="#__codelineno-40-49"></a>
</span><span id="__span-40-50"><a id="__codelineno-40-50" name="__codelineno-40-50" href="#__codelineno-40-50"></a>        <span class="k">return</span> <span class="n">batch</span>
</span></code></pre></div>
<div class="language-python highlight"><pre><span></span><code><span id="__span-41-1"><a id="__codelineno-41-1" name="__codelineno-41-1" href="#__codelineno-41-1"></a><span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorCTCWithPadding</span><span class="p">(</span><span class="n">processor</span><span class="o">=</span><span class="n">processor</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></code></pre></div>
<p>接下来，定义评估指标。如前所述，ASR 中的主要指标是单词错误率 (WER)，因此我们也将在本 notebook 中使用它。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-42-1"><a id="__codelineno-42-1" name="__codelineno-42-1" href="#__codelineno-42-1"></a><span class="kn">from</span> <span class="nn">evaluate</span> <span class="kn">import</span> <span class="n">load</span>
</span><span id="__span-42-2"><a id="__codelineno-42-2" name="__codelineno-42-2" href="#__codelineno-42-2"></a>
</span><span id="__span-42-3"><a id="__codelineno-42-3" name="__codelineno-42-3" href="#__codelineno-42-3"></a><span class="n">wer_metric</span> <span class="o">=</span> <span class="n">load</span><span class="p">(</span><span class="s2">&quot;wer&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>模型将返回一系列 logit 向量:
<span class="arithmatex">\( \mathbf{y}_1, \ldots, \mathbf{y}_m \)</span> 其中 <span class="arithmatex">\( \mathbf{y} _1 = f_{\theta}(x_1, \ldots, x_n)[0] \)</span> 且  <span class="arithmatex">\( n &gt;&gt; m \)</span>。</p>
<p>logit 向量 <span class="arithmatex">\( \mathbf{y}_1 \)</span> 包含我们前面定义的词汇表中每个单词的对数几率，因此 <span class="arithmatex">\( \text{len}(\mathbf{y}_i) = \)</span> <code>config.vocab_size</code>。我们对模型最可能的预测感兴趣，因此取 logits 的  <code>argmax(...)</code>。此外，我们通过将 <code>-100</code> 替换为 <code>pad_token_id</code> 并解码 id，同时确保连续标记 <strong>不</strong> 以 CTC 风格分组到同一标记 <span class="arithmatex">\( {}^1 \)</span>，将编码后的标签转换回原始字符串。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-43-1"><a id="__codelineno-43-1" name="__codelineno-43-1" href="#__codelineno-43-1"></a><span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">pred</span><span class="p">):</span>
</span><span id="__span-43-2"><a id="__codelineno-43-2" name="__codelineno-43-2" href="#__codelineno-43-2"></a>    <span class="n">pred_logits</span> <span class="o">=</span> <span class="n">pred</span><span class="o">.</span><span class="n">predictions</span>
</span><span id="__span-43-3"><a id="__codelineno-43-3" name="__codelineno-43-3" href="#__codelineno-43-3"></a>    <span class="n">pred_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">pred_logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-43-4"><a id="__codelineno-43-4" name="__codelineno-43-4" href="#__codelineno-43-4"></a>
</span><span id="__span-43-5"><a id="__codelineno-43-5" name="__codelineno-43-5" href="#__codelineno-43-5"></a>    <span class="n">pred</span><span class="o">.</span><span class="n">label_ids</span><span class="p">[</span><span class="n">pred</span><span class="o">.</span><span class="n">label_ids</span> <span class="o">==</span> <span class="o">-</span><span class="mi">100</span><span class="p">]</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
</span><span id="__span-43-6"><a id="__codelineno-43-6" name="__codelineno-43-6" href="#__codelineno-43-6"></a>
</span><span id="__span-43-7"><a id="__codelineno-43-7" name="__codelineno-43-7" href="#__codelineno-43-7"></a>    <span class="n">pred_str</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">pred_ids</span><span class="p">)</span>
</span><span id="__span-43-8"><a id="__codelineno-43-8" name="__codelineno-43-8" href="#__codelineno-43-8"></a>    <span class="c1"># we do not want to group tokens when computing the metrics</span>
</span><span id="__span-43-9"><a id="__codelineno-43-9" name="__codelineno-43-9" href="#__codelineno-43-9"></a>    <span class="n">label_str</span> <span class="o">=</span> <span class="n">processor</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">pred</span><span class="o">.</span><span class="n">label_ids</span><span class="p">,</span> <span class="n">group_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-43-10"><a id="__codelineno-43-10" name="__codelineno-43-10" href="#__codelineno-43-10"></a>
</span><span id="__span-43-11"><a id="__codelineno-43-11" name="__codelineno-43-11" href="#__codelineno-43-11"></a>    <span class="n">wer</span> <span class="o">=</span> <span class="n">wer_metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">pred_str</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">label_str</span><span class="p">)</span>
</span><span id="__span-43-12"><a id="__codelineno-43-12" name="__codelineno-43-12" href="#__codelineno-43-12"></a>
</span><span id="__span-43-13"><a id="__codelineno-43-13" name="__codelineno-43-13" href="#__codelineno-43-13"></a>    <span class="k">return</span> <span class="p">{</span><span class="s2">&quot;wer&quot;</span><span class="p">:</span> <span class="n">wer</span><span class="p">}</span>
</span></code></pre></div>
<p>现在，我们可以加载预训练的 <a href="https://huggingface.co/facebook/mms-1b-all"><code>mms-1b-all</code></a> 检查点。分词器的 <code>pad_token_id</code> 必须定义模型的 <code>pad_token_id</code>，或者在 <code>Wav2Vec2ForCTC</code> 的情况下也是 CTC 的 <em>空白标记</em> <span class="arithmatex">\( {}^2 \)</span>。</p>
<p>由于我们只训练一小部分权重，模型不容易过拟合。因此，我们确保禁用所有 dropout 层。</p>
<p><strong>注意</strong>: 当使用本笔记本在 Common Voice 的另一种语言上训练 MMS 时，这些超参数设置可能不会很好地工作。根据你的用例，随意调整这些设置。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-44-1"><a id="__codelineno-44-1" name="__codelineno-44-1" href="#__codelineno-44-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Wav2Vec2ForCTC</span>
</span><span id="__span-44-2"><a id="__codelineno-44-2" name="__codelineno-44-2" href="#__codelineno-44-2"></a>
</span><span id="__span-44-3"><a id="__codelineno-44-3" name="__codelineno-44-3" href="#__codelineno-44-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Wav2Vec2ForCTC</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
</span><span id="__span-44-4"><a id="__codelineno-44-4" name="__codelineno-44-4" href="#__codelineno-44-4"></a>    <span class="s2">&quot;facebook/mms-1b-all&quot;</span><span class="p">,</span>
</span><span id="__span-44-5"><a id="__codelineno-44-5" name="__codelineno-44-5" href="#__codelineno-44-5"></a>    <span class="n">attention_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-44-6"><a id="__codelineno-44-6" name="__codelineno-44-6" href="#__codelineno-44-6"></a>    <span class="n">hidden_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-44-7"><a id="__codelineno-44-7" name="__codelineno-44-7" href="#__codelineno-44-7"></a>    <span class="n">feat_proj_dropout</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-44-8"><a id="__codelineno-44-8" name="__codelineno-44-8" href="#__codelineno-44-8"></a>    <span class="n">layerdrop</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-44-9"><a id="__codelineno-44-9" name="__codelineno-44-9" href="#__codelineno-44-9"></a>    <span class="n">ctc_loss_reduction</span><span class="o">=</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span>
</span><span id="__span-44-10"><a id="__codelineno-44-10" name="__codelineno-44-10" href="#__codelineno-44-10"></a>    <span class="n">pad_token_id</span><span class="o">=</span><span class="n">processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>
</span><span id="__span-44-11"><a id="__codelineno-44-11" name="__codelineno-44-11" href="#__codelineno-44-11"></a>    <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">),</span>
</span><span id="__span-44-12"><a id="__codelineno-44-12" name="__codelineno-44-12" href="#__codelineno-44-12"></a>    <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-44-13"><a id="__codelineno-44-13" name="__codelineno-44-13" href="#__codelineno-44-13"></a><span class="p">)</span>
</span></code></pre></div>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-45-1"><a id="__codelineno-45-1" name="__codelineno-45-1" href="#__codelineno-45-1"></a><span class="w">    </span>Some<span class="w"> </span>weights<span class="w"> </span>of<span class="w"> </span>Wav2Vec2ForCTC<span class="w"> </span>were<span class="w"> </span>not<span class="w"> </span>initialized<span class="w"> </span>from<span class="w"> </span>the<span class="w"> </span>model<span class="w"> </span>checkpoint<span class="w"> </span>at<span class="w"> </span>facebook/mms-1b-all<span class="w"> </span>and<span class="w"> </span>are<span class="w"> </span>newly<span class="w"> </span>initialized<span class="w"> </span>because<span class="w"> </span>the<span class="w"> </span>shapes<span class="w"> </span>did<span class="w"> </span>not<span class="w"> </span>match:
</span><span id="__span-45-2"><a id="__codelineno-45-2" name="__codelineno-45-2" href="#__codelineno-45-2"></a><span class="w">    </span>-<span class="w"> </span>lm_head.bias:<span class="w"> </span>found<span class="w"> </span>shape<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">154</span><span class="o">])</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>checkpoint<span class="w"> </span>and<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">39</span><span class="o">])</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>model<span class="w"> </span>instantiated
</span><span id="__span-45-3"><a id="__codelineno-45-3" name="__codelineno-45-3" href="#__codelineno-45-3"></a><span class="w">    </span>-<span class="w"> </span>lm_head.weight:<span class="w"> </span>found<span class="w"> </span>shape<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">154</span>,<span class="w"> </span><span class="m">1280</span><span class="o">])</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>checkpoint<span class="w"> </span>and<span class="w"> </span>torch.Size<span class="o">([</span><span class="m">39</span>,<span class="w"> </span><span class="m">1280</span><span class="o">])</span><span class="w"> </span><span class="k">in</span><span class="w"> </span>the<span class="w"> </span>model<span class="w"> </span>instantiated
</span><span id="__span-45-4"><a id="__codelineno-45-4" name="__codelineno-45-4" href="#__codelineno-45-4"></a><span class="w">    </span>You<span class="w"> </span>should<span class="w"> </span>probably<span class="w"> </span>TRAIN<span class="w"> </span>this<span class="w"> </span>model<span class="w"> </span>on<span class="w"> </span>a<span class="w"> </span>down-stream<span class="w"> </span>task<span class="w"> </span>to<span class="w"> </span>be<span class="w"> </span>able<span class="w"> </span>to<span class="w"> </span>use<span class="w"> </span>it<span class="w"> </span><span class="k">for</span><span class="w"> </span>predictions<span class="w"> </span>and<span class="w"> </span>inference.
</span></code></pre></div>
<p><strong>注意</strong>: 预计一些权重将被重新初始化。这些权重对应于新初始化的词汇输出层。</p>
<p>我们现在希望确保只有适配器权重将被训练，而模型的其余部分保持冻结。</p>
<p>首先，我们重新初始化所有适配器权重，这可以通过方便的 <code>init_adapter_layers</code> 方法完成。也可以不重新初始化适配器权重并继续微调，但在这种情况下，在训练之前应该通过 <a href="https://huggingface.co/docs/transformers/main/en/model_doc/wav2vec2#transformers.Wav2Vec2ForCTC.load_adapter"><code>load_adapter(...)</code> 方法</a> 加载合适的适配器权重。然而，词汇表通常仍然不会很好地匹配自定义训练数据，因此通常更容易重新初始化所有适配器层，以便它们可以轻松地进行微调。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-46-1"><a id="__codelineno-46-1" name="__codelineno-46-1" href="#__codelineno-46-1"></a><span class="n">model</span><span class="o">.</span><span class="n">init_adapter_layers</span><span class="p">()</span>
</span></code></pre></div>
<p>接下来，我们冻结 <strong>除</strong> 适配器层之外的所有权重。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-47-1"><a id="__codelineno-47-1" name="__codelineno-47-1" href="#__codelineno-47-1"></a><span class="n">model</span><span class="o">.</span><span class="n">freeze_base_model</span><span class="p">()</span>
</span><span id="__span-47-2"><a id="__codelineno-47-2" name="__codelineno-47-2" href="#__codelineno-47-2"></a>
</span><span id="__span-47-3"><a id="__codelineno-47-3" name="__codelineno-47-3" href="#__codelineno-47-3"></a><span class="n">adapter_weights</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_get_adapters</span><span class="p">()</span>
</span><span id="__span-47-4"><a id="__codelineno-47-4" name="__codelineno-47-4" href="#__codelineno-47-4"></a><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">adapter_weights</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
</span><span id="__span-47-5"><a id="__codelineno-47-5" name="__codelineno-47-5" href="#__codelineno-47-5"></a>    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">True</span>
</span></code></pre></div>
<p>最后一步，我们定义与训练相关的所有参数。
对一些参数进行更多解释:</p>
<ul>
<li><code>group_by_length</code> 通过将输入长度相似的训练样本分组到一个批次中，使训练更加高效。这可以通过大大减少通过模型传递的无用填充标记的总数，从而显著加快训练时间</li>
<li><code>learning_rate</code> 被选择为 1e-3，这是使用 Adam 训练的常用默认值。其他学习率可能同样有效。</li>
</ul>
<p>有关其他参数的更多解释，可以查看 <a href="https://huggingface.co/transformers/master/main_classes/trainer.html?highlight=trainer#trainingarguments">文档</a>。为了节省 GPU 内存，我们启用 PyTorch 的 <a href="https://pytorch.org/docs/stable/checkpoint.html">梯度检查点</a>，并将损失减少设置为“ <em>mean</em> ”。MMS 适配器微调非常快地收敛到非常好的性能，因此即使对于像 4 小时这样小的数据集，我们也只会训练 4 个周期。在训练过程中，每 200 个训练步骤将异步上传一个检查点到 hub。它允许你在模型仍在训练时也可以使用演示小部件玩耍。</p>
<p><strong>注意</strong>: 如果不想将模型检查点上传到 hub，只需将 <code>push_to_hub=False</code> 即可。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-48-1"><a id="__codelineno-48-1" name="__codelineno-48-1" href="#__codelineno-48-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span>
</span><span id="__span-48-2"><a id="__codelineno-48-2" name="__codelineno-48-2" href="#__codelineno-48-2"></a>
</span><span id="__span-48-3"><a id="__codelineno-48-3" name="__codelineno-48-3" href="#__codelineno-48-3"></a><span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span>
</span><span id="__span-48-4"><a id="__codelineno-48-4" name="__codelineno-48-4" href="#__codelineno-48-4"></a>  <span class="n">output_dir</span><span class="o">=</span><span class="n">repo_name</span><span class="p">,</span>
</span><span id="__span-48-5"><a id="__codelineno-48-5" name="__codelineno-48-5" href="#__codelineno-48-5"></a>  <span class="n">group_by_length</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-48-6"><a id="__codelineno-48-6" name="__codelineno-48-6" href="#__codelineno-48-6"></a>  <span class="n">per_device_train_batch_size</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span>
</span><span id="__span-48-7"><a id="__codelineno-48-7" name="__codelineno-48-7" href="#__codelineno-48-7"></a>  <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;steps&quot;</span><span class="p">,</span>
</span><span id="__span-48-8"><a id="__codelineno-48-8" name="__codelineno-48-8" href="#__codelineno-48-8"></a>  <span class="n">num_train_epochs</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
</span><span id="__span-48-9"><a id="__codelineno-48-9" name="__codelineno-48-9" href="#__codelineno-48-9"></a>  <span class="n">gradient_checkpointing</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-48-10"><a id="__codelineno-48-10" name="__codelineno-48-10" href="#__codelineno-48-10"></a>  <span class="n">fp16</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-48-11"><a id="__codelineno-48-11" name="__codelineno-48-11" href="#__codelineno-48-11"></a>  <span class="n">save_steps</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span>
</span><span id="__span-48-12"><a id="__codelineno-48-12" name="__codelineno-48-12" href="#__codelineno-48-12"></a>  <span class="n">eval_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-48-13"><a id="__codelineno-48-13" name="__codelineno-48-13" href="#__codelineno-48-13"></a>  <span class="n">logging_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-48-14"><a id="__codelineno-48-14" name="__codelineno-48-14" href="#__codelineno-48-14"></a>  <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
</span><span id="__span-48-15"><a id="__codelineno-48-15" name="__codelineno-48-15" href="#__codelineno-48-15"></a>  <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
</span><span id="__span-48-16"><a id="__codelineno-48-16" name="__codelineno-48-16" href="#__codelineno-48-16"></a>  <span class="n">save_total_limit</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span><span id="__span-48-17"><a id="__codelineno-48-17" name="__codelineno-48-17" href="#__codelineno-48-17"></a>  <span class="n">push_to_hub</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-48-18"><a id="__codelineno-48-18" name="__codelineno-48-18" href="#__codelineno-48-18"></a><span class="p">)</span>
</span></code></pre></div>
<p>现在，所有实例都可以传递给 Trainer，我们准备开始训练！</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-49-1"><a id="__codelineno-49-1" name="__codelineno-49-1" href="#__codelineno-49-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">Trainer</span>
</span><span id="__span-49-2"><a id="__codelineno-49-2" name="__codelineno-49-2" href="#__codelineno-49-2"></a>
</span><span id="__span-49-3"><a id="__codelineno-49-3" name="__codelineno-49-3" href="#__codelineno-49-3"></a><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
</span><span id="__span-49-4"><a id="__codelineno-49-4" name="__codelineno-49-4" href="#__codelineno-49-4"></a>    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-49-5"><a id="__codelineno-49-5" name="__codelineno-49-5" href="#__codelineno-49-5"></a>    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
</span><span id="__span-49-6"><a id="__codelineno-49-6" name="__codelineno-49-6" href="#__codelineno-49-6"></a>    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
</span><span id="__span-49-7"><a id="__codelineno-49-7" name="__codelineno-49-7" href="#__codelineno-49-7"></a>    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
</span><span id="__span-49-8"><a id="__codelineno-49-8" name="__codelineno-49-8" href="#__codelineno-49-8"></a>    <span class="n">train_dataset</span><span class="o">=</span><span class="n">common_voice_train</span><span class="p">,</span>
</span><span id="__span-49-9"><a id="__codelineno-49-9" name="__codelineno-49-9" href="#__codelineno-49-9"></a>    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">common_voice_test</span><span class="p">,</span>
</span><span id="__span-49-10"><a id="__codelineno-49-10" name="__codelineno-49-10" href="#__codelineno-49-10"></a>    <span class="n">tokenizer</span><span class="o">=</span><span class="n">processor</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">,</span>
</span><span id="__span-49-11"><a id="__codelineno-49-11" name="__codelineno-49-11" href="#__codelineno-49-11"></a><span class="p">)</span>
</span></code></pre></div>
<hr />
<p><span class="arithmatex">\( {}^1 \)</span> 为了使模型独立于说话人速率，在 CTC 中，相同的连续标记简单地分组为单个标记。然而，在解码时不应该对编码的标签进行分组，因为它们不对应于模型的预测标记，这就是为什么必须传递 <code>group_tokens=False</code> 参数。如果我们不传递这个参数，像 <code>"hello"</code> 这样的单词会被错误地编码，并解码为 <code>"helo"</code>。</p>
<p><span class="arithmatex">\( {}^2 \)</span> 空白标记允许模型通过强制在两个 l 之间插入空白标记来预测一个词，例如 <code>"hello"</code>。我们模型的 CTC 符合预测 <code>"hello"</code> 将是 <code>[PAD] [PAD]"h" "e" "e" "l" "l" [PAD]"l" "o" "o" [PAD]</code>。</p>
<h3 id="_6">训练<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h3>
<p>训练时间应该少于 30 分钟，具体取决于所使用的 GPU。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-50-1"><a id="__codelineno-50-1" name="__codelineno-50-1" href="#__codelineno-50-1"></a><span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
</span></code></pre></div>
<table>
<thead>
<tr>
<th style="text-align: center;">训练损失</th>
<th style="text-align: center;">训练步数</th>
<th style="text-align: center;">验证损失</th>
<th style="text-align: center;">Wer</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">4.905</td>
<td style="text-align: center;">100</td>
<td style="text-align: center;">0.215</td>
<td style="text-align: center;">0.280</td>
</tr>
<tr>
<td style="text-align: center;">0.290</td>
<td style="text-align: center;">200</td>
<td style="text-align: center;">0.167</td>
<td style="text-align: center;">0.232</td>
</tr>
<tr>
<td style="text-align: center;">0.2659</td>
<td style="text-align: center;">300</td>
<td style="text-align: center;">0.161</td>
<td style="text-align: center;">0.229</td>
</tr>
<tr>
<td style="text-align: center;">0.2398</td>
<td style="text-align: center;">400</td>
<td style="text-align: center;">0.156</td>
<td style="text-align: center;">0.223</td>
</tr>
</tbody>
</table>
<p>训练损失和验证 WER 都很好地下降。</p>
<p>我们看到，仅微调 <code>mms-1b-all</code> 的适配器层 100 步就大大超过了 <a href="https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2#training-1">这里</a> 显示的微调整个 <code>xls-r-300m</code> 检查点。</p>
<p>从 <a href="https://scontent-cdg4-3.xx.fbcdn.net/v/t39.8562-6/348827959_6967534189927933_6819186233244071998_n.pdf?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=ad8a9d&amp;_nc_ohc=fSo3qQ7uxr0AX8EWnWl&amp;_nc_ht=scontent-cdg4-3.xx&amp;oh=00_AfBL34K0MAAPb0CgnthjbHfiB6pSnnwbn5esj9DZVPvyoA&amp;oe=6495E802">官方论文</a> 和这个快速比较中可以清楚地看出， <code>mms-1b-all</code> 具有更高的将知识转移到低资源语言的能力，应该优先于 <code>xls-r-300m</code>。此外，训练也更节省内存，因为只训练了一小部分层。</p>
<p>适配器权重将作为模型检查点的一部分上传，但我们也希望确保单独保存它们，以便它们可以轻松地上下线。</p>
<p>让我们将所有适配器层保存到训练输出目录中，以便它能够正确上传到 Hub。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-51-1"><a id="__codelineno-51-1" name="__codelineno-51-1" href="#__codelineno-51-1"></a><span class="kn">from</span> <span class="nn">safetensors.torch</span> <span class="kn">import</span> <span class="n">save_file</span> <span class="k">as</span> <span class="n">safe_save_file</span>
</span><span id="__span-51-2"><a id="__codelineno-51-2" name="__codelineno-51-2" href="#__codelineno-51-2"></a><span class="kn">from</span> <span class="nn">transformers.models.wav2vec2.modeling_wav2vec2</span> <span class="kn">import</span> <span class="n">WAV2VEC2_ADAPTER_SAFE_FILE</span>
</span><span id="__span-51-3"><a id="__codelineno-51-3" name="__codelineno-51-3" href="#__codelineno-51-3"></a><span class="kn">import</span> <span class="nn">os</span>
</span><span id="__span-51-4"><a id="__codelineno-51-4" name="__codelineno-51-4" href="#__codelineno-51-4"></a>
</span><span id="__span-51-5"><a id="__codelineno-51-5" name="__codelineno-51-5" href="#__codelineno-51-5"></a><span class="n">adapter_file</span> <span class="o">=</span> <span class="n">WAV2VEC2_ADAPTER_SAFE_FILE</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">target_lang</span><span class="p">)</span>
</span><span id="__span-51-6"><a id="__codelineno-51-6" name="__codelineno-51-6" href="#__codelineno-51-6"></a><span class="n">adapter_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">training_args</span><span class="o">.</span><span class="n">output_dir</span><span class="p">,</span> <span class="n">adapter_file</span><span class="p">)</span>
</span><span id="__span-51-7"><a id="__codelineno-51-7" name="__codelineno-51-7" href="#__codelineno-51-7"></a>
</span><span id="__span-51-8"><a id="__codelineno-51-8" name="__codelineno-51-8" href="#__codelineno-51-8"></a><span class="n">safe_save_file</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">_get_adapters</span><span class="p">(),</span> <span class="n">adapter_file</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;pt&quot;</span><span class="p">})</span>
</span></code></pre></div>
<p>最后，你可以将训练结果上传到🤗 Hub。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-52-1"><a id="__codelineno-52-1" name="__codelineno-52-1" href="#__codelineno-52-1"></a><span class="n">trainer</span><span class="o">.</span><span class="n">push_to_hub</span><span class="p">()</span>
</span></code></pre></div>
<p>适配器权重训练的主要优点之一是“基础”模型 (约占模型权重的 99%) 保持不变，只需共享一个小的 <a href="https://huggingface.co/patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab/blob/main/adapter.tur.safetensors">2.5M 适配器检查点</a> 即可使用训练好的检查点。</p>
<p>这使得训练额外的适配器层并将它们添加到你的仓库变得非常简单。</p>
<p>你可以通过简单地重新运行此脚本并将你想要训练的语言更改为另一种语言来轻松实现，例如 <code>swe</code> 表示瑞典语。此外，你应该确保词汇表不会被完全覆盖，而是新语言词汇表应该像上面注释掉的单元格中所述那样 <strong>附加</strong> 到现有词汇表中。</p>
<p>为了演示如何加载不同的适配器层，我还训练并上传了一个瑞典语适配器层，其 iso 语言代码为 <code>swe</code>，如 <a href="https://huggingface.co/patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab/blob/main/adapter.swe.safetensors">此处</a> 所示</p>
<p>你可以像往常一样使用 <code>from_pretrained(...)</code> 加载微调后的检查点，但应确保在方法中添加 <code>target_lang="&lt;your-lang-code&gt;"</code>，以便加载正确的适配器。你还应该为分词器正确设置目标语言。</p>
<p>让我们看看如何首先加载土耳其检查点。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-53-1"><a id="__codelineno-53-1" name="__codelineno-53-1" href="#__codelineno-53-1"></a><span class="n">model_id</span> <span class="o">=</span> <span class="s2">&quot;patrickvonplaten/wav2vec2-large-mms-1b-turkish-colab&quot;</span>
</span><span id="__span-53-2"><a id="__codelineno-53-2" name="__codelineno-53-2" href="#__codelineno-53-2"></a>
</span><span id="__span-53-3"><a id="__codelineno-53-3" name="__codelineno-53-3" href="#__codelineno-53-3"></a><span class="n">model</span> <span class="o">=</span> <span class="n">Wav2Vec2ForCTC</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">,</span> <span class="n">target_lang</span><span class="o">=</span><span class="s2">&quot;tur&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">)</span>
</span><span id="__span-53-4"><a id="__codelineno-53-4" name="__codelineno-53-4" href="#__codelineno-53-4"></a><span class="n">processor</span> <span class="o">=</span> <span class="n">Wav2Vec2Processor</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_id</span><span class="p">)</span>
</span><span id="__span-53-5"><a id="__codelineno-53-5" name="__codelineno-53-5" href="#__codelineno-53-5"></a>
</span><span id="__span-53-6"><a id="__codelineno-53-6" name="__codelineno-53-6" href="#__codelineno-53-6"></a><span class="n">processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">set_target_lang</span><span class="p">(</span><span class="s2">&quot;tur&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>让我们检查模型是否可以正确转录土耳其语</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-54-1"><a id="__codelineno-54-1" name="__codelineno-54-1" href="#__codelineno-54-1"></a><span class="kn">from</span> <span class="nn">datasets</span> <span class="kn">import</span> <span class="n">Audio</span>
</span><span id="__span-54-2"><a id="__codelineno-54-2" name="__codelineno-54-2" href="#__codelineno-54-2"></a>
</span><span id="__span-54-3"><a id="__codelineno-54-3" name="__codelineno-54-3" href="#__codelineno-54-3"></a><span class="n">common_voice_test_tr</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mozilla-foundation/common_voice_6_1&quot;</span><span class="p">,</span> <span class="s2">&quot;tr&quot;</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="s2">&quot;./cv-corpus-6.1-2020-12-11&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">use_auth_token</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-54-4"><a id="__codelineno-54-4" name="__codelineno-54-4" href="#__codelineno-54-4"></a><span class="n">common_voice_test_tr</span> <span class="o">=</span> <span class="n">common_voice_test_tr</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>
</span></code></pre></div>
<p>让我们处理音频，运行前向传递并预测 ids</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-55-1"><a id="__codelineno-55-1" name="__codelineno-55-1" href="#__codelineno-55-1"></a><span class="n">input_dict</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">common_voice_test_tr</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">],</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-55-2"><a id="__codelineno-55-2" name="__codelineno-55-2" href="#__codelineno-55-2"></a>
</span><span id="__span-55-3"><a id="__codelineno-55-3" name="__codelineno-55-3" href="#__codelineno-55-3"></a><span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_dict</span><span class="o">.</span><span class="n">input_values</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">logits</span>
</span><span id="__span-55-4"><a id="__codelineno-55-4" name="__codelineno-55-4" href="#__codelineno-55-4"></a>
</span><span id="__span-55-5"><a id="__codelineno-55-5" name="__codelineno-55-5" href="#__codelineno-55-5"></a><span class="n">pred_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span></code></pre></div>
<p>最后，我们可以解码该示例。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-56-1"><a id="__codelineno-56-1" name="__codelineno-56-1" href="#__codelineno-56-1"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction:&quot;</span><span class="p">)</span>
</span><span id="__span-56-2"><a id="__codelineno-56-2" name="__codelineno-56-2" href="#__codelineno-56-2"></a><span class="nb">print</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">pred_ids</span><span class="p">))</span>
</span><span id="__span-56-3"><a id="__codelineno-56-3" name="__codelineno-56-3" href="#__codelineno-56-3"></a>
</span><span id="__span-56-4"><a id="__codelineno-56-4" name="__codelineno-56-4" href="#__codelineno-56-4"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reference:&quot;</span><span class="p">)</span>
</span><span id="__span-56-5"><a id="__codelineno-56-5" name="__codelineno-56-5" href="#__codelineno-56-5"></a><span class="nb">print</span><span class="p">(</span><span class="n">common_voice_test_tr</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span></code></pre></div>
<p><strong>输出</strong>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-57-1"><a id="__codelineno-57-1" name="__codelineno-57-1" href="#__codelineno-57-1"></a><span class="w">    </span>Prediction:
</span><span id="__span-57-2"><a id="__codelineno-57-2" name="__codelineno-57-2" href="#__codelineno-57-2"></a><span class="w">    </span>pekçoğuda<span class="w"> </span>roman<span class="w"> </span>toplumundan<span class="w"> </span>geliyor
</span><span id="__span-57-3"><a id="__codelineno-57-3" name="__codelineno-57-3" href="#__codelineno-57-3"></a>
</span><span id="__span-57-4"><a id="__codelineno-57-4" name="__codelineno-57-4" href="#__codelineno-57-4"></a><span class="w">    </span>Reference:
</span><span id="__span-57-5"><a id="__codelineno-57-5" name="__codelineno-57-5" href="#__codelineno-57-5"></a><span class="w">    </span>pek<span class="w"> </span>çoğu<span class="w"> </span>da<span class="w"> </span>roman<span class="w"> </span>toplumundan<span class="w"> </span>geliyor.
</span></code></pre></div>
<p>这看起来几乎完全正确，只是第一个单词中应该添加两个空格。
现在，通过调用 <a href="mozilla-foundation/common_voice_6_1"><code>model.load_adapter(...)</code></a> 并将分词器更改为瑞典语，可以非常简单地将适配器更改为瑞典语。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-58-1"><a id="__codelineno-58-1" name="__codelineno-58-1" href="#__codelineno-58-1"></a><span class="n">model</span><span class="o">.</span><span class="n">load_adapter</span><span class="p">(</span><span class="s2">&quot;swe&quot;</span><span class="p">)</span>
</span><span id="__span-58-2"><a id="__codelineno-58-2" name="__codelineno-58-2" href="#__codelineno-58-2"></a><span class="n">processor</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">set_target_lang</span><span class="p">(</span><span class="s2">&quot;swe&quot;</span><span class="p">)</span>
</span></code></pre></div>
<p>我们再次从普通语音加载瑞典语测试集</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-59-1"><a id="__codelineno-59-1" name="__codelineno-59-1" href="#__codelineno-59-1"></a><span class="n">common_voice_test_swe</span> <span class="o">=</span> <span class="n">load_dataset</span><span class="p">(</span><span class="s2">&quot;mozilla-foundation/common_voice_6_1&quot;</span><span class="p">,</span> <span class="s2">&quot;sv-SE&quot;</span><span class="p">,</span> <span class="n">data_dir</span><span class="o">=</span><span class="s2">&quot;./cv-corpus-6.1-2020-12-11&quot;</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span> <span class="n">use_auth_token</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-59-2"><a id="__codelineno-59-2" name="__codelineno-59-2" href="#__codelineno-59-2"></a><span class="n">common_voice_test_swe</span> <span class="o">=</span> <span class="n">common_voice_test_swe</span><span class="o">.</span><span class="n">cast_column</span><span class="p">(</span><span class="s2">&quot;audio&quot;</span><span class="p">,</span> <span class="n">Audio</span><span class="p">(</span><span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">))</span>
</span></code></pre></div>
<p>并转录一个样本:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-60-1"><a id="__codelineno-60-1" name="__codelineno-60-1" href="#__codelineno-60-1"></a><span class="n">input_dict</span> <span class="o">=</span> <span class="n">processor</span><span class="p">(</span><span class="n">common_voice_test_swe</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;audio&quot;</span><span class="p">][</span><span class="s2">&quot;array&quot;</span><span class="p">],</span> <span class="n">sampling_rate</span><span class="o">=</span><span class="mi">16_000</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-60-2"><a id="__codelineno-60-2" name="__codelineno-60-2" href="#__codelineno-60-2"></a>
</span><span id="__span-60-3"><a id="__codelineno-60-3" name="__codelineno-60-3" href="#__codelineno-60-3"></a><span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_dict</span><span class="o">.</span><span class="n">input_values</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">))</span><span class="o">.</span><span class="n">logits</span>
</span><span id="__span-60-4"><a id="__codelineno-60-4" name="__codelineno-60-4" href="#__codelineno-60-4"></a>
</span><span id="__span-60-5"><a id="__codelineno-60-5" name="__codelineno-60-5" href="#__codelineno-60-5"></a><span class="n">pred_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-60-6"><a id="__codelineno-60-6" name="__codelineno-60-6" href="#__codelineno-60-6"></a>
</span><span id="__span-60-7"><a id="__codelineno-60-7" name="__codelineno-60-7" href="#__codelineno-60-7"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Prediction:&quot;</span><span class="p">)</span>
</span><span id="__span-60-8"><a id="__codelineno-60-8" name="__codelineno-60-8" href="#__codelineno-60-8"></a><span class="nb">print</span><span class="p">(</span><span class="n">processor</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">pred_ids</span><span class="p">))</span>
</span><span id="__span-60-9"><a id="__codelineno-60-9" name="__codelineno-60-9" href="#__codelineno-60-9"></a>
</span><span id="__span-60-10"><a id="__codelineno-60-10" name="__codelineno-60-10" href="#__codelineno-60-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Reference:&quot;</span><span class="p">)</span>
</span><span id="__span-60-11"><a id="__codelineno-60-11" name="__codelineno-60-11" href="#__codelineno-60-11"></a><span class="nb">print</span><span class="p">(</span><span class="n">common_voice_test_swe</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;sentence&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">())</span>
</span></code></pre></div>
<p><strong>输出</strong>:</p>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-61-1"><a id="__codelineno-61-1" name="__codelineno-61-1" href="#__codelineno-61-1"></a><span class="w">    </span>Prediction:
</span><span id="__span-61-2"><a id="__codelineno-61-2" name="__codelineno-61-2" href="#__codelineno-61-2"></a><span class="w">    </span>jag<span class="w"> </span>lämnade<span class="w"> </span>grovjobbet<span class="w"> </span>åt<span class="w"> </span>honom
</span><span id="__span-61-3"><a id="__codelineno-61-3" name="__codelineno-61-3" href="#__codelineno-61-3"></a>
</span><span id="__span-61-4"><a id="__codelineno-61-4" name="__codelineno-61-4" href="#__codelineno-61-4"></a><span class="w">    </span>Reference:
</span><span id="__span-61-5"><a id="__codelineno-61-5" name="__codelineno-61-5" href="#__codelineno-61-5"></a><span class="w">    </span>jag<span class="w"> </span>lämnade<span class="w"> </span>grovjobbet<span class="w"> </span>åt<span class="w"> </span>honom.
</span></code></pre></div>
<p>太好了，这看起来像是一个完美的转录！</p>
<p>我们在这篇博客文章中展示了 MMS 适配器权重微调不仅在低资源语言上提供了最先进的性能，而且还显著缩短了训练时间，并允许轻松构建定制的适配器权重集合。</p>
<p><em>相关帖子和附加链接列在这里:</em></p>
<ul>
<li><a href="https://huggingface.co/papers/2305.13516"><strong>官方论文</strong></a></li>
<li><a href="https://github.com/facebookresearch/fairseq/tree/main/examples/mms/asr"><strong>原始 cobebase</strong></a></li>
<li><a href="https://huggingface.co/spaces/facebook/MMS"><strong>官方演示</strong></a></li>
<li><a href="https://huggingface.co/docs/transformers/index"><strong>Transformers 文档</strong></a></li>
<li><a href="https://huggingface.co/blog/zh/fine-tune-xlsr-wav2vec2"><strong>相关 XLS-R 博客文章</strong></a></li>
<li><a href="https://huggingface.co/models?other=mms"><strong>Hub 上的模型</strong></a></li>
</ul>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9 3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3 3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3 3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.54 5.54 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13zM0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9-.59.68-.95 1.62-.95 2.65V20zm24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65 2.56.34 4.45 1.51 4.45 2.9z"/></svg>
      
    </span>
    <nav>
      
    </nav>
  </span>

    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank" rel="noopener">feedback form</a>.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../ml-for-games-5/" class="md-footer__link md-footer__link--prev" aria-label="Previous: ChatGPT 设计游戏剧情 | 基于 AI 5 天创建一个农场游戏，完结篇！">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                ChatGPT 设计游戏剧情 | 基于 AI 5 天创建一个农场游戏，完结篇！
              </div>
            </div>
          </a>
        
        
          
          <a href="../moe/" class="md-footer__link md-footer__link--next" aria-label="Next: 混合专家模型（MoE）详解">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                混合专家模型（MoE）详解
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 - 2024 FastX-AI
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
    
    
    
    <a href="https://fastx-ai.com" target="_blank" rel="noopener me" title="fastx-ai" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:x.stark.dylan@gmail.com" target="_blank" rel="noopener" title="send me an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 112c-8.8 0-16 7.2-16 16v22.1l172.5 141.6c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16zM48 212.2V384c0 8.8 7.2 16 16 16h384c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0zM0 128c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64z"/></svg>
    </a>
  
    
    
    
    
    <a href="/contact" target="_blank" rel="noopener" title="contact us" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 4H7a5 5 0 0 0-5 5v11h18a2 2 0 0 0 2-2V9a5 5 0 0 0-5-5m-7 14H4V9a3 3 0 0 1 3-3 3 3 0 0 1 3 3zm9-3h-2v-2h-4v-2h6zM9 11H5V9h4z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.prune", "content.action.edit", "content.code.copy", "content.code.annotate", "content.tabs.link", "content.tooltips", "header.autohide", "announce.dismiss", "search.suggest", "search.highlight", "search.share", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
<!-- Add scripts that need to run before here -->

      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
<!-- Add scripts that need to run afterwards here -->

  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>