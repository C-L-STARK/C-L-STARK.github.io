
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="FastDoc is a website that you can get started with FastX AI in minutes.">
      
      
      
        <link rel="canonical" href="https://doc.fastx-ai.com/ml/encoder-decoder/">
      
      
        <link rel="prev" href="../embedding-quantization/">
      
      
        <link rel="next" href="../encrypted-llm/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>基于 Transformers 的编码器-解码器模型 - FastDocs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="基于 Transformers 的编码器-解码器模型 - FastDocs" >
      
        <meta  property="og:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  property="og:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/encoder-decoder.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://doc.fastx-ai.com/ml/encoder-decoder/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="基于 Transformers 的编码器-解码器模型 - FastDocs" >
      
        <meta  name="twitter:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  name="twitter:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/encoder-decoder.png" >
      
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#transformers-" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
              </button>
            
            
<p style="text-align: center">
  Welcome to <span style="font-size: bold">FastDocs</span>! Just feel free to start read docs!
</p>

          </div>
          
            <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="FastDocs" class="md-header__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FastDocs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              基于 Transformers 的编码器-解码器模型
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  主页

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../backend/" class="md-tabs__link">
        
  
    
  
  后端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../web/" class="md-tabs__link">
        
  
    
  
  前端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../client/" class="md-tabs__link">
        
  
    
  
  客户端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../pc/" class="md-tabs__link">
        
  
    
  
  桌面端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../big-data/" class="md-tabs__link">
        
  
    
  
  大数据

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_58_llm_extreme_quantization/" class="md-tabs__link">
          
  
    
  
  人工智能

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../ops/" class="md-tabs__link">
        
  
    
  
  运维

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  博客

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../resume/" class="md-tabs__link">
        
  
    
  
  简历模板

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="FastDocs" class="md-nav__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FastDocs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../backend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    后端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../web/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../client/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    客户端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    桌面端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../big-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大数据
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    人工智能
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            人工智能
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_58_llm_extreme_quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning LLMs to 1.58bit: extreme quantization made easy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2023-in-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023, 开源大模型之年
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3d-assets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手把手教你使用人工智能生成 3D 素材
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4bit-transformers-bitsandbytes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Llama2-for-non-engineers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非工程师指南：训练 LLaMA 2 聊天机器人
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Lora-for-sequence-classification-with-Roberta-Llama-Mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在灾难推文分析场景上比较用 LoRA 微调 Roberta、Llama 2 和 Mistral 的过程及表现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../_policy-ntia-rfc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能政策@🤗：回应美国国家电信和信息管理局（ NTIA ）关于人工智能问责制的评论请求
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerate-v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate 1.0.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerated-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何成功将 🤗 API 客户的 transformer 模型推理速度加快 100 倍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    授权调用：介绍 Transformers 智能体 2.0  
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aivsai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 大战 AI，一个深度强化学习多智能体竞赛系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../arena-tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS 擂台: 文本转语音模型的自由搏击场
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../asr-diarization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 推理终端搭建强大的“语音识别 + 说话人分割 + 投机解码”工作流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation-support-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    英特尔 Gaudi 加速辅助生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    辅助生成：低延迟文本生成的新方向
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audioldm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AudioLDM 2，加速⚡️！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer 模型能够有效地进行时间序列预测 (使用 Autoformer)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beating-gaia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers 代码智能体成功刷榜 GAIA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../big-bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解 BigBird 的块稀疏注意力
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BLIP-2 零样本“图生文”
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化故事: BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-pytorch-scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DeepSpeed 和 Accelerate 进行超快 BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-megatron-deepspeed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    千亿参数开源大模型 BLOOM 背后的技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Habana Gaudi2 加速视觉语言模型 BridgeTower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chat-templates/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天模板：无声性能杀手的终结
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-ai-expansion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中国 AI 出海现状概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-language-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中文博客正式发布！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cloudflare-workers-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为 Hugging Face 用户带来无服务器 GPU 推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codellama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Llama：Llama 2 学会写代码了！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../community-datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据好合：Argilla 和 Hugging Face Spaces 赋能社区合力构建更好的数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../constrained-beam-search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 🤗 Transformers 中使用约束波束搜索引导文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🧨 Diffusers 实现 ControlNet 高速推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cosmopedia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cosmopedia：如何为大语言模型预训练构建大规模合成数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cost-efficient-rag-applications-with-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用英特尔 Gaudi 2 和至强 CPU 构建经济高效的企业级 RAG 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cv_state/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中计算机视觉的现状
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../daily-papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 论文平台 Daily Papers 功能全解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dedup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCode 背后的大规模数据去重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep-learning-with-proteins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    蛋白质深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepspeed-to-fsdp-and-back/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 DeepSpeed 到 FSDP，再回到 Hugging Face Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-deepfloydif-using-bentoml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BentoML 部署 🤗 Hugging Face 上的模型：DeepFloyd IF 实战
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-with-openvino/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Optimum-Intel 和 OpenVINO GenAI 优化和部署模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dialog-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    是什么让对话代理有用？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffusers-turns-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Diffusers 一岁啦 !
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docmatix - 超大文档视觉问答数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../document-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加速 Document AI (文档智能) 发展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo-trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DPO 微调 Llama 2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo_vlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为视觉语言多模态模型进行偏好优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dreambooth/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Diffusers 通过 Dreambooth 技术来训练 Stable Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic_speculation_lookahead/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的辅助生成: 动态推测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../elixir-bumblebee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 GPT2 到 Stable Diffusion：Elixir 社区迎来了 Hugging Face
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用于显著提高检索速度和降低成本的二进制和标量嵌入量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    基于 Transformers 的编码器-解码器模型
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encrypted-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 FHE 实现加密大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开发 Diffusers 库的道德行为指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    道德与社会问题简报 #3: Hugging Face 上的道德开放性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ethics and Society Newsletter #4: Bias in Text-to-Image Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon-180b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 180B 登陆 Hugging Face Hub 🔥
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 登陆 Hugging Face 生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falconmamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon Mamba: 首个高效的无注意力机制 7B 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-tune-whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 为多语种语音识别任务微调 Whisper 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    揭秘 FineVideo 数据集构建的背后的秘密
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune-florence2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调 Florence-2 - 微软的尖端视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../game-jam-first-edition-results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首届开源 AI 游戏挑战赛事结果
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gaussian-splatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3D 高斯点染简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-july-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 最新发布： Gemma 2 2B, ShieldGemma 和 Gemma Scope
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 微调 Gemma 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Gemma: Google 最新推出开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 发布最新开放大语言模型 Gemma 2，现已登陆 Hugging Face Hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generative-ai-models-on-intel-cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    越小越好：Q8-Chat，在英特尔至强 CPU 上体验高效的生成式 AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started-habana/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Habana Gaudi 的 Transformers 入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../google-cloud-model-garden/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Google Cloud 上轻松部署开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptq-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 AutoGPTQ 和 transformers 让大语言模型更轻量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio 5 现已发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-lite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio-Lite: 完全在浏览器里运行的无服务器 Gradio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-reload/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Gradio 的“热重载”模式快速开发 AI 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphml-classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Transformers 进行图分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-benchmark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的训练和推理：对比 Habana Gaudi®2 和英伟达 A100 80GB
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型快速推理：在 Habana Gaudi2 上推理 BLOOMZ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hf-bitsandbytes-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模 Transformer 模型 8 比特矩阵乘简介 - 基于 Hugging Face Transformers、Accelerate 以及 bitsandbytes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../how-to-generate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何生成文本：通过 Transformers 用不同的解码方法生成文本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hugging-face-wiz-security-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 Wiz Research 合作提高人工智能安全性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../huggy-lingo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Huggy Lingo：利用机器学习改进 Hugging Face Hub 上的语言元数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IDEFICS 简介：最先进视觉语言模型的开源复现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Idefics2 简介：为社区而生的强大 8B 视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在免费版 Google Colab 上使用 🧨 diffusers 运行 IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../image-similarity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Hugging Face Datasets 和 Transformers 的图像相似性搜索
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-endpoints-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Hugging Face 推理端点部署 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 提供的推理（Inference）解决方案
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infini-attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一次失败的实验——无限注意力，我们为什么坚持实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../informer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Informer 进行多元概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../instruction-tuning-sd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 InstructPix2Pix 对 Stable Diffusion 进行指令微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-fast-embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用 🤗 Optimum Intel 和 fastRAG 在 CPU 上优化文本嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-protein-language-model-protst/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 Gaudi 2 上加速蛋白质语言模型 ProtST
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 推理 | 使用英特尔 Sapphire Rapids 加速 PyTorch Transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用英特尔 Sapphire Rapids 加速 PyTorch Transformers 模型（第一部分）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-starcoder-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Optimum Intel 在英特尔至强上加速 StarCoder：Q8/Q4 及投机解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intro-graphml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一文带你入门图机器学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introducing-csearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Transformers 中使用对比搜索生成可媲美人类水平的文本🤗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-to-ggml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ggml 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    万事通，专精部分领域的多功能 Transformer 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kv-cache-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 KV 缓存量化解锁长文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face x LangChain：全新 LangChain 合作伙伴包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../large-language-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型：新的摩尔定律？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lcm_lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LCM LoRA 4 步完成 SDXL 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-bigcodebench/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCodeBench: 继 HumanEval 之后的新一代代码生成基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-decodingtrust/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    来自 AI Secure 实验室的 LLM 安全排行榜简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-medicalllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源医疗大模型排行榜：健康领域大模型基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-patronus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    企业场景排行榜简介：现实世界用例排行榜
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 2 来袭 - 在 Hugging Face 上玩转它
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Llama 3：Meta 的新一代开源大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 3.1：405B/70B/8B 模型的多语言与长上下文能力解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    现在 Llama 具备视觉能力并可以在你的设备上运行 - 欢迎使用 Llama 3.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../long-range-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    长程 transformer 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LoRA 进行 Stable Diffusion 的高效参数微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mask2former/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用图像分割任务：使用 Mask2Former 和 OneFormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matryoshka/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🪆 俄罗斯套娃嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何使用 Megatron-LM 训练语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Mixtral - 当前 Hugging Face 上最先进的 MoE 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于AI进行游戏开发：5天！创建一个农场游戏！第1部分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ChatGPT 启发游戏创意｜基于 AI 5 天创建一个农场游戏，第 2 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 制作 3D 素材｜基于 AI 5 天创建一个农场游戏，第 3 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    制作 2D 素材｜基于 AI 5 天创建一个农场游戏，第 4 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 设计游戏剧情 | 基于 AI 5 天创建一个农场游戏，完结篇！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mms_adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调用于多语言 ASR 的 MMS 适配器模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合专家模型（MoE）详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-lora-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 多-LoRA：部署一次，搞定 30 个模型的推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../noob_intro_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face Transformers 萌新完全指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-drop/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开放 LLM 排行榜：深入研究 DROP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-mmlu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open LLM 排行榜近况
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础大模型能像人类一样标注数据吗？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-source-llms-as-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源大语言模型作为 LangChain 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimize-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向生产的 LLM 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizing-bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 优化 Bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimum-onnxruntime-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimum + ONNX Runtime: 更容易、更快地训练你的 Hugging Face 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../os-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 的文本生成和大语言模型的开源生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview-quantization-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Transformers 中原生支持的量化方案概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../packing-with-FA2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过打包 Flash Attention 来提升 Hugging Face 训练效率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../paligemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PaliGemma 正式发布 — Google 最新发布的前沿开放视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../password-git-deprecation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hub 上的 Git 操作不再支持使用密码验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 PEFT：在低资源硬件上对十亿规模模型进行参数高效微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../personal-copilot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    个人编程助手：训练你自己的编码助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi2-intel-meteor-lake/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    笔记本电脑上的聊天机器人：在英特尔 Meteor Lake 上运行 Phi-2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../presidio-pii-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hub 上使用 Presidio 进行自动 PII 检测实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../putting_rl_back_in_rlhf_with_rloo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将强化学习重新引入 RLHF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pycharm-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 PyCharm 深度集成：轻松引入丰富的 AI 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-ddp-accelerate-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 PyTorch DDP 到 Accelerate 到 Trainer，轻松掌握分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 完全分片数据并行技术加速大模型训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Quanto 和 Diffusers 的内存高效 transformer 扩散模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quanto：PyTorch 量化工具包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ram-efficient-pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch FSDP 微调 Llama 2 70B
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../red-teaming/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为大语言模型建立红队对抗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reformer 模型 - 突破语言建模的极限
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HF Hub 现已加入存储区域功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../researcher-dataset-sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hugging Face Hub 分享你的开源数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 背后的“功臣”——RLHF 技术详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RWKV -- transformer 与 RNN 的强强联合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ryght-case-study/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ryght 在 Hugging Face 专家助力下赋能医疗保健和生命科学之旅
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../safecoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    推介 SafeCoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sc2-instruct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3.5 Large 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd_distillation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源 SD-Small 和 SD-Tiny 知识蒸馏代码与权重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sdxl_lora_advanced_script/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    全世界 LoRA 训练脚本，联合起来!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-absa/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFitABSA：基于 SetFit 的少样本、方面级情感分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-optimum-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔至强 CPU 上使用 🤗 Optimum Intel 实现超快 SetFit 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFit: 高效的无提示少样本学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../smollm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SmolLM：一个超快速、超高性能的小模型集合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speecht5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 SpeechT5 进行语音合成、识别和更多功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sql-console/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为数据集而生的 SQL 控制台
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-finetuning-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-inference-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上加速 Stable Diffusion 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用Diffusers来实现Stable Diffusion 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stackllama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    “StackLLaMA”: 用 RLHF 训练 LLaMA 的手把手教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starchat-alpha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 StarCoder 创建一个编程助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder：最先进的代码大模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2 及 The Stack v2 数据集正式发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthetic-data-save-costs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    合成数据：利用开源技术节约资金、时间和减少碳排放
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthid-text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SynthID Text：在 AI 生成文本中应用不可见水印的新技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t2i-sdxl-adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 SDXL 上用 T2I-Adapter 实现高效可控的文生图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text-to-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解文生视频模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../textgen-pipe-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于英特尔® Gaudi® 2 AI 加速器的文本生成流水线
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tgi-benchmarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the-age-of-ml-as-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    机器学习即代码的时代已经到来
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the_n_implementation_details_of_rlhf_with_ppo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PPO 算法进行 RLHF 的 N 步实现细节
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../time-series-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 进行概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-dgx-cloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 NVIDIA DGX Cloud上使用 H100 GPU 轻松训练模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-optimize-sd-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 NNCF 和 🤗 Optimum 面向 Intel CPU 对 Stable Diffusion 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-sentence-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Sentence Transformers v3 训练和微调嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-your-controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 diffusers 训练你自己的 ControlNet 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers-design-philosophy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    〜不要〜重复自己
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-ddpo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DDPO 在 TRL 中微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trufflesecurity-partnership/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 TruffleHog 成为合作伙伴，实现风险信息预警
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unified-tool-use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对 LLM 工具使用进行统一
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何安装和使用 Hugging Face Unity API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 Unity 游戏中集成 AI 语音识别？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-in-spaces/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 🤗 Space 上托管 Unity 游戏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../universal_assisted_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用辅助生成：使用任意辅助模型加速解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vertex-colored-to-textured-mesh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    顶点着色网格转换为 UV 映射的纹理化网格
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_language_pretraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入了解视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit-align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kakao Brain 的开源 ViT、ALIGN 和 COYO 文字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vlms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    视觉语言模型详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../watermarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能水印技术入门：工具与技巧
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper-speculative-decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用推测解码使 Whisper 实现 2 倍的推理加速
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../winning-aimo-progress-prize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NuminaMath 是如何荣膺首届 AIMO 进步奖的？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xethub-joins-hf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XetHub 加入 Hugging Face!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../zero-shot-vqa-docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LAVE：使用 LLM 对 Docmatix 进行零样本 VQA 评估 - 我们还需要微调吗？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运维
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../blog/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    博客
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../resume/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简历模板
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/C-L-STARK/C-L-STARK.github.io/edit/master/docs/ml/encoder-decoder.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2zm-2.3 6.35c.22-.21.22-.56 0-.77L15.42 7.3a.53.53 0 0 0-.77 0l-1 1 2.05 2.05zM7 14.94V17h2.06l6.06-6.06-2.06-2.06z"/></svg>
    </a>
  
  


<h1 id="transformers-">基于 Transformers 的编码器-解码器模型<a class="headerlink" href="#transformers-" title="Permanent link">&para;</a></h1>
<p><a target="_blank" href="https://colab.research.google.com/github/patrickvonplaten/notebooks/blob/master/Encoder_Decoder_Model.ipynb">
    <a class="glightbox" href="https://colab.research.google.com/assets/colab-badge.svg" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt=" 在 Colab 中打开 "/></a>
</a></p>
<h1 id="transformers-_1"><strong>基于 Transformers 的编码器-解码器模型</strong><a class="headerlink" href="#transformers-_1" title="Permanent link">&para;</a></h1>
<div class="language-bash highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a>!pip<span class="w"> </span>install<span class="w"> </span><span class="nv">transformers</span><span class="o">==</span><span class="m">4</span>.2.1
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a>!pip<span class="w"> </span>install<span class="w"> </span><span class="nv">sentencepiece</span><span class="o">==</span><span class="m">0</span>.1.95
</span></code></pre></div>
<p>Vaswani 等人在其名作 <a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a> 中首创了 <em>基于 transformer</em> 的编码器-解码器模型，如今已成为自然语言处理 (natural language processing，NLP) 领域编码器-解码器架构的 <em>事实标准</em> 。</p>
<p>最近基于 transformer 的编码器-解码器模型训练这一方向涌现出了大量关于 <em>预训练目标函数</em> 的研究，<em>例如</em> T5、Bart、Pegasus、ProphetNet、Marge 等，但它们所使用的网络结构并没有改变。</p>
<p>本文的目的是 <strong>详细</strong> 解释如何用基于 transformer 的编码器-解码器架构来对 <em>序列到序列 (sequence-to-sequence)</em> 问题进行建模。我们将重点关注有关这一架构的数学知识以及如何对该架构的模型进行推理。在此过程中，我们还将介绍 NLP 中序列到序列模型的一些背景知识，并将 <em>基于 transformer</em> 的编码器-解码器架构分解为 <strong>编码器</strong> 和 <strong>解码器</strong> 这两个部分分别讨论。我们提供了许多图例，并把 <em>基于 transformer</em> 的编码器-解码器模型的理论与其在 🤗 transformers 推理场景中的实际应用二者联系起来。请注意，这篇博文 <em>不</em> 解释如何训练这些模型 —— 我们会在后续博文中涵盖这一方面的内容。</p>
<p>基于 transformer 的编码器-解码器模型是 <em>表征学习</em> 和 <em>模型架构</em> 这两个领域多年研究成果的结晶。本文简要介绍了神经编码器-解码器模型的历史，更多背景知识，建议读者阅读由 Sebastion Ruder 撰写的这篇精彩 <a href="https://ruder.io/a-review-of-the-recent-history-of-nlp/">博文</a>。此外，建议读者对 _自注意力 (self-attention) 架构_有一个基本了解，可以阅读 Jay Alammar 的 <a href="http://jalammar.github.io/illustrated-transformer/">这篇博文</a> 复习一下原始 transformer 模型。</p>
<p>截至本文撰写时，🤗 transformers 库已经支持的编码器-解码器模型有: <em>T5</em> 、<em>Bart</em> 、<em>MarianMT</em> 以及 <em>Pegasus</em> ，你可以从 <a href="https://huggingface.co/docs/transformers/model_summary#nlp-encoder-decoder">这儿</a> 获取相关信息。</p>
<p>本文分 4 个部分:</p>
<ul>
<li><strong>背景</strong> - <em>简要回顾了神经编码器-解码器模型的历史，重点关注基于 RNN 的模型。</em></li>
<li><strong>编码器-解码器</strong> - <em>阐述基于 transformer 的编码器-解码器模型，并阐述如何使用该模型进行推理。</em></li>
<li><strong>编码器</strong> - <em>阐述模型的编码器部分。</em></li>
<li><strong>解码器</strong> - <em>阐述模型的解码器部分。</em></li>
</ul>
<p>每个部分都建立在前一部分的基础上，但也可以单独阅读。</p>
<h2 id="_1"><strong>背景</strong><a class="headerlink" href="#_1" title="Permanent link">&para;</a></h2>
<p>自然语言生成 (natural language generation，NLG) 是 NLP 的一个子领域，其任务一般可被建模为序列到序列问题。这类任务可以定义为寻找一个模型，该模型将输入词序列映射为目标词序列，典型的例子有 <em>摘要</em> 和 <em>翻译</em> 。在下文中，我们假设每个单词都被编码为一个向量表征。因此，<span class="arithmatex">\(n\)</span> 个输入词可以表示为 <span class="arithmatex">\(n\)</span> 个输入向量组成的序列:</p>
<div class="arithmatex">\[\mathbf{X}_{1:n} = {\mathbf{x}_1, \ldots, \mathbf{x}_n}\]</div>
<p>因此，序列到序列问题可以表示为找到一个映射 <span class="arithmatex">\(f\)</span>，其输入为 <span class="arithmatex">\(n\)</span> 个向量的序列，输出为 <span class="arithmatex">\(m\)</span> 个向量的目标序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span>。这里，目标向量数 <span class="arithmatex">\(m\)</span> 是先验未知的，其值取决于输入序列:</p>
<div class="arithmatex">\[ f: \mathbf{X}_{1:n} \to \mathbf{Y}_{1:m} \]</div>
<p><a href="https://arxiv.org/abs/1409.3215">Sutskever 等 (2014) </a> 的工作指出，深度神经网络 (deep neural networks，DNN)“<em>尽管灵活且强大，但只能用于拟合输入和输出维度均固定的映射。</em>” <span class="arithmatex">\({}^1\)</span></p>
<p>因此，要用使用 DNN 模型 <span class="arithmatex">\({}^2\)</span> 解决序列到序列问题就意味着目标向量数 <span class="arithmatex">\(m\)</span> 必须是先验已知的，且必须独立于输入 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span>。这样设定肯定不是最优的。因为对 NLG 任务而言，目标词的数量通常取决于输入内容 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span>，而不仅仅是输入长度 <span class="arithmatex">\(n\)</span>。 <em>例如</em> ，一篇 1000 字的文章，根据内容的不同，有可能可以概括为 200 字，也有可能可以概括为 100 字。</p>
<p>2014 年，<a href="https://arxiv.org/pdf/1406.1078.pdf">Cho 等人</a> 和 <a href="https://arxiv.org/abs/1409.3215">Sutskever 等人</a> 提出使用完全基于递归神经网络 (recurrent neural networks，RNN) 的编码器-解码器模型来解决 _序列到序列_任务。与 DNN 相比，RNN 支持输出可变数量的目标向量。下面，我们深入了解一下基于 RNN 的编码器-解码器模型的功能。</p>
<p>在推理过程中，RNN 编码器通过连续更新其 <em>隐含状态</em> <span class="arithmatex">\({}^3\)</span> 对输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 进行编码。我们定义处理完最后一个输入向量 <span class="arithmatex">\(\mathbf{x}_n\)</span> 后的编码器隐含状态为 <span class="arithmatex">\(\mathbf{c}\)</span>。因此，编码器主要完成如下映射:</p>
<div class="arithmatex">\[ f_{\theta_{enc}}: \mathbf{X}_{1:n} \to \mathbf{c} \]</div>
<p>然后，我们用 <span class="arithmatex">\(\mathbf{c}\)</span> 来初始化解码器的隐含状态，再用解码器 RNN 自回归地生成目标序列。</p>
<p>下面，我们进一步解释一下。从数学角度讲，解码器定义了给定隐含状态 <span class="arithmatex">\(\mathbf{c}\)</span> 下目标序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span> 的概率分布:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{Y}_{1:m} |\mathbf{c}) \]</div>
<p>根据贝叶斯法则，上述分布可以分解为每个目标向量的条件分布的积，如下所示:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{Y}_{1:m} |\mathbf{c}) = \prod_{i=1}^{m} p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{c}) \]</div>
<p>因此，如果模型架构可以在给定所有前驱目标向量的条件下对下一个目标向量的条件分布进行建模的话:</p>
<div class="arithmatex">\[ p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{c}), \forall i \in \{1, \ldots, m\}\]</div>
<p>那它就可以通过简单地将所有条件概率相乘来模拟给定隐藏状态 <span class="arithmatex">\(\mathbf{c}\)</span> 下任意目标向量序列的分布。</p>
<p>那么基于 RNN 的解码器架构如何建模</p>
<p><span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{c})\)</span> 呢?</p>
<p>从计算角度讲，模型按序将前一时刻的内部隐含状态 <span class="arithmatex">\(\mathbf{c}_{i-1}\)</span> 和前一时刻的目标向量 <span class="arithmatex">\(\mathbf{y}_{i-1}\)</span> 映射到当前内部隐含状态 <span class="arithmatex">\(\mathbf{c}_i\)</span> 和一个 <em>logit 向量</em> <span class="arithmatex">\(\mathbf{l}_i\)</span> (下图中以深红色表示):</p>
<div class="arithmatex">\[ f_{\theta_{\text{dec}}}(\mathbf{y}_{i-1}, \mathbf{c}_{i-1}) \to \mathbf{l}_i, \mathbf{c}_i\]</div>
<p>此处，<span class="arithmatex">\(\mathbf{c}_0\)</span> 为 RNN 编码器的输出。随后，对 logit 向量 <span class="arithmatex">\(\mathbf{l}_i\)</span> 进行 <em>softmax</em> 操作，将其变换为下一个目标向量的条件概率分布:</p>
<div class="arithmatex">\[ p(\mathbf{y}_i | \mathbf{l}_i) = \textbf{Softmax}(\mathbf{l}_i), \text{ 其中 } \mathbf{l}_i = f_{\theta_{\text{dec}}}(\mathbf{y}_{i-1}, \mathbf{c}_{\text{prev}})\]</div>
<p>更多有关 logit 向量及其生成的概率分布的详细信息，请参阅脚注 <span class="arithmatex">\({}^4\)</span>。从上式可以看出，目标向量 <span class="arithmatex">\(\mathbf{y}_i\)</span> 的分布是其前一时刻的目标向量 <span class="arithmatex">\(\mathbf{y}_{i-1}\)</span> 及前一时刻的隐含状态 <span class="arithmatex">\(\mathbf{c}_{i-1}\)</span> 的条件分布。而我们知道前一时刻的隐含状态 <span class="arithmatex">\(\mathbf{c}_{i-1}\)</span> 依赖于之前所有的目标向量 <span class="arithmatex">\(\mathbf{y}_0, \ldots, \mathbf{y}_{i- 2}\)</span>，因此我们可以说 RNN 解码器 <em>隐式</em> (<em>或间接</em>) 地建模了条件分布
<span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{c})\)</span>。</p>
<p>目标向量序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span> 的概率空间非常大，因此在推理时，必须借助解码方法对 = <span class="arithmatex">\({}^5\)</span> 对  <span class="arithmatex">\(p_{\theta_{dec}}(\mathbf{Y}_{1:m} |\mathbf{c})\)</span> 进行采样才能高效地生成最终的目标向量序列。</p>
<p>给定某解码方法，在推理时，我们首先从分布 <span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{c})\)</span> 中采样出下一个输出向量; 接着，将其添加至解码器输入序列末尾，让解码器 RNN 继续从
<span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_{i+1} | \mathbf{Y}_{0: i}, \mathbf{c})\)</span> 中采样出下一个输出向量 <span class="arithmatex">\(\mathbf{y}_{i+1}\)</span>，如此往复，整个模型就以 _自回归_的方式生成了最终的输出序列。</p>
<p>基于 RNN 的编码器-解码器模型的一个重要特征是需要定义一些 <em>特殊</em> 向量，如 <span class="arithmatex">\(\text{EOS}\)</span> (终止符) 和  <span class="arithmatex">\(\text{BOS}\)</span> (起始符) 向量。 <span class="arithmatex">\(\text{EOS}\)</span> 向量通常意味着 <span class="arithmatex">\(\mathbf{x}_n\)</span> 中止，出现这个即“提示”编码器输入序列已结束; 如果它出现在目标序列中意味着输出结束，一旦从 logit 向量中采样到 <span class="arithmatex">\(\text{EOS}\)</span>，生成就完成了。<span class="arithmatex">\(\text{BOS}\)</span> 向量用于表示在第一步解码时馈送到解码器 RNN 的输入向量 <span class="arithmatex">\(\mathbf{y}_0\)</span>。为了输出第一个 logit <span class="arithmatex">\(\mathbf{l}_1\)</span>，需要一个输入，而由于在其之前还没有生成任何输入，所以我们馈送了一个特殊的 <span class="arithmatex">\(\text{BOS}\)</span> 输入向量到解码器 RNN。好，有点绕了！我们用一个例子说明一下。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/rnn_seq2seq.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/rnn_seq2seq.png" /></a></p>
<p>上图中，我们将编码器 RNN 编码器展开，并用绿色表示; 同时，将解码器 RNN 展开，并用红色表示。</p>
<p>英文句子 <code>I want to buy a car</code>，表示为 <span class="arithmatex">\((\mathbf{x}_1 = \text{I}\)</span>，<span class="arithmatex">\(\mathbf{x}_2 = \text{want}\)</span>，<span class="arithmatex">\(\mathbf{x}_3 = \text{to}\)</span>，<span class="arithmatex">\(\mathbf{x}_4 = \text{buy}\)</span>，<span class="arithmatex">\(\mathbf{x}_5 = \text{a}\)</span>，<span class="arithmatex">\(\mathbf{x}_6 = \text{car}\)</span>，<span class="arithmatex">\(\mathbf{x}_7 = \text{EOS}\)</span>)。将其翻译成德语: “Ich will ein Auto kaufen"，表示为 <span class="arithmatex">\((\mathbf{y}_0 = \text{BOS}\)</span>，<span class="arithmatex">\(\mathbf{y}_1 = \text{Ich}\)</span>，<span class="arithmatex">\(\mathbf{y}_2 = \text{will}\)</span>，<span class="arithmatex">\(\mathbf{y}_3 = \text {ein}\)</span>，<span class="arithmatex">\(\mathbf{y}_4 = \text{Auto}\)</span>，<span class="arithmatex">\(\mathbf{y}_5 = \text{kaufen}\)</span>，<span class="arithmatex">\(\mathbf{y}_6=\text{EOS}\)</span>)。首先，编码器 RNN 处理输入向量 <span class="arithmatex">\(\mathbf{x}_1 = \text{I}\)</span> 并更新其隐含状态。请注意，对编码器而言，因为我们只对其最终隐含状态 <span class="arithmatex">\(\mathbf{c}\)</span> 感兴趣，所以我们可以忽略它的目标向量。然后，编码器 RNN 以相同的方式依次处理输入句子的其余部分: <span class="arithmatex">\(\text{want}\)</span>、<span class="arithmatex">\(\text{to}\)</span>、<span class="arithmatex">\(\text{buy}\)</span>、<span class="arithmatex">\(\text{a}\)</span>、<span class="arithmatex">\(\text{car}\)</span>、<span class="arithmatex">\(\text{EOS}\)</span>，并且每一步都更新其隐含状态，直到遇到向量 <span class="arithmatex">\(\mathbf{x}_7={EOS}\)</span> <span class="arithmatex">\({}^6\)</span>。在上图中，连接展开的编码器 RNN 的水平箭头表示按序更新隐含状态。编码器 RNN 的最终隐含状态，由 <span class="arithmatex">\(\mathbf{c}\)</span> 表示，其完全定义了输入序列的 <em>编码</em> ，并可用作解码器 RNN 的初始隐含状态。可以认为，解码器 RNN 以编码器 RNN 的最终隐含状态为条件。</p>
<p>为了生成第一个目标向量，将 <span class="arithmatex">\(\text{BOS}\)</span> 向量输入给解码器，即上图中的 <span class="arithmatex">\(\mathbf{y}_0\)</span>。然后通过 <em>语言模型头 (LM Head)</em> 前馈层将 RNN 的目标向量进一步映射到 logit 向量 <span class="arithmatex">\(\mathbf{l}_1\)</span>，此时，可得第一个目标向量的条件分布:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{y} | \text{BOS}, \mathbf{c}) \]</div>
<p>最终采样出第一个目标词 <span class="arithmatex">\(\text{Ich}\)</span> (如图中连接 <span class="arithmatex">\(\mathbf{l}_1\)</span> 和  <span class="arithmatex">\(\mathbf{y}_1\)</span> 的灰色箭头所示)。接着，继续采样出第二个目标向量:</p>
<div class="arithmatex">\[ \text{will} \sim p_{\theta_{dec}}(\mathbf{y} | \text{BOS}, \text{Ich}, \mathbf{c}) \]</div>
<p>依此类推，一直到第 6 步，此时从 <span class="arithmatex">\(\mathbf{l}_6\)</span> 中采样出 <span class="arithmatex">\(\text{EOS}\)</span>，解码完成。输出目标序列为 <span class="arithmatex">\(\mathbf{Y}_{1:6} = {\mathbf{y}_1, \ldots, \mathbf{y}_6}\)</span>, 即上文中的 “Ich will ein Auto kaufen”。</p>
<p>综上所述，我们通过将分布 <span class="arithmatex">\(p(\mathbf{Y}_{1:m} | \mathbf{X}_{1:n})\)</span> 分解为 <span class="arithmatex">\(f_{\theta_{\text{enc}}}\)</span> 和  <span class="arithmatex">\(p_{\theta_{\text{dec}}}\)</span> 的表示来建模基于 RNN 的 encoder-decoder 模型:</p>
<div class="arithmatex">\[ p_{\theta_{\text{enc}}, \theta_{\text{dec}}}(\mathbf{Y}_{1:m} | \mathbf{X}_{1:n}) = \prod_{i=1}^{m} p_{\theta_{\text{enc}}, \theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{X}_{1:n}) = \prod_{i=1}^{m} p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{c}), \text{ 其中 } \mathbf{c}=f_{\theta_{enc}}(X) \]</div>
<p>在推理过程中，利用高效的解码方法可以自回归地生成目标序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span>。</p>
<p>基于 RNN 的编码器-解码器模型席卷了 NLG 社区。2016 年，谷歌宣布用基于 RNN 的编码器-解码器单一模型完全取代其原先使用的的含有大量特征工程的翻译服务 (参见
<a href="https://www.oreilly.com/radar/what-machine-learning-means-for-software-development/#:~:text=Machine%20learning%20is%20already%20making,of%20code%20in%20Google%20Translate">此处</a>)。</p>
<p>然而，基于 RNN 的编码器-解码器模型存在两个主要缺陷。首先，RNN 存在梯度消失问题，因此很难捕获长程依赖性， <em>参见</em> <a href="https://www.bioinf.jku.at/publications/older/ch7.pdf">Hochreiter 等 (2001) </a> 的工作。其次，RNN 固有的循环架构使得在编码时无法进行有效的并行化， <em>参见</em> <a href="https://arxiv.org/abs/1706.03762">Vaswani 等 (2017) </a> 的工作。</p>
<hr />
<p><span class="arithmatex">\({}^1\)</span> 论文的原话是“<em>尽管 DNN 具有灵活性和强大的功能，但它们只能应用于输入和目标可以用固定维度的向量进行合理编码的问题</em>”，用在本文时稍作调整。</p>
<p><span class="arithmatex">\({}^2\)</span> 这同样适用于卷积神经网络 (CNN)。虽然可以将可变长度的输入序列输入 CNN，但目标的维度要么取决于输入维数要么需要固定为特定值。</p>
<p><span class="arithmatex">\({}^3\)</span> 在第一步时，隐含状态被初始化为零向量，并与第一个输入向量 <span class="arithmatex">\(\mathbf{x}_1\)</span> 一起馈送给 RNN。</p>
<p><span class="arithmatex">\({}^4\)</span> 神经网络可以将所有单词的概率分布定义为 <span class="arithmatex">\(p(\mathbf{y} | \mathbf{c}, \mathbf{Y}_{0 : i-1})\)</span>。首先，其将输入 <span class="arithmatex">\(\mathbf{c}, \mathbf{Y}_{0: i-1}\)</span> 转换为嵌入向量 <span class="arithmatex">\(\mathbf{y'}\)</span>，该向量对应于 RNN 模型的目标向量。随后将 <span class="arithmatex">\(\mathbf{y'}\)</span> 送给“语言模型头”，即将其乘以 <em>词嵌入矩阵</em> (即<span class="arithmatex">\(\mathbf{Y}^{\text{vocab}}\)</span>)，得到 <span class="arithmatex">\(\mathbf{y'}\)</span> 和词表 <span class="arithmatex">\(\mathbf{Y}^{\text{vocab}}\)</span> 中的每个向量 <span class="arithmatex">\(\mathbf{y}\)</span> 的相似度得分，生成的向量称为 logit 向量 <span class="arithmatex">\(\mathbf{l} = \mathbf{Y}^{\text{vocab}} \mathbf{y'}\)</span>，最后再通过 softmax 操作归一化成所有单词的概率分布: <span class="arithmatex">\(p(\mathbf{y} | \mathbf{c}) = \text{Softmax}(\mathbf{Y}^{\text{vocab}} \mathbf{y'}) = \text {Softmax}(\mathbf{l})\)</span>。</p>
<p><span class="arithmatex">\({}^5\)</span> 波束搜索 (beam search) 是其中一种解码方法。本文不会对不同的解码方法进行介绍，如对此感兴趣，建议读者参考 <a href="https://huggingface.co/blog/zh/how-to-generate">此文</a>。</p>
<p><span class="arithmatex">\({}^6\)</span> <a href="https://arxiv.org/abs/1409.3215">Sutskever 等 (2014) </a> 的工作对输入顺序进行了逆序，对上面的例子而言，输入向量变成了 (<span class="arithmatex">\(\mathbf{x}_1 = \text{car}\)</span>，<span class="arithmatex">\(\mathbf{x}_2 = \text{a}\)</span>，<span class="arithmatex">\(\mathbf{x}_3 = \text{buy}\)</span>，<span class="arithmatex">\(\mathbf{x}_4 = \text{to}\)</span>，<span class="arithmatex">\(\mathbf{x}_5 = \text{want}\)</span>，<span class="arithmatex">\(\mathbf{x}_6 = \text{I}\)</span>，<span class="arithmatex">\(\mathbf{x}_7 = \text{EOS}\)</span>)。其动机是让对应词对之间的连接更短，如可以使得 <span class="arithmatex">\(\mathbf{x}_6 = \text{I}\)</span> 和  <span class="arithmatex">\(\mathbf{y}_1 = \text{Ich}\)</span> 之间的连接更短。该研究小组强调，将输入序列进行逆序是他们的模型在机器翻译上的性能提高的一个关键原因。</p>
<h2 id="-"><strong>编码器-解码器</strong><a class="headerlink" href="#-" title="Permanent link">&para;</a></h2>
<p>2017 年，Vaswani 等人引入了 <strong>transformer</strong> 架构，从而催生了 <em>基于 transformer</em> 的编码器-解码器模型。</p>
<p>与基于 RNN 的编码器-解码器模型类似，基于 transformer 的编码器-解码器模型由一个编码器和一个解码器组成，且其编码器和解码器均由 <em>残差注意力模块 (residual attention blocks)</em> 堆叠而成。基于 transformer 的编码器-解码器模型的关键创新在于: 残差注意力模块无需使用循环结构即可处理长度 <span class="arithmatex">\(n\)</span> 可变的输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span>。不依赖循环结构使得基于 transformer 的编码器-解码器可以高度并行化，这使得模型在现代硬件上的计算效率比基于 RNN 的编码器-解码器模型高出几个数量级。</p>
<p>回忆一下，要解决 <em>序列到序列</em> 问题，我们需要找到输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 到变长输出序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span> 的映射。我们看看如何使用基于 transformer 的编码器-解码器模型来找到这样的映射。</p>
<p>与基于 RNN 的编码器-解码器模型类似，基于 transformer 的编码器-解码器模型定义了在给定输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 条件下目标序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span> 的条件分布:</p>
<div class="arithmatex">\[
p_{\theta_{\text{enc}}, \theta_{\text{dec}}}(\mathbf{Y}_{1:m} | \mathbf{X}_{1:n})
\]</div>
<p>基于 transformer 的编码器部分将输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 编码为 <em>隐含状态序列</em> <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span>，即:</p>
<div class="arithmatex">\[ f_{\theta_{\text{enc}}}: \mathbf{X}_{1:n} \to \mathbf{\overline{X}}_{1:n} \]</div>
<p>然后，基于 transformer 的解码器负责建模在给定隐含状态序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> 的条件下目标向量序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span> 的概率分布:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{Y}_{1:m} | \mathbf{\overline{X}}_{1:n})\]</div>
<p>根据贝叶斯法则，该序列分布可被分解为每个目标向量 <span class="arithmatex">\(\mathbf{y}_i\)</span> 在给定隐含状态 <span class="arithmatex">\(\mathbf{\overline{X} }_{1:n}\)</span> 和其所有前驱目标向量 <span class="arithmatex">\(\mathbf{Y}_{0:i-1}\)</span> 时的条件概率之积:</p>
<div class="arithmatex">\[
p_{\theta_{dec}}(\mathbf{Y}_{1:m} | \mathbf{\overline{X}}_{1:n}) = \prod_{i=1}^{m} p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n}) \]</div>
<p>因此，在生成 <span class="arithmatex">\(\mathbf{y}_i\)</span> 时，基于 transformer 的解码器将隐含状态序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> 及其所有前驱目标向量 <span class="arithmatex">\(\mathbf{Y}_{0 :i-1}\)</span> 映射到 <em>logit</em> 向量 <span class="arithmatex">\(\mathbf{l}_i\)</span>。 然后经由 <em>softmax</em> 运算对 logit 向量 <span class="arithmatex">\(\mathbf{l}_i\)</span> 进行处理，从而生成条件分布 <span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n})\)</span>。这个流程跟基于 RNN 的解码器是一样的。然而，与基于 RNN 的解码器不同的是，在这里，目标向量 <span class="arithmatex">\(\mathbf{y}_i\)</span> 的分布是 <em>显式</em>(或直接) 地以其所有前驱目标向量 <span class="arithmatex">\(\mathbf{y}_0, \ldots, \mathbf{y}_{i-1}\)</span> 为条件的，稍后我们将详细介绍。此处第 0 个目标向量 <span class="arithmatex">\(\mathbf{y}_0\)</span> 仍表示为 <span class="arithmatex">\(\text{BOS}\)</span> 向量。有了条件分布 <span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X} }_{1:n})\)</span>，我们就可以 _自回归_生成输出了。至此，我们定义了可用于推理的从输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 到输出序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span> 的映射。</p>
<p>我们可视化一下使用 <em>基于 transformer</em> 的编码器-解码器模型 _自回归_地生成序列的完整过程。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/EncoderDecoder.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/EncoderDecoder.png" /></a></p>
<p>上图中，绿色为基于 transformer 的编码器，红色为基于 transformer 的解码器。与上一节一样，我们展示了如何将表示为 <span class="arithmatex">\((\mathbf{x}_1 = \text{I}，\mathbf{ x}_2 = \text{want}，\mathbf{x}_3 = \text{to}，\mathbf{x}_4 = \text{buy}，\mathbf{x}_5 = \text{a}，\mathbf{x}_6 = \text{car}，\mathbf{x}_7 = \text{EOS})\)</span> 的英语句子 “I want to buy a car” 翻译成表示为 <span class="arithmatex">\((\mathbf{y}_0 = \text{BOS}，\mathbf{y }_1 = \text{Ich}，\mathbf{y}_2 = \text{will}，\mathbf{y}_3 = \text{ein}，\mathbf{y}_4 = \text{Auto}，\mathbf{y}_5 = \text{kaufen}，\mathbf{y}_6=\text{EOS})\)</span> 的德语句子 “Ich will ein Auto kaufen”。</p>
<p>首先，编码器将完整的输入序列 <span class="arithmatex">\(\mathbf{X}_{1:7}\)</span> = “I want to buy a car” (由浅绿色向量表示) 处理为上下文相关的编码序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:7}\)</span>。这里上下文相关的意思是， <em>举个例子</em> ，<span class="arithmatex">\(\mathbf{\overline{x}}_4\)</span> 的编码不仅取决于输入 <span class="arithmatex">\(\mathbf{x}_4\)</span> = “buy”，还与所有其他词 “I”、“want”、“to”、“a”、“car” 及 “EOS” 相关，这些词即该词的 <em>上下文</em> 。</p>
<p>接下来，输入编码 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:7}\)</span> 与 BOS 向量 ( <em>即</em> <span class="arithmatex">\(\mathbf{y}_0\)</span>) 被一起馈送到解码器。解码器将输入 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:7}\)</span> 和  <span class="arithmatex">\(\mathbf{y}_0\)</span> 变换为第一个 logit <span class="arithmatex">\(\mathbf{l }_1\)</span> (图中以深红色显示)，从而得到第一个目标向量 <span class="arithmatex">\(\mathbf{y}_1\)</span> 的条件分布:</p>
<div class="arithmatex">\[ p_{\theta_{enc, dec}}(\mathbf{y} | \mathbf{y}_0, \mathbf{X}_{1:7}) = p_{\theta_{enc, dec}}(\mathbf{y} | \text{BOS}, \text{I want to buy a car EOS}) = p_{\theta_{dec}}(\mathbf{y} | \text{BOS}, \mathbf{\overline{X}}_{1:7}) \]</div>
<p>然后，从该分布中采样出第一个目标向量 <span class="arithmatex">\(\mathbf{y}_1\)</span> = <span class="arithmatex">\(\text{Ich}\)</span> (由灰色箭头表示)，得到第一个输出后，我们会并将其继续馈送到解码器。现在，解码器开始以 <span class="arithmatex">\(\mathbf{y}_0\)</span> = “BOS” 和  <span class="arithmatex">\(\mathbf{y}_1\)</span> = “Ich” 为条件来定义第二个目标向量的条件分布 <span class="arithmatex">\(\mathbf{y}_2\)</span>:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{y} | \text{BOS Ich}, \mathbf{\overline{X}}_{1:7}) \]</div>
<p>再采样一次，生成目标向量 <span class="arithmatex">\(\mathbf{y}_2\)</span> = “will”。重复该自回归过程，直到第 6 步从条件分布中采样到 EOS:</p>
<div class="arithmatex">\[ \text{EOS} \sim p_{\theta_{dec}}(\mathbf{y} | \text{BOS Ich will ein Auto kaufen}, \mathbf{\overline{X}}_{1:7}) \]</div>
<p>这里有一点比较重要，我们仅在第一次前向传播时用编码器将 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 映射到 <span class="arithmatex">\(\mathbf{\overline{X}}_{ 1:n}\)</span>。从第二次前向传播开始，解码器可以直接使用之前算得的编码 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span>。为清楚起见，下图画出了上例中第一次和第二次前向传播所需要做的操作。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/EncoderDecoder_step_by_step.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/EncoderDecoder_step_by_step.png" /></a></p>
<p>可以看出，仅在步骤 <span class="arithmatex">\(i=1\)</span> 时，我们才需要将 “I want to buy a car EOS” 编码为 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:7}\)</span>。从 <span class="arithmatex">\(i=2\)</span> 开始，解码器只是简单地复用了已生成的编码。</p>
<p>在 🤗 transformers 库中，这一自回归生成过程是在调用 <code>.generate()</code> 方法时在后台完成的。我们用一个翻译模型来实际体验一下。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianMTModel</span><span class="p">,</span> <span class="n">MarianTokenizer</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a><span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a><span class="c1"># create ids of encoded input vectors</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I want to buy a car&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="c1"># translate example</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="n">output_ids</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="c1"># decode and print</span>
</span><span id="__span-1-13"><a id="__codelineno-1-13" name="__codelineno-1-13" href="#__codelineno-1-13"></a><span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">output_ids</span><span class="p">))</span>
</span></code></pre></div>
<p><em>输出:</em></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a>    &lt;pad&gt; Ich will ein Auto kaufen
</span></code></pre></div>
<p><code>.generate()</code> 接口做了很多事情。首先，它将 <code>input_ids</code> 传递给编码器。然后，它将一个预定义的标记连同已编码的 <code>input_ids</code>一起传递给解码器 (在使用 <code>MarianMTModel</code> 的情况下，该预定义标记为 <span class="arithmatex">\(\text{&lt;pad&gt;}\)</span>)。接着，它使用波束搜索解码机制根据最新的解码器输出的概率分布<span class="arithmatex">\({}^1\)</span>自回归地采样下一个输出词。更多有关波束搜索解码工作原理的详细信息，建议阅读 <a href="https://huggingface.co/blog/zh/how-to-generate">这篇博文</a>。</p>
<p>我们在附录中加入了一个代码片段，展示了如何“从头开始”实现一个简单的生成方法。如果你想要完全了解 _自回归_生成的幕后工作原理，强烈建议阅读附录。</p>
<p>总结一下:</p>
<ul>
<li>基于 transformer 的编码器实现了从输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> 到上下文相关的编码序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1 :n}\)</span> 之间的映射。</li>
<li>基于 transformer 的解码器定义了条件分布 <span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{ \overline{X}}_{1:n})\)</span>。</li>
<li>给定适当的解码机制，可以自回归地从 <span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n}), \forall i \in {1, \ldots, m}\)</span> 中采样出输出序列 <span class="arithmatex">\(\mathbf{Y}_{1:m}\)</span>。</li>
</ul>
<p>太好了，现在我们已经大致了解了 <em>基于 transformer 的_编码器-解码器模型的工作原理。下面的部分，我们将更深入地研究模型的编码器和解码器部分。更具体地说，我们将确切地看到编码器如何利用自注意力层来产生一系列上下文相关的向量编码，以及自注意力层如何实现高效并行化。然后，我们将详细解释自注意力层在解码器模型中的工作原理，以及解码器如何通过 _交叉注意力</em> 层以编码器输出为条件来定义分布 <span class="arithmatex">\(p_{\theta_{\text{dec}}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n})\)</span>。在此过程中，基于 transformer 的编码器-解码器模型如何解决基于 RNN 的编码器-解码器模型的长程依赖问题的答案将变得显而易见。</p>
<hr />
<p><span class="arithmatex">\({}^1\)</span> 可以从 <a href="https://s3.amazonaws.com/models.huggingface.co/bert/Helsinki-NLP/opus-mt-en-de/config.json">此处</a> 获取 <code>"Helsinki-NLP/opus-mt-en-de"</code> 的解码参数。可以看到，其使用了 <code>num_beams=6</code> 的波束搜索。</p>
<h2 id="_2"><strong>编码器</strong><a class="headerlink" href="#_2" title="Permanent link">&para;</a></h2>
<p>如前一节所述， <em>基于 transformer</em> 的编码器将输入序列映射到上下文相关的编码序列:</p>
<div class="arithmatex">\[ f_{\theta_{\text{enc}}}: \mathbf{X}_{1:n} \to \mathbf{\overline{X}}_{1:n} \]</div>
<p>仔细观察架构，基于 transformer 的编码器由许多 <em>残差注意力模块_堆叠而成。每个编码器模块都包含一个 <strong>双向</strong>自注意力层，其后跟着两个前馈层。这里，为简单起见，我们忽略归一化层 (normalization layer)。此外，我们不会深入讨论两个前馈层的作用，仅将其视为每个编码器模块 <span class="arithmatex">\({}^1\)</span> 的输出映射层。双向自注意层将每个输入向量 <span class="arithmatex">\(\mathbf{x'}_j, \forall j \in {1, \ldots, n}\)</span> 与全部输入向量 <span class="arithmatex">\(\mathbf{x'}_1, \ldots, \mathbf{x'}_n\)</span> 相关联并通过该机制将每个输入向量 <span class="arithmatex">\(\mathbf{x'}_j\)</span> 提炼为与其自身上下文相关的表征: <span class="arithmatex">\(\mathbf{x''}_j\)</span>。因此，第一个编码器块将输入序列 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> (如下图浅绿色所示) 中的每个输入向量从 _上下文无关</em> 的向量表征转换为 _上下文相关_的向量表征，后面每一个编码器模块都会进一步细化这个上下文表征，直到最后一个编码器模块输出最终的上下文相关编码 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> (如下图深绿色所示)。</p>
<p>我们对 <code>编码器如何将输入序列 "I want to buy a car EOS" 变换为上下文编码序列</code>这一过程进行一下可视化。与基于 RNN 的编码器类似，基于 transformer 的编码器也在输入序列最后添加了一个 EOS，以提示模型输入向量序列已结束 <span class="arithmatex">\({}^2\)</span>。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/Encoder_block.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/Encoder_block.png" /></a></p>
<p>上图中的 <em>基于 transformer</em> 的编码器由三个编码器模块组成。我们在右侧的红框中详细列出了第二个编码器模块的前三个输入向量: <span class="arithmatex">\(\mathbf{x}_1\)</span>，<span class="arithmatex">\(\mathbf {x}_2\)</span> 及 <span class="arithmatex">\(\mathbf{x}_3\)</span>。红框下部的全连接图描述了双向自注意力机制，上面是两个前馈层。如前所述，我们主要关注双向自注意力机制。</p>
<p>可以看出，自注意力层的每个输出向量 <span class="arithmatex">\(\mathbf{x''}_i, \forall i \in {1, \ldots, 7}\)</span> 都 <em>直接</em> 依赖于 <em>所有</em> 输入向量 <span class="arithmatex">\(\mathbf{x'}_1, \ldots, \mathbf{x'}_7\)</span>。这意味着，单词 “want” 的输入向量表示 <span class="arithmatex">\(\mathbf{x'}_2\)</span> 与单词 “buy” (即 <span class="arithmatex">\(\mathbf{x'}_4\)</span>) 和单词 “I” (即 <span class="arithmatex">\(\mathbf{x'}_1\)</span>) 直接相关。 因此，“want” 的输出向量表征，<em>即</em> <span class="arithmatex">\(\mathbf{x''}_2\)</span>，是一个融合了其上下文信息的更精细的表征。</p>
<p>我们更深入了解一下双向自注意力的工作原理。编码器模块的输入序列 <span class="arithmatex">\(\mathbf{X'}_{1:n}\)</span> 中的每个输入向量 <span class="arithmatex">\(\mathbf{x'}_i\)</span> 通过三个可训练的权重矩阵 <span class="arithmatex">\(\mathbf{W}_q\)</span>，<span class="arithmatex">\(\mathbf{W}_v\)</span>，<span class="arithmatex">\(\mathbf{W}_k\)</span> 分别投影至 <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_i\)</span>、<code>value</code> 向量 <span class="arithmatex">\(\mathbf{v}_i\)</span> 和 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_i\)</span> (下图分别以橙色、蓝色和紫色表示):</p>
<div class="arithmatex">\[ \mathbf{q}_i = \mathbf{W}_q \mathbf{x'}_i,$$
$$ \mathbf{v}_i = \mathbf{W}_v \mathbf{x'}_i,$$
$$ \mathbf{k}_i = \mathbf{W}_k \mathbf{x'}_i, $$
$$ \forall i \in {1, \ldots n }\]</div>
<p>请注意，对每个输入向量 <span class="arithmatex">\(\mathbf{x}_i (\forall i \in {i, \ldots, n}\)</span>) 而言，其所使用的权重矩阵都是 <strong>相同</strong>的。将每个输入向量 <span class="arithmatex">\(\mathbf{x}_i\)</span> 投影到 <code>query</code> 、 <code>key</code> 和 <code>value</code> 向量后，将每个 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_j (\forall j \in {1, \ldots, n}\)</span>) 与所有 <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_1, \ldots, \mathbf{k}_n\)</span> 进行比较。哪个 <code>key</code> 向量与 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_j\)</span> 越相似，其对应的 <code>value</code> 向量 <span class="arithmatex">\(\mathbf{v}_j\)</span> 对输出向量 <span class="arithmatex">\(\mathbf{x''}_j\)</span> 的影响就越重要。更具体地说，输出向量 <span class="arithmatex">\(\mathbf{x''}_j\)</span> 被定义为所有 <code>value</code> 向量的加权和 <span class="arithmatex">\(\mathbf{v}_1, \ldots, \mathbf{v}_n\)</span> 加上输入向量 <span class="arithmatex">\(\mathbf{x'}_j\)</span>。而各 <code>value</code> 向量的权重与 <span class="arithmatex">\(\mathbf{q}_j\)</span> 和各个 <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_1, \ldots, \mathbf{k}_n\)</span> 之间的余弦相似度成正比，其数学公式为 <span class="arithmatex">\(\textbf{Softmax}(\mathbf{K}_{1:n}^\intercal \mathbf{q}_j)\)</span>，如下文的公式所示。关于自注意力层的完整描述，建议读者阅读 <a href="http://jalammar.github.io/illustrated-transformer/">这篇</a> 博文或 <a href="https://arxiv.org/abs/1706.03762">原始论文</a>。</p>
<p>好吧，又复杂起来了。我们以上例中的一个 <code>query</code> 向量为例图解一下双向自注意层。为简单起见，本例中假设我们的 <em>基于 transformer</em> 的解码器只有一个注意力头 <code>config.num_heads = 1</code> 并且没有归一化层。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/encoder_detail.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/encoder_detail.png" /></a></p>
<p>图左显示了上个例子中的第二个编码器模块，右边详细可视化了第二个输入向量 <span class="arithmatex">\(\mathbf{x'}_2\)</span> 的双向自注意机制，其对应输入词为 “want”。首先将所有输入向量 <span class="arithmatex">\(\mathbf{x'}_1, \ldots, \mathbf{x'}_7\)</span> 投影到它们各自的 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_1, \ldots, \mathbf{q}_7\)</span> (上图中仅以紫色显示前三个 <code>query</code> 向量)， <code>value</code> 向量 <span class="arithmatex">\(\mathbf{v}_1, \ldots, \mathbf{v}_7\)</span> (蓝色) 和 <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_1, \ldots, \mathbf{k}_7\)</span> (橙色)。然后，将 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_2\)</span> 与所有 <code>key</code> 向量的转置 ( <em>即</em> <span class="arithmatex">\(\mathbf{K}_{1:7}^{\intercal}\)</span>) 相乘，随后进行 softmax 操作以产生 <em>自注意力权重</em> 。 自注意力权重最终与各自的 <code>value</code> 向量相乘，并加上输入向量 <span class="arithmatex">\(\mathbf{x'}_2\)</span>，最终输出单词 “want” 的上下文相关表征， <em>即</em> <span class="arithmatex">\(\mathbf{x''}_2\)</span> (图右深绿色表示)。整个等式显示在图右框的上部。 <span class="arithmatex">\(\mathbf{K}_{1:7}^{\intercal}\)</span> 和  <span class="arithmatex">\(\mathbf{q}_2\)</span> 的相乘使得将 “want” 的向量表征与所有其他输入 (“I”，“to”，“buy”，“a”，“car”，“EOS”) 的向量表征相比较成为可能，因此自注意力权重反映出每个输入向量 <span class="arithmatex">\(\mathbf{x'}_j\)</span> 对 “want” 一词的最终表征 <span class="arithmatex">\(\mathbf{x''}_2\)</span> 的重要程度。</p>
<p>为了进一步理解双向自注意力层的含义，我们假设以下句子: “ <em>房子很漂亮且位于市中心，因此那儿公共交通很方便</em>”。 “那儿”这个词指的是“房子”，这两个词相隔 12 个字。在基于 transformer 的编码器中，双向自注意力层运算一次，即可将“房子”的输入向量与“那儿”的输入向量相关联。相比之下，在基于 RNN 的编码器中，相距 12 个字的词将需要至少 12 个时间步的运算，这意味着在基于 RNN 的编码器中所需数学运算与距离呈线性关系。这使得基于 RNN 的编码器更难对长程上下文表征进行建模。此外，很明显，基于 transformer 的编码器比基于 RNN 的编码器-解码器模型更不容易丢失重要信息，因为编码的序列长度相对输入序列长度保持不变， <em>即</em> <span class="arithmatex">\(\textbf{len }(\mathbf{X}_{1:n}) = \textbf{len}(\mathbf{\overline{X}}_{1:n}) = n\)</span>，而 RNN 则会将 <span class="arithmatex">\(\textbf{len}((\mathbf{X}_{1:n}) = n\)</span> 压缩到 <span class="arithmatex">\(\textbf{len}(\mathbf{c}) = 1\)</span>，这使得 RNN 很难有效地对输入词之间的长程依赖关系进行编码。</p>
<p>除了更容易学到长程依赖外，我们还可以看到 transformer 架构能够并行处理文本。从数学上讲，这是通过将自注意力机制表示为 <code>query</code> 、 <code>key</code> 和 <code>value</code> 的矩阵乘来完成的:</p>
<div class="arithmatex">\[\mathbf{X''}_{1:n} = \mathbf{V}_{1:n} \text{Softmax}(\mathbf{Q}_{1:n}^\intercal \mathbf{K}_{1:n}) + \mathbf{X'}_{1:n} \]</div>
<p>输出 <span class="arithmatex">\(\mathbf{X''}_{1:n} = \mathbf{x''}_1, \ldots, \mathbf{x''}_n\)</span> 是由一系列矩阵乘计算和 softmax 操作算得，因此可以有效地并行化。请注意，在基于 RNN 的编码器模型中，隐含状态 <span class="arithmatex">\(\mathbf{c}\)</span> 的计算必须按顺序进行: 先计算第一个输入向量的隐含状态 <span class="arithmatex">\(\mathbf{x}_1\)</span>; 然后计算第二个输入向量的隐含状态，其取决于第一个隐含向量的状态，依此类推。RNN 的顺序性阻碍了有效的并行化，并使其在现代 GPU 硬件上比基于 transformer 的编码器模型的效率低得多。</p>
<p>太好了，现在我们应该对 a) 基于 transformer 的编码器模型如何有效地建模长程上下文表征，以及 b) 它们如何有效地处理长序列向量输入这两个方面有了比较好的理解了。</p>
<p>现在，我们写一个 <code>MarianMT</code> 编码器-解码器模型的编码器部分的小例子，以验证这些理论在实践中行不行得通。</p>
<hr />
<p><span class="arithmatex">\({}^1\)</span> 关于前馈层在基于 transformer 的模型中所扮演的角色的详细解释超出了本文的范畴。<a href="https://arxiv.org/pdf/1912.10077.pdf">Yun 等人 (2017) </a> 的工作认为前馈层对于将每个上下文向量 <span class="arithmatex">\(\mathbf{x'}_i\)</span> 映射到目标输出空间至关重要，而单靠 <em>自注意力</em> 层无法达成这一目的。这里请注意，每个输出词元 <span class="arithmatex">\(\mathbf{x'}\)</span> 都经由相同的前馈层处理。更多详细信息，建议读者阅读论文。</p>
<p><span class="arithmatex">\({}^2\)</span> 我们无须将 EOS 附加到输入序列，虽然有工作表明，在很多情况下加入它可以提高性能。相反地，基于 transformer 的解码器必须把 <span class="arithmatex">\(\text{BOS}\)</span> 作为第 0 个目标向量，并以之为条件预测第 1 个目标向量。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianMTModel</span><span class="p">,</span> <span class="n">MarianTokenizer</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a><span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="c1"># create ids of encoded input vectors</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I want to buy a car&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a><span class="c1"># pass input_ids to encoder</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a><span class="n">encoder_hidden_states</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a><span class="c1"># change the input slightly and pass to encoder</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a><span class="n">input_ids_perturbed</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I want to buy a house&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a><span class="n">encoder_hidden_states_perturbed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_ids_perturbed</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a><span class="c1"># compare shape and encoding of first vector</span>
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Length of input embeddings </span><span class="si">{</span><span class="n">embeddings</span><span class="p">(</span><span class="n">input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">. Length of encoder_hidden_states </span><span class="si">{</span><span class="n">encoder_hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a><span class="c1"># compare values of word embedding of &quot;I&quot; for input_ids and perturbed input_ids</span>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Is encoding for `I` equal to its perturbed version?: &quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">encoder_hidden_states</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">encoder_hidden_states_perturbed</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">))</span>
</span></code></pre></div>
<p><em>输出:</em>
<div class="language-text highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a>    Length of input embeddings 7. Length of encoder_hidden_states 7
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a>    Is encoding for `I` equal to its perturbed version?: False
</span></code></pre></div></p>
<p>我们比较一下输入词嵌入的序列长度 ( <em>即</em> <code>embeddings(input_ids)</code>，对应于 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span>) 和 <code>encoder_hidden_​​states</code> 的长度 (对应于<span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span>)。同时，我们让编码器对单词序列 “I want to buy a car” 及其轻微改动版 “I want to buy a house” 分别执行前向操作，以检查第一个词 “I” 的输出编码在更改输入序列的最后一个单词后是否会有所不同。</p>
<p>不出意外，输入词嵌入和编码器输出编码的长度， <em>即</em> <span class="arithmatex">\(\textbf{len}(\mathbf{X}_{1:n})\)</span> 和  <span class="arithmatex">\(\textbf{len }(\mathbf{\overline{X}}_{1:n})\)</span>，是相等的。同时，可以注意到当最后一个单词从 “car” 改成 “house” 后，<span class="arithmatex">\(\mathbf{\overline{x}}_1 = \text{“I”}\)</span> 的编码输出向量的值也改变了。因为我们现在已经理解了双向自注意力机制，这就不足为奇了。</p>
<p>顺带一提， <em>自编码</em> 模型 (如 BERT) 的架构与 <em>基于 transformer</em> 的编码器模型是完全一样的。 <em>自编码_模型利用这种架构对开放域文本数据进行大规模自监督预训练，以便它们可以将任何单词序列映射到深度双向表征。在 <a href="https://arxiv.org/abs/1810.04805">Devlin 等 (2018) </a> 的工作中，作者展示了一个预训练 BERT 模型，其顶部有一个任务相关的分类层，可以在 11 个 NLP 任务上获得 SOTA 结果。你可以从 <a href="https://huggingface.co/transformers/model_summary.html#autoencoding-models">此处</a> 找到 🤗 transformers 支持的所有 _自编码</em> 模型。</p>
<h2 id="_3"><strong>解码器</strong><a class="headerlink" href="#_3" title="Permanent link">&para;</a></h2>
<p>如 <em>编码器-解码器</em> 部分所述， <em>基于 transformer</em> 的解码器定义了给定上下文编码序列条件下目标序列的条件概率分布:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{Y}_{1: m} | \mathbf{\overline{X}}_{1:n}) \]</div>
<p>根据贝叶斯法则，在给定上下文编码序列和每个目标变量的所有前驱目标向量的条件下，可将上述分布分解为每个目标向量的条件分布的乘积:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{Y}_{1:m} | \mathbf{\overline{X}}_{1:n}) = \prod_{i=1}^{m} p_{\theta_{dec}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n}) \]</div>
<p>我们首先了解一下基于 transformer 的解码器如何定义概率分布。基于 transformer 的解码器由很多 _解码器模块_堆叠而成，最后再加一个线性层 (即 “LM 头”)。这些解码器模块的堆叠将上下文相关的编码序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> 和每个目标向量的前驱输入 <span class="arithmatex">\(\mathbf{Y}_{0:i-1}\)</span> (这里 <span class="arithmatex">\(\mathbf{y}_0\)</span> 为 BOS) 映射为目标向量的编码序列 <span class="arithmatex">\(\mathbf{\overline{Y} }_{0:i-1}\)</span>。然后，“LM 头”将目标向量的编码序列 <span class="arithmatex">\(\mathbf{\overline{Y}}_{0:i-1}\)</span> 映射到 logit 向量序列 <span class="arithmatex">\(\mathbf {L}_{1:n} = \mathbf{l}_1, \ldots, \mathbf{l}_n\)</span>, 而每个 logit 向量<span class="arithmatex">\(\mathbf{l}_i\)</span> 的维度即为词表的词汇量。这样，对于每个 <span class="arithmatex">\(i \in {1, \ldots, n}\)</span>，其在整个词汇表上的概率分布可以通过对 <span class="arithmatex">\(\mathbf{l}_i\)</span> 取 softmax 获得。公式如下:</p>
<div class="arithmatex">\[p_{\theta_{dec}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n}), \forall i \in {1, \ldots, n}\]</div>
<p>“LM 头” 即为词嵌入矩阵的转置， <em>即</em> <span class="arithmatex">\(\mathbf{W}_{\text{emb}}^{\intercal} = \left[\mathbf{ y}^1, \ldots, \mathbf{y}^{\text{vocab}}\right]^{​​T}\)</span> <span class="arithmatex">\({}^1\)</span>。直观上来讲，这意味着对于所有 <span class="arithmatex">\(i \in {0, \ldots, n - 1}\)</span> “LM 头” 层会将 <span class="arithmatex">\(\mathbf{\overline{y }}_i\)</span> 与词汇表 <span class="arithmatex">\(\mathbf{y}^1, \ldots, \mathbf{y}^{\text{vocab}}\)</span> 中的所有词嵌入一一比较，输出的 logit 向量 <span class="arithmatex">\(\mathbf{l}_{i+1}\)</span> 即表示 <span class="arithmatex">\(\mathbf{\overline{y }}_i\)</span> 与每个词嵌入之间的相似度。Softmax 操作只是将相似度转换为概率分布。对于每个 <span class="arithmatex">\(i \in {1, \ldots, n}\)</span>，以下等式成立:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{y} | \mathbf{\overline{X}}_{1:n}, \mathbf{Y}_{0:i-1})$$
$$ = \text{Softmax}(f_{\theta_{\text{dec}}}(\mathbf{\overline{X}}_{1:n}, \mathbf{Y}_{0:i-1}))$$
$$ = \text{Softmax}(\mathbf{W}_{\text{emb}}^{\intercal} \mathbf{\overline{y}}_{i-1})$$
$$ = \text{Softmax}(\mathbf{l}_i) \]</div>
<p>总结一下，为了对目标向量序列 <span class="arithmatex">\(\mathbf{Y}_{1: m}\)</span> 的条件分布建模，先在目标向量 <span class="arithmatex">\(\mathbf{Y}_{1: m-1}\)</span> 前面加上特殊的 <span class="arithmatex">\(\text{BOS}\)</span> 向量 ( <em>即</em> <span class="arithmatex">\(\mathbf{y}_0\)</span>)，并将其与上下文相关的编码序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> 一起映射到 logit 向量序列 <span class="arithmatex">\(\mathbf{L}_{1:m}\)</span>。然后，使用 softmax 操作将每个 logit 目标向量 <span class="arithmatex">\(\mathbf{l}_i\)</span> 转换为目标向量 <span class="arithmatex">\(\mathbf{y}_i\)</span> 的条件概率分布。最后，将所有目标向量的条件概率 <span class="arithmatex">\(\mathbf{y}_1, \ldots, \mathbf{y}_m\)</span> 相乘得到完整目标向量序列的条件概率:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{Y}_{1:m} | \mathbf{\overline{X}}_{1:n}) = \prod_{i=1}^{m} p_{\theta_{dec}}(\mathbf{y}_i | \mathbf{Y}_{0: i-1}, \mathbf{\overline{X}}_{1:n}).\]</div>
<p>与基于 transformer 的编码器不同，在基于 transformer 的解码器中，其输出向量 <span class="arithmatex">\(\mathbf{\overline{y}}_{i-1}\)</span> 应该能很好地表征 _下一个_目标向量 (即 <span class="arithmatex">\(\mathbf{y}_i\)</span>)，而不是输入向量本身 (即 <span class="arithmatex">\(\mathbf{y}_{i-1}\)</span>)。此外，输出向量 <span class="arithmatex">\(\mathbf{\overline{y}}_{i-1}\)</span> 应基于编码器的整个输出序列 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span>。为了满足这些要求，每个解码器块都包含一个 <strong>单向</strong>自注意层，紧接着是一个 <strong>交叉注意</strong>层，最后是两个前馈层<span class="arithmatex">\({}^2\)</span>。单向自注意层将其每个输入向量 <span class="arithmatex">\(\mathbf{y'}_j\)</span> 仅与其前驱输入向量 <span class="arithmatex">\(\mathbf{y'}_i\)</span> (其中 <span class="arithmatex">\(i \le j\)</span>，且 <span class="arithmatex">\(j \in {1, \ldots, n}\)</span>) 相关联，来模拟下一个目标向量的概率分布。交叉注意层将其每个输入向量 <span class="arithmatex">\(\mathbf{y''}_j\)</span> 与编码器输出的所有向量 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> 相关联，来根据编码器输入预测下一个目标向量的概率分布。</p>
<p>好，我们仍以英语到德语翻译为例可视化一下 <em>基于 transformer</em> 的解码器。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/encoder_decoder_detail.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/encoder_decoder_detail.png" /></a></p>
<p>我们可以看到解码器将 <span class="arithmatex">\(\mathbf{Y}_{0:5}\)</span>: “BOS”、“Ich”、“will”、“ein”、“Auto”、“kaufen” (图中以浅红色显示) 和 “I”、“want”、“to”、“buy”、“a”、“car”、“EOS” ( <em>即</em> <span class="arithmatex">\(\mathbf{\overline{X}}_{1:7}\)</span> (图中以深绿色显示)) 映射到 logit 向量 <span class="arithmatex">\(\mathbf{L}_{1:6}\)</span> (图中以深红色显示)。</p>
<p>因此，对每个 <span class="arithmatex">\(\mathbf{l}_1、\mathbf{l}_2、\ldots、\mathbf{l}_6\)</span> 使用 softmax 操作可以定义下列条件概率分布:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\mathbf{y} | \text{BOS}, \mathbf{\overline{X}}_{1:7}), $$
&gt; $$ p_{\theta_{dec}}(\mathbf{y} | \text{BOS Ich}, \mathbf{\overline{X}}_{1:7}), $$
&gt; $$ \ldots, $$
&gt; $$ p_{\theta_{dec}}(\mathbf{y} | \text{BOS Ich will ein Auto kaufen}, \mathbf{\overline{X}}_{1:7}) \]</div>
<p>总条件概率如下:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\text{Ich will ein Auto kaufen EOS} | \mathbf{\overline{X}}_{1:n})\]</div>
<p>其可表示为以下乘积形式:</p>
<div class="arithmatex">\[ p_{\theta_{dec}}(\text{Ich} | \text{BOS}, \mathbf{\overline{X}}_{1:7}) \times \ldots \times p_{\theta_{dec}}(\text{EOS} | \text{BOS Ich will ein Auto kaufen}, \mathbf{\overline{X}}_{1:7}) \]</div>
<p>图右侧的红框显示了前三个目标向量 <span class="arithmatex">\(\mathbf{y}_0\)</span>、<span class="arithmatex">\(\mathbf{y}_1\)</span>、 <span class="arithmatex">\(\mathbf{y}_2\)</span> 在一个解码器模块中的行为。下半部分说明了单向自注意机制，中间说明了交叉注意机制。我们首先关注单向自注意力。</p>
<p>与双向自注意一样，在单向自注意中， <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_0, \ldots, \mathbf{q}_{m-1}\)</span> (如下图紫色所示)， <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_0, \ldots, \mathbf{k}_{m-1}\)</span> (如下图橙色所示)，和 <code>value</code> 向量 <span class="arithmatex">\(\mathbf{v }_0, \ldots, \mathbf{v}_{m-1}\)</span> (如下图蓝色所示) 均由输入向量 <span class="arithmatex">\(\mathbf{y'}_0, \ldots, \mathbf{ y'}_{m-1}\)</span> (如下图浅红色所示) 映射而来。然而，在单向自注意力中，每个 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_i\)</span> <em>仅</em> 与当前及之前的 <code>key</code> 向量进行比较 (即 <span class="arithmatex">\(\mathbf{k}_0 , \ldots, \mathbf{k}_i\)</span>) 并生成各自的 <em>注意力权重</em> 。这可以防止输出向量 <span class="arithmatex">\(\mathbf{y''}_j\)</span> (如下图深红色所示) 包含未来向量 (<span class="arithmatex">\(\mathbf{y}_i\)</span>，其中 <span class="arithmatex">\(i &gt; j\)</span> 且  <span class="arithmatex">\(j \in {0, \ldots, m - 1 }\)</span>) 的任何信息 。与双向自注意力的情况一样，得到的注意力权重会乘以它们各自的 <code>value</code> 向量并加权求和。</p>
<p>我们将单向自注意力总结如下:</p>
<div class="arithmatex">\[\mathbf{y''}_i = \mathbf{V}_{0: i} \textbf{Softmax}(\mathbf{K}_{0: i}^\intercal \mathbf{q}_i) + \mathbf{y'}_i\]</div>
<p>请注意， <code>key</code> 和 <code>value</code> 向量的索引范围都是 <span class="arithmatex">\(0:i\)</span> 而不是 <span class="arithmatex">\(0: m-1\)</span>，<span class="arithmatex">\(0: m-1\)</span> 是双向自注意力中 <code>key</code> 向量的索引范围。</p>
<p>下图显示了上例中输入向量 <span class="arithmatex">\(\mathbf{y'}_1\)</span> 的单向自注意力。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/causal_attn.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/causal_attn.png" /></a></p>
<p>可以看出 <span class="arithmatex">\(\mathbf{y''}_1\)</span> 只依赖于 <span class="arithmatex">\(\mathbf{y'}_0\)</span> 和  <span class="arithmatex">\(\mathbf{y'}_1\)</span>。因此，单词 “Ich” 的向量表征 ( <em>即</em> <span class="arithmatex">\(\mathbf{y'}_1\)</span>) 仅与其自身及 “BOS” 目标向量 ( <em>即</em> <span class="arithmatex">\(\mathbf{y'}_0\)</span>) 相关联，而 <strong>不</strong> 与 “will” 的向量表征 ( <em>即</em> <span class="arithmatex">\(\mathbf{y'}_2\)</span>) 相关联。</p>
<p>那么，为什么解码器使用单向自注意力而不是双向自注意力这件事很重要呢？如前所述，基于 transformer 的解码器定义了从输入向量序列 <span class="arithmatex">\(\mathbf{Y}_{0: m-1}\)</span> 到其 <strong>下一个</strong> 解码器输入的 logit 向量的映射，即 <span class="arithmatex">\(\mathbf{L}_{1:m}\)</span>。举个例子，输入向量 <span class="arithmatex">\(\mathbf{y}_1\)</span> = “Ich” 会映射到 logit 向量 <span class="arithmatex">\(\mathbf{l}_2\)</span>，并用于预测下一个输入向量 <span class="arithmatex">\(\mathbf{y}_2\)</span>。因此，如果 <span class="arithmatex">\(\mathbf{y'}_1\)</span> 可以获取后续输入向量 <span class="arithmatex">\(\mathbf{Y'}_{2:5}\)</span>的信息，解码器将会简单地复制向量 “will” 的向量表征 ( <em>即</em> <span class="arithmatex">\(\mathbf{y'}_2\)</span>) 作为其输出 <span class="arithmatex">\(\mathbf{y''}_1\)</span>，并就这样一直传播到最后一层，所以最终的输出向量 <span class="arithmatex">\(\mathbf{\overline{y}}_1\)</span> 基本上就只对应于 <span class="arithmatex">\(\mathbf{y}_2\)</span> 的向量表征，并没有起到预测的作用。</p>
<p>这显然是不对的，因为这样的话，基于 transformer 的解码器永远不会学到在给定所有前驱词的情况下预测下一个词，而只是对所有 <span class="arithmatex">\(i \in {1, \ldots, m }\)</span>，通过网络将目标向量 <span class="arithmatex">\(\mathbf{y}_i\)</span> 复制到 <span class="arithmatex">\(\mathbf {\overline{y}}_{i-1}\)</span>。以下一个目标变量本身为条件去定义下一个目标向量，即从 <span class="arithmatex">\(p(\mathbf{y} | \mathbf{Y}_{0:i}, \mathbf{\overline{ X}})\)</span> 中预测 <span class="arithmatex">\(\mathbf{y}_i\)</span>， 显然是不对的。因此，单向自注意力架构允许我们定义一个 _因果的_概率分布，这对有效建模下一个目标向量的条件分布而言是必要的。</p>
<p>太棒了！现在我们可以转到连接编码器和解码器的层 - _交叉注意力_机制！</p>
<p>交叉注意层将两个向量序列作为输入: 单向自注意层的输出 <span class="arithmatex">\(\mathbf{Y''}_{0: m-1}\)</span> 和编码器的输出 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span>。与自注意力层一样， <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_0, \ldots, \mathbf{q}_{m-1}\)</span> 是上一层输出向量 <span class="arithmatex">\(\mathbf{Y''}_{0: m-1}\)</span> 的投影。而 <code>key</code> 和 <code>value</code> 向量 <span class="arithmatex">\(\mathbf{k}_0, \ldots, \mathbf{k}_{n-1}\)</span>、<span class="arithmatex">\(\mathbf{v}_0, \ldots, \mathbf {v}_{n-1}\)</span> 是编码器输出向量 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span> 的投影。定义完 <code>key</code> 、<code>value</code> 和 <code>query</code> 向量后，将 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_i\)</span> 与  <em>所有</em> <code>key</code> 向量进行比较，并用各自的得分对相应的 <code>value</code> 向量进行加权求和。这个过程与 _双向_自注意力对所有 <span class="arithmatex">\(i \in {0, \ldots, m-1}\)</span> 求 <span class="arithmatex">\(\mathbf{y'''}_i\)</span> 是一样的。交叉注意力可以概括如下:</p>
<div class="arithmatex">\[
\mathbf{y'''}_i = \mathbf{V}_{1:n} \textbf{Softmax}(\mathbf{K}_{1: n}^\intercal \mathbf{q}_i) + \mathbf{y''}_i
\]</div>
<p>注意，<code>key</code> 和 <code>value</code> 向量的索引范围是 <span class="arithmatex">\(1:n\)</span>，对应于编码器输入向量的数目。</p>
<p>我们用上例中输入向量 <span class="arithmatex">\(\mathbf{y''}_1\)</span> 来图解一下交叉注意力机制。</p>
<p><a class="glightbox" href="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/cross_attention.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://raw.githubusercontent.com/patrickvonplaten/scientific_images/master/encoder_decoder/cross_attention.png" /></a></p>
<p>我们可以看到 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_1\)</span>（紫色）源自 <span class="arithmatex">\(\mathbf{y''}_1\)</span>（红色），因此其依赖于单词 "Ich" 的向量表征。然后将 <code>query</code> 向量 <span class="arithmatex">\(\mathbf{q}_1\)</span> 与对应的 <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_1, \ldots, \mathbf{k}_7\)</span>（黄色）进行比较，这里的 <code>key</code> 向量对应于编码器对其输入 <span class="arithmatex">\(\mathbf{X}_{1:n}\)</span> = \"I want to buy a car EOS\" 的上下文相关向量表征。这将 \"Ich\" 的向量表征与所有编码器输入向量直接关联起来。最后，将注意力权重乘以 <code>value</code> 向量 <span class="arithmatex">\(\mathbf{v}_1, \ldots, \mathbf{v}_7\)</span>（青绿色）并加上输入向量 <span class="arithmatex">\(\mathbf{y''}_1\)</span> 最终得到输出向量 <span class="arithmatex">\(\mathbf{y'''}_1\)</span>（深红色）。</p>
<p>所以，直观而言，到底发生了什么？每个输出向量 <span class="arithmatex">\(\mathbf{y'''}_i\)</span> 是由所有从编码器来的 <code>value</code> 向量（<span class="arithmatex">\(\mathbf{v}_{1}, \ldots, \mathbf{v }_7\)</span> ）的加权和与输入向量本身 <span class="arithmatex">\(\mathbf{y''}_i\)</span> 相加而得（参见上图所示的公式）。其关键思想是：<em>来自解码器的</em> <span class="arithmatex">\(\mathbf{q}_i\)</span> 的 <code>query</code> 投影与 <em>来自编码器的 <span class="arithmatex">\(\mathbf{k}_j\)</span></em> 越相关，其对应的 <span class="arithmatex">\(\mathbf{v}_j\)</span> 对输出的影响越大。</p>
<p>酷！现在我们可以看到这种架构的每个输出向量 <span class="arithmatex">\(\mathbf{y'''}_i\)</span> 取决于其来自编码器的输入向量 <span class="arithmatex">\(\mathbf{\overline{X}}_{1 :n}\)</span> 及其自身的输入向量 <span class="arithmatex">\(\mathbf{y''}_i\)</span>。这里有一个重要的点，在该架构中，虽然输出向量 <span class="arithmatex">\(\mathbf{y'''}_i\)</span> 依赖来自编码器的输入向量 <span class="arithmatex">\(\mathbf{\overline{X}}_{1:n}\)</span>，但其完全独立于该向量的数量 <span class="arithmatex">\(n\)</span>。所有生成 <code>key</code> 向量 <span class="arithmatex">\(\mathbf{k}_1, \ldots, \mathbf{k}_n\)</span> 和 <code>value</code> 向量 $\mathbf{v}<em>1, \ldots, \mathbf{v}_n $ 的投影矩阵 <span class="arithmatex">\(\mathbf{W}^{\text{cross}}_{k}\)</span> 和 <span class="arithmatex">\(\mathbf{W}^{\text{cross}}_{v}\)</span> 都是与 <span class="arithmatex">\(n\)</span> 无关的，所有 <span class="arithmatex">\(n\)</span> 共享同一个投影矩阵。且对每个 <span class="arithmatex">\(\mathbf{y'''}_i\)</span>，所有 <code>value</code> 向量 <span class="arithmatex">\(\mathbf{v}_1, \ldots, \mathbf{v}_n\)</span> 被加权求和至一个向量。至此，关于<code>为什么基于 transformer 的解码器没有远程依赖问题而基于 RNN 的解码器有</code>这一问题的答案已经很显然了。因为每个解码器 logit 向量 _直接</em> 依赖于每个编码后的输出向量，因此比较第一个编码输出向量和最后一个解码器 logit 向量只需一次操作，而不像 RNN 需要很多次。</p>
<p>总而言之，单向自注意力层负责基于当前及之前的所有解码器输入向量建模每个输出向量，而交叉注意力层则负责进一步基于编码器的所有输入向量建模每个输出向量。</p>
<p>为了验证我们对该理论的理解，我们继续上面编码器部分的代码，完成解码器部分。</p>
<hr />
<p><span class="arithmatex">\({}^1\)</span> 词嵌入矩阵 <span class="arithmatex">\(\mathbf{W}_{\text{emb}}\)</span> 为每个输入词提供唯一的 _上下文无关_向量表示。这个矩阵通常也被用作 “LM 头”，此时 “LM 头”可以很好地完成“编码向量到 logit” 的映射。</p>
<p><span class="arithmatex">\({}^2\)</span> 与编码器部分一样，本文不会详细解释前馈层在基于 transformer 的模型中的作用。<a href="https://arxiv.org/pdf/1912.10077.pdf">Yun 等 (2017) </a> 的工作认为前馈层对于将每个上下文相关向量 <span class="arithmatex">\(\mathbf{x'}_i\)</span> 映射到所需的输出空间至关重要，仅靠自注意力层无法完成。这里应该注意，每个输出词元 <span class="arithmatex">\(\mathbf{x'}\)</span> 对应的前馈层是相同的。有关更多详细信息，建议读者阅读论文。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianMTModel</span><span class="p">,</span> <span class="n">MarianTokenizer</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a><span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a><span class="n">embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_input_embeddings</span><span class="p">()</span>
</span><span id="__span-5-7"><a id="__codelineno-5-7" name="__codelineno-5-7" href="#__codelineno-5-7"></a>
</span><span id="__span-5-8"><a id="__codelineno-5-8" name="__codelineno-5-8" href="#__codelineno-5-8"></a><span class="c1"># create token ids for encoder input</span>
</span><span id="__span-5-9"><a id="__codelineno-5-9" name="__codelineno-5-9" href="#__codelineno-5-9"></a><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I want to buy a car&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-5-10"><a id="__codelineno-5-10" name="__codelineno-5-10" href="#__codelineno-5-10"></a>
</span><span id="__span-5-11"><a id="__codelineno-5-11" name="__codelineno-5-11" href="#__codelineno-5-11"></a><span class="c1"># pass input token ids to encoder</span>
</span><span id="__span-5-12"><a id="__codelineno-5-12" name="__codelineno-5-12" href="#__codelineno-5-12"></a><span class="n">encoder_output_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span><span id="__span-5-13"><a id="__codelineno-5-13" name="__codelineno-5-13" href="#__codelineno-5-13"></a>
</span><span id="__span-5-14"><a id="__codelineno-5-14" name="__codelineno-5-14" href="#__codelineno-5-14"></a><span class="c1"># create token ids for decoder input</span>
</span><span id="__span-5-15"><a id="__codelineno-5-15" name="__codelineno-5-15" href="#__codelineno-5-15"></a><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;&lt;pad&gt; Ich will ein&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-5-16"><a id="__codelineno-5-16" name="__codelineno-5-16" href="#__codelineno-5-16"></a>
</span><span id="__span-5-17"><a id="__codelineno-5-17" name="__codelineno-5-17" href="#__codelineno-5-17"></a><span class="c1"># pass decoder input ids and encoded input vectors to decoder</span>
</span><span id="__span-5-18"><a id="__codelineno-5-18" name="__codelineno-5-18" href="#__codelineno-5-18"></a><span class="n">decoder_output_vectors</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">encoder_output_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span><span id="__span-5-19"><a id="__codelineno-5-19" name="__codelineno-5-19" href="#__codelineno-5-19"></a>
</span><span id="__span-5-20"><a id="__codelineno-5-20" name="__codelineno-5-20" href="#__codelineno-5-20"></a><span class="c1"># derive embeddings by multiplying decoder outputs with embedding weights</span>
</span><span id="__span-5-21"><a id="__codelineno-5-21" name="__codelineno-5-21" href="#__codelineno-5-21"></a><span class="n">lm_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">decoder_output_vectors</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">final_logits_bias</span><span class="p">)</span>
</span><span id="__span-5-22"><a id="__codelineno-5-22" name="__codelineno-5-22" href="#__codelineno-5-22"></a>
</span><span id="__span-5-23"><a id="__codelineno-5-23" name="__codelineno-5-23" href="#__codelineno-5-23"></a><span class="c1"># change the decoder input slightly</span>
</span><span id="__span-5-24"><a id="__codelineno-5-24" name="__codelineno-5-24" href="#__codelineno-5-24"></a><span class="n">decoder_input_ids_perturbed</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;&lt;pad&gt; Ich will das&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-5-25"><a id="__codelineno-5-25" name="__codelineno-5-25" href="#__codelineno-5-25"></a><span class="n">decoder_output_vectors_perturbed</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">base_model</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">decoder_input_ids_perturbed</span><span class="p">,</span> <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">encoder_output_vectors</span><span class="p">)</span><span class="o">.</span><span class="n">last_hidden_state</span>
</span><span id="__span-5-26"><a id="__codelineno-5-26" name="__codelineno-5-26" href="#__codelineno-5-26"></a><span class="n">lm_logits_perturbed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">decoder_output_vectors_perturbed</span><span class="p">,</span> <span class="n">embeddings</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">final_logits_bias</span><span class="p">)</span>
</span><span id="__span-5-27"><a id="__codelineno-5-27" name="__codelineno-5-27" href="#__codelineno-5-27"></a>
</span><span id="__span-5-28"><a id="__codelineno-5-28" name="__codelineno-5-28" href="#__codelineno-5-28"></a><span class="c1"># compare shape and encoding of first vector</span>
</span><span id="__span-5-29"><a id="__codelineno-5-29" name="__codelineno-5-29" href="#__codelineno-5-29"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of decoder input vectors </span><span class="si">{</span><span class="n">embeddings</span><span class="p">(</span><span class="n">decoder_input_ids</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">. Shape of decoder logits </span><span class="si">{</span><span class="n">lm_logits</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-5-30"><a id="__codelineno-5-30" name="__codelineno-5-30" href="#__codelineno-5-30"></a>
</span><span id="__span-5-31"><a id="__codelineno-5-31" name="__codelineno-5-31" href="#__codelineno-5-31"></a><span class="c1"># compare values of word embedding of &quot;I&quot; for input_ids and perturbed input_ids</span>
</span><span id="__span-5-32"><a id="__codelineno-5-32" name="__codelineno-5-32" href="#__codelineno-5-32"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Is encoding for `Ich` equal to its perturbed version?: &quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">lm_logits</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">lm_logits_perturbed</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">))</span>
</span></code></pre></div>
<p><em>输出:</em></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a>    Shape of decoder input vectors torch.Size([1, 5, 512]). Shape of decoder logits torch.Size([1, 5, 58101])
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a>    Is encoding for `Ich` equal to its perturbed version?: True
</span></code></pre></div>
<p>我们首先比较解码器词嵌入层的输出维度 <code>embeddings(decoder_input_ids)</code> (对应于 <span class="arithmatex">\(\mathbf{Y}_{0: 4}\)</span>，这里 <code>&lt;pad&gt;</code> 对应于 BOS 且  "Ich will das" 被分为 4 个词) 和 <code>lm_logits</code> (对应于 <span class="arithmatex">\(\mathbf{L}_{1:5}\)</span>) 的维度。此外，我们还通过解码器将单词序列 “<code>&lt;pad&gt;</code> Ich will ein” 和其轻微改编版 “<code>&lt;pad&gt;</code> Ich will das” 与 <code>encoder_output_vectors</code> 一起传递给解码器，以检查对应于 “Ich” 的第二个 lm_logit 在仅改变输入序列中的最后一个单词 (“ein” -&gt; “das”) 时是否会有所不同。</p>
<p>正如预期的那样，解码器输入词嵌入和 lm_logits 的输出， <em>即</em> <span class="arithmatex">\(\mathbf{Y}_{0: 4}\)</span> 和  <span class="arithmatex">\(\mathbf{L}_{ 1:5}\)</span> 的最后一个维度不同。虽然序列长度相同 (=5)，但解码器输入词嵌入的维度对应于 <code>model.config.hidden_​​size</code>，而 <code>lm_logit</code> 的维数对应于词汇表大小 <code>model.config.vocab_size</code>。其次，可以注意到，当将最后一个单词从 “ein” 变为 “das”，<span class="arithmatex">\(\mathbf{l}_1 = \text{“Ich”}\)</span> 的输出向量的值不变。鉴于我们已经理解了单向自注意力，这就不足为奇了。</p>
<p>最后一点， <em>自回归_模型，如 GPT2，与删除了交叉注意力层的 _基于 transformer</em> 的解码器模型架构是相同的，因为纯自回归模型不依赖任何编码器的输出。因此，自回归模型本质上与 _自编码_模型相同，只是用单向注意力代替了双向注意力。这些模型还可以在大量开放域文本数据上进行预训练，以在自然语言生成 (NLG) 任务中表现出令人印象深刻的性能。在 <a href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf">Radford 等 (2019) </a> 的工作中，作者表明预训练的 GPT2 模型无需太多微调即可在多种 NLG 任务上取得达到 SOTA 或接近 SOTA 的结果。你可以在 <a href="https://huggingface.co/transformers/model_summary.html#autoregressive-models">此处</a> 获取所有 🤗 transformers 支持的 _自回归_模型的信息。</p>
<p>好了！至此，你应该已经很好地理解了 <em>基于 transforemr</em> 的编码器-解码器模型以及如何在 🤗 transformers 库中使用它们。</p>
<p>非常感谢 Victor Sanh、Sasha Rush、Sam Shleifer、Oliver Åstrand、Ted Moskovitz 和 Kristian Kyvik 提供的宝贵反馈。</p>
<h2 id="_4"><strong>附录</strong><a class="headerlink" href="#_4" title="Permanent link">&para;</a></h2>
<p>如上所述，以下代码片段展示了如何为 <em>基于 transformer</em> 的编码器-解码器模型编写一个简单的生成方法。在这里，我们使用 <code>torch.argmax</code> 实现了一个简单的 _贪心_解码法来对目标向量进行采样。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">MarianMTModel</span><span class="p">,</span> <span class="n">MarianTokenizer</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">MarianTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="n">model</span> <span class="o">=</span> <span class="n">MarianMTModel</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;Helsinki-NLP/opus-mt-en-de&quot;</span><span class="p">)</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="c1"># create ids of encoded input vectors</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;I want to buy a car&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="c1"># create BOS token</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="p">(</span><span class="s2">&quot;&lt;pad&gt;&quot;</span><span class="p">,</span> <span class="n">add_special_tokens</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="k">assert</span> <span class="n">decoder_input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="n">model</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">decoder_start_token_id</span><span class="p">,</span> <span class="s2">&quot;`decoder_input_ids` should correspond to `model.config.decoder_start_token_id`&quot;</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="c1"># STEP 1</span>
</span><span id="__span-7-16"><a id="__codelineno-7-16" name="__codelineno-7-16" href="#__codelineno-7-16"></a>
</span><span id="__span-7-17"><a id="__codelineno-7-17" name="__codelineno-7-17" href="#__codelineno-7-17"></a><span class="c1"># pass input_ids to encoder and to decoder and pass BOS token to decoder to retrieve first logit</span>
</span><span id="__span-7-18"><a id="__codelineno-7-18" name="__codelineno-7-18" href="#__codelineno-7-18"></a><span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">input_ids</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-7-19"><a id="__codelineno-7-19" name="__codelineno-7-19" href="#__codelineno-7-19"></a>
</span><span id="__span-7-20"><a id="__codelineno-7-20" name="__codelineno-7-20" href="#__codelineno-7-20"></a><span class="c1"># get encoded sequence</span>
</span><span id="__span-7-21"><a id="__codelineno-7-21" name="__codelineno-7-21" href="#__codelineno-7-21"></a><span class="n">encoded_sequence</span> <span class="o">=</span> <span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">encoder_last_hidden_state</span><span class="p">,)</span>
</span><span id="__span-7-22"><a id="__codelineno-7-22" name="__codelineno-7-22" href="#__codelineno-7-22"></a><span class="c1"># get logits</span>
</span><span id="__span-7-23"><a id="__codelineno-7-23" name="__codelineno-7-23" href="#__codelineno-7-23"></a><span class="n">lm_logits</span> <span class="o">=</span> <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span>
</span><span id="__span-7-24"><a id="__codelineno-7-24" name="__codelineno-7-24" href="#__codelineno-7-24"></a>
</span><span id="__span-7-25"><a id="__codelineno-7-25" name="__codelineno-7-25" href="#__codelineno-7-25"></a><span class="c1"># sample last token with highest prob</span>
</span><span id="__span-7-26"><a id="__codelineno-7-26" name="__codelineno-7-26" href="#__codelineno-7-26"></a><span class="n">next_decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">lm_logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-7-27"><a id="__codelineno-7-27" name="__codelineno-7-27" href="#__codelineno-7-27"></a>
</span><span id="__span-7-28"><a id="__codelineno-7-28" name="__codelineno-7-28" href="#__codelineno-7-28"></a><span class="c1"># concat</span>
</span><span id="__span-7-29"><a id="__codelineno-7-29" name="__codelineno-7-29" href="#__codelineno-7-29"></a><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">next_decoder_input_ids</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-7-30"><a id="__codelineno-7-30" name="__codelineno-7-30" href="#__codelineno-7-30"></a>
</span><span id="__span-7-31"><a id="__codelineno-7-31" name="__codelineno-7-31" href="#__codelineno-7-31"></a><span class="c1"># STEP 2</span>
</span><span id="__span-7-32"><a id="__codelineno-7-32" name="__codelineno-7-32" href="#__codelineno-7-32"></a>
</span><span id="__span-7-33"><a id="__codelineno-7-33" name="__codelineno-7-33" href="#__codelineno-7-33"></a><span class="c1"># reuse encoded_inputs and pass BOS + &quot;Ich&quot; to decoder to second logit</span>
</span><span id="__span-7-34"><a id="__codelineno-7-34" name="__codelineno-7-34" href="#__codelineno-7-34"></a><span class="n">lm_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="o">=</span><span class="n">encoded_sequence</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">logits</span>
</span><span id="__span-7-35"><a id="__codelineno-7-35" name="__codelineno-7-35" href="#__codelineno-7-35"></a>
</span><span id="__span-7-36"><a id="__codelineno-7-36" name="__codelineno-7-36" href="#__codelineno-7-36"></a><span class="c1"># sample last token with highest prob again</span>
</span><span id="__span-7-37"><a id="__codelineno-7-37" name="__codelineno-7-37" href="#__codelineno-7-37"></a><span class="n">next_decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">lm_logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-7-38"><a id="__codelineno-7-38" name="__codelineno-7-38" href="#__codelineno-7-38"></a>
</span><span id="__span-7-39"><a id="__codelineno-7-39" name="__codelineno-7-39" href="#__codelineno-7-39"></a><span class="c1"># concat again</span>
</span><span id="__span-7-40"><a id="__codelineno-7-40" name="__codelineno-7-40" href="#__codelineno-7-40"></a><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">next_decoder_input_ids</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-7-41"><a id="__codelineno-7-41" name="__codelineno-7-41" href="#__codelineno-7-41"></a>
</span><span id="__span-7-42"><a id="__codelineno-7-42" name="__codelineno-7-42" href="#__codelineno-7-42"></a><span class="c1"># STEP 3</span>
</span><span id="__span-7-43"><a id="__codelineno-7-43" name="__codelineno-7-43" href="#__codelineno-7-43"></a><span class="n">lm_logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">encoder_outputs</span><span class="o">=</span><span class="n">encoded_sequence</span><span class="p">,</span> <span class="n">decoder_input_ids</span><span class="o">=</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">logits</span>
</span><span id="__span-7-44"><a id="__codelineno-7-44" name="__codelineno-7-44" href="#__codelineno-7-44"></a><span class="n">next_decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">lm_logits</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">:],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-7-45"><a id="__codelineno-7-45" name="__codelineno-7-45" href="#__codelineno-7-45"></a><span class="n">decoder_input_ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">decoder_input_ids</span><span class="p">,</span> <span class="n">next_decoder_input_ids</span><span class="p">],</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-7-46"><a id="__codelineno-7-46" name="__codelineno-7-46" href="#__codelineno-7-46"></a>
</span><span id="__span-7-47"><a id="__codelineno-7-47" name="__codelineno-7-47" href="#__codelineno-7-47"></a><span class="c1"># let&#39;s see what we have generated so far!</span>
</span><span id="__span-7-48"><a id="__codelineno-7-48" name="__codelineno-7-48" href="#__codelineno-7-48"></a><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Generated so far: </span><span class="si">{</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">decoder_input_ids</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span><span class="w"> </span><span class="n">skip_special_tokens</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</span><span id="__span-7-49"><a id="__codelineno-7-49" name="__codelineno-7-49" href="#__codelineno-7-49"></a>
</span><span id="__span-7-50"><a id="__codelineno-7-50" name="__codelineno-7-50" href="#__codelineno-7-50"></a><span class="c1"># This can be written in a loop as well.</span>
</span></code></pre></div>
<p><em>输出:</em></p>
<div class="language-text highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a>    Generated so far: Ich will ein
</span></code></pre></div>
<p>在这个示例代码中，我们准确地展示了正文中描述的内容。我们在输入 “I want to buy a car” 前面加上 <span class="arithmatex">\(\text{BOS}\)</span> ，然后一起传给编码器-解码器模型，并对第一个 logit $\mathbf{l}_1 $ (对应代码中第一次出现 lm_logits 的部分) 进行采样。这里，我们的采样策略很简单: 贪心地选择概率最高的词作为下一个解码器输入向量。然后，我们以自回归方式将采样得的解码器输入向量与先前的输入一起传递给编码器-解码器模型并再次采样。重复 3 次后，该模型生成了 “Ich will ein”。结果没问题，开了个好头。</p>
<p>在实践中，我们会使用更复杂的解码方法来采样 <code>lm_logits</code>。你可以参考 <a href="https://huggingface.co/blog/zh/how-to-generate">这篇博文</a> 了解更多的解码方法。</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9 3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3 3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3 3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.54 5.54 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13zM0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9-.59.68-.95 1.62-.95 2.65V20zm24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65 2.56.34 4.45 1.51 4.45 2.9z"/></svg>
      
    </span>
    <nav>
      
    </nav>
  </span>

    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank" rel="noopener">feedback form</a>.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../embedding-quantization/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 用于显著提高检索速度和降低成本的二进制和标量嵌入量化">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                用于显著提高检索速度和降低成本的二进制和标量嵌入量化
              </div>
            </div>
          </a>
        
        
          
          <a href="../encrypted-llm/" class="md-footer__link md-footer__link--next" aria-label="Next: 使用 FHE 实现加密大语言模型">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                使用 FHE 实现加密大语言模型
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 - 2024 FastX-AI
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
    
    
    
    <a href="https://fastx-ai.com" target="_blank" rel="noopener me" title="fastx-ai" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:x.stark.dylan@gmail.com" target="_blank" rel="noopener" title="send me an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 112c-8.8 0-16 7.2-16 16v22.1l172.5 141.6c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16zM48 212.2V384c0 8.8 7.2 16 16 16h384c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0zM0 128c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64z"/></svg>
    </a>
  
    
    
    
    
    <a href="/contact" target="_blank" rel="noopener" title="contact us" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 4H7a5 5 0 0 0-5 5v11h18a2 2 0 0 0 2-2V9a5 5 0 0 0-5-5m-7 14H4V9a3 3 0 0 1 3-3 3 3 0 0 1 3 3zm9-3h-2v-2h-4v-2h6zM9 11H5V9h4z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.prune", "content.action.edit", "content.code.copy", "content.code.annotate", "content.tabs.link", "content.tooltips", "header.autohide", "announce.dismiss", "search.suggest", "search.highlight", "search.share", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
<!-- Add scripts that need to run before here -->

      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
<!-- Add scripts that need to run afterwards here -->

  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>