
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="FastDoc is a website that you can get started with FastX AI in minutes.">
      
      
      
        <link rel="canonical" href="https://doc.fastx-ai.com/ml/the_n_implementation_details_of_rlhf_with_ppo/">
      
      
        <link rel="prev" href="../the-age-of-ml-as-code/">
      
      
        <link rel="next" href="../time-series-transformers/">
      
      
        <link rel="alternate" type="application/rss+xml" title="RSS feed" href="../../feed_rss_created.xml">
        <link rel="alternate" type="application/rss+xml" title="RSS feed of updated content" href="../../feed_rss_updated.xml">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.46">
    
    
      
        <title>使用 PPO 算法进行 RLHF 的 N 步实现细节 - FastDocs</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.6f8fc17f.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
      
        <meta  property="og:type"  content="website" >
      
        <meta  property="og:title"  content="使用 PPO 算法进行 RLHF 的 N 步实现细节 - FastDocs" >
      
        <meta  property="og:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  property="og:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/the_n_implementation_details_of_rlhf_with_ppo.png" >
      
        <meta  property="og:image:type"  content="image/png" >
      
        <meta  property="og:image:width"  content="1200" >
      
        <meta  property="og:image:height"  content="630" >
      
        <meta  property="og:url"  content="https://doc.fastx-ai.com/ml/the_n_implementation_details_of_rlhf_with_ppo/" >
      
        <meta  name="twitter:card"  content="summary_large_image" >
      
        <meta  name="twitter:title"  content="使用 PPO 算法进行 RLHF 的 N 步实现细节 - FastDocs" >
      
        <meta  name="twitter:description"  content="FastDoc is a website that you can get started with FastX AI in minutes." >
      
        <meta  name="twitter:image"  content="https://doc.fastx-ai.com/assets/images/social/ml/the_n_implementation_details_of_rlhf_with_ppo.png" >
      
    
    
   <link href="../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
    html.glightbox-open { overflow: initial; height: 100%; }
    .gslide-title { margin-top: 0px; user-select: text; }
    .gslide-desc { color: #666; user-select: text; }
    .gslide-image img { background: white; }
    .gscrollbar-fixer { padding-right: 15px; }
    .gdesc-inner { font-size: 0.75rem; }
    body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
    body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
    body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}</style> <script src="../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#ppo-rlhf-n" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
              <button class="md-banner__button md-icon" aria-label="Don't show this again">
                
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
              </button>
            
            
<p style="text-align: center">
  Welcome to <span style="font-size: bold">FastDocs</span>! Just feel free to start read docs!
</p>

          </div>
          
            <script>var el=document.querySelector("[data-md-component=announce]");if(el){var content=el.querySelector(".md-typeset");__md_hash(content.innerHTML)===__md_get("__announce")&&(el.hidden=!0)}</script>
          
        </aside>
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="FastDocs" class="md-header__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            FastDocs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              使用 PPO 算法进行 RLHF 的 N 步实现细节
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../.." class="md-tabs__link">
        
  
    
  
  主页

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../backend/" class="md-tabs__link">
        
  
    
  
  后端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../web/" class="md-tabs__link">
        
  
    
  
  前端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../client/" class="md-tabs__link">
        
  
    
  
  客户端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../pc/" class="md-tabs__link">
        
  
    
  
  桌面端

      </a>
    </li>
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../big-data/" class="md-tabs__link">
        
  
    
  
  大数据

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../1_58_llm_extreme_quantization/" class="md-tabs__link">
          
  
    
  
  人工智能

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../ops/" class="md-tabs__link">
        
  
    
  
  运维

      </a>
    </li>
  

      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../blog/" class="md-tabs__link">
          
  
    
  
  博客

        </a>
      </li>
    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../resume/" class="md-tabs__link">
        
  
    
  
  简历模板

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


  

<nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="FastDocs" class="md-nav__button md-logo" aria-label="FastDocs" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    FastDocs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/C-L-STARK/C-L-STARK.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1M480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2m-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3m-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1"/></svg>
  </div>
  <div class="md-source__repository">
    C-L-STARK/C-L-STARK.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    主页
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../backend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    后端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../web/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    前端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../client/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    客户端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    桌面端
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../big-data/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大数据
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
        
      
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_7" checked>
        
          
          <label class="md-nav__link" for="__nav_7" id="__nav_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    人工智能
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_7_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_7">
            <span class="md-nav__icon md-icon"></span>
            人工智能
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1_58_llm_extreme_quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Fine-tuning LLMs to 1.58bit: extreme quantization made easy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2023-in-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2023, 开源大模型之年
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../3d-assets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    手把手教你使用人工智能生成 3D 素材
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4bit-transformers-bitsandbytes/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 bitsandbytes、4 比特量化和 QLoRA 打造亲民的 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Llama2-for-non-engineers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    非工程师指南：训练 LLaMA 2 聊天机器人
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../Lora-for-sequence-classification-with-Roberta-Llama-Mistral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在灾难推文分析场景上比较用 LoRA 微调 Roberta、Llama 2 和 Mistral 的过程及表现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../_policy-ntia-rfc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能政策@🤗：回应美国国家电信和信息管理局（ NTIA ）关于人工智能问责制的评论请求
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerate-v1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Accelerate 1.0.0
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../accelerated-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何成功将 🤗 API 客户的 transformer 模型推理速度加快 100 倍
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    授权调用：介绍 Transformers 智能体 2.0  
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../aivsai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 大战 AI，一个深度强化学习多智能体竞赛系统
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../arena-tts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TTS 擂台: 文本转语音模型的自由搏击场
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../asr-diarization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 推理终端搭建强大的“语音识别 + 说话人分割 + 投机解码”工作流
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation-support-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    英特尔 Gaudi 加速辅助生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../assisted-generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    辅助生成：低延迟文本生成的新方向
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../audioldm2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AudioLDM 2，加速⚡️！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../autoformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer 模型能够有效地进行时间序列预测 (使用 Autoformer)
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../beating-gaia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformers 代码智能体成功刷榜 GAIA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../big-bird/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解 BigBird 的块稀疏注意力
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BLIP-2 零样本“图生文”
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-optimization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    优化故事: BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-inference-pytorch-scripts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DeepSpeed 和 Accelerate 进行超快 BLOOM 模型推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bloom-megatron-deepspeed/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    千亿参数开源大模型 BLOOM 背后的技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../bridgetower/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Habana Gaudi2 加速视觉语言模型 BridgeTower
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chat-templates/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    聊天模板：无声性能杀手的终结
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-ai-expansion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    中国 AI 出海现状概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../chinese-language-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中文博客正式发布！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cloudflare-workers-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为 Hugging Face 用户带来无服务器 GPU 推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../codellama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Code Llama：Llama 2 学会写代码了！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../community-datasets/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    数据好合：Argilla 和 Hugging Face Spaces 赋能社区合力构建更好的数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../constrained-beam-search/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 🤗 Transformers 中使用约束波束搜索引导文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🧨 Diffusers 实现 ControlNet 高速推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cosmopedia/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Cosmopedia：如何为大语言模型预训练构建大规模合成数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cost-efficient-rag-applications-with-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用英特尔 Gaudi 2 和至强 CPU 构建经济高效的企业级 RAG 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../cv_state/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 中计算机视觉的现状
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../daily-papers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 论文平台 Daily Papers 功能全解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dedup/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCode 背后的大规模数据去重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deep-learning-with-proteins/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    蛋白质深度学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepspeed-to-fsdp-and-back/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 DeepSpeed 到 FSDP，再回到 Hugging Face Accelerate
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-deepfloydif-using-bentoml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 BentoML 部署 🤗 Hugging Face 上的模型：DeepFloyd IF 实战
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deploy-with-openvino/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Optimum-Intel 和 OpenVINO GenAI 优化和部署模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dialog-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    是什么让对话代理有用？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffusers-turns-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Diffusers 一岁啦 !
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Docmatix - 超大文档视觉问答数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../document-ai/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    加速 Document AI (文档智能) 发展
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo-trl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DPO 微调 Llama 2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dpo_vlm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为视觉语言多模态模型进行偏好优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dreambooth/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Diffusers 通过 Dreambooth 技术来训练 Stable Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dynamic_speculation_lookahead/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的辅助生成: 动态推测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../elixir-bumblebee/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 GPT2 到 Stable Diffusion：Elixir 社区迎来了 Hugging Face
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../embedding-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用于显著提高检索速度和降低成本的二进制和标量嵌入量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encoder-decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Transformers 的编码器-解码器模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../encrypted-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 FHE 实现加密大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开发 Diffusers 库的道德行为指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    道德与社会问题简报 #3: Hugging Face 上的道德开放性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ethics-soc-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ethics and Society Newsletter #4: Bias in Text-to-Image Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon-180b/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 180B 登陆 Hugging Face Hub 🔥
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falcon/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon 登陆 Hugging Face 生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../falconmamba/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Falcon Mamba: 首个高效的无注意力机制 7B 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-tune-whisper/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 为多语种语音识别任务微调 Whisper 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../fine-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    揭秘 FineVideo 数据集构建的背后的秘密
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../finetune-florence2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调 Florence-2 - 微软的尖端视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../game-jam-first-edition-results/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    首届开源 AI 游戏挑战赛事结果
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gaussian-splatting/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3D 高斯点染简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-july-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 最新发布： Gemma 2 2B, ShieldGemma 和 Gemma Scope
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Hugging Face 微调 Gemma 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Gemma: Google 最新推出开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gemma2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Google 发布最新开放大语言模型 Gemma 2，现已登陆 Hugging Face Hub
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../generative-ai-models-on-intel-cpu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    越小越好：Q8-Chat，在英特尔至强 CPU 上体验高效的生成式 AI
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started-habana/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Habana Gaudi 的 Transformers 入门
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../google-cloud-model-garden/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Google Cloud 上轻松部署开放大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gptq-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 AutoGPTQ 和 transformers 让大语言模型更轻量化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio 5 现已发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-lite/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gradio-Lite: 完全在浏览器里运行的无服务器 Gradio
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gradio-reload/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Gradio 的“热重载”模式快速开发 AI 应用
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../graphml-classification/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Transformers 进行图分类
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-benchmark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    更快的训练和推理：对比 Habana Gaudi®2 和英伟达 A100 80GB
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../habana-gaudi-2-bloom/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型快速推理：在 Habana Gaudi2 上推理 BLOOMZ
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hf-bitsandbytes-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大规模 Transformer 模型 8 比特矩阵乘简介 - 基于 Hugging Face Transformers、Accelerate 以及 bitsandbytes
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../how-to-generate/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何生成文本：通过 Transformers 用不同的解码方法生成文本
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hugging-face-wiz-security-blog/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 Wiz Research 合作提高人工智能安全性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../huggy-lingo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Huggy Lingo：利用机器学习改进 Hugging Face Hub 上的语言元数据
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IDEFICS 简介：最先进视觉语言模型的开源复现
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../idefics2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Idefics2 简介：为社区而生的强大 8B 视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在免费版 Google Colab 上使用 🧨 diffusers 运行 IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../image-similarity/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Hugging Face Datasets 和 Transformers 的图像相似性搜索
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-endpoints-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Hugging Face 推理端点部署 LLM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../inference-update/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 提供的推理（Inference）解决方案
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../infini-attention/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一次失败的实验——无限注意力，我们为什么坚持实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../informer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 Informer 进行多元概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../instruction-tuning-sd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 InstructPix2Pix 对 Stable Diffusion 进行指令微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-fast-embedding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    利用 🤗 Optimum Intel 和 fastRAG 在 CPU 上优化文本嵌入
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-protein-language-model-protst/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 Gaudi 2 上加速蛋白质语言模型 ProtST
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids-inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CPU 推理 | 使用英特尔 Sapphire Rapids 加速 PyTorch Transformers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-sapphire-rapids/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用英特尔 Sapphire Rapids 加速 PyTorch Transformers 模型（第一部分）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intel-starcoder-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Optimum Intel 在英特尔至强上加速 StarCoder：Q8/Q4 及投机解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../intro-graphml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    一文带你入门图机器学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introducing-csearch/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Transformers 中使用对比搜索生成可媲美人类水平的文本🤗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-to-ggml/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ggml 简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../jat/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    万事通，专精部分领域的多功能 Transformer 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kv-cache-quantization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 KV 缓存量化解锁长文本生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../langchain/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face x LangChain：全新 LangChain 合作伙伴包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../large-language-models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    大语言模型：新的摩尔定律？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lcm_lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LCM LoRA 4 步完成 SDXL 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-bigcodebench/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BigCodeBench: 继 HumanEval 之后的新一代代码生成基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-decodingtrust/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    来自 AI Secure 实验室的 LLM 安全排行榜简介
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-medicalllm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源医疗大模型排行榜：健康领域大模型基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../leaderboard-patronus/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    企业场景排行榜简介：现实世界用例排行榜
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 2 来袭 - 在 Hugging Face 上玩转它
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Llama 3：Meta 的新一代开源大语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama31/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Llama 3.1：405B/70B/8B 模型的多语言与长上下文能力解析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../llama32/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    现在 Llama 具备视觉能力并可以在你的设备上运行 - 欢迎使用 Llama 3.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../long-range-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    长程 transformer 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 LoRA 进行 Stable Diffusion 的高效参数微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mask2former/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用图像分割任务：使用 Mask2Former 和 OneFormer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../matryoshka/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🪆 俄罗斯套娃嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../megatron-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何使用 Megatron-LM 训练语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mixtral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Mixtral - 当前 Hugging Face 上最先进的 MoE 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-1/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于AI进行游戏开发：5天！创建一个农场游戏！第1部分
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 ChatGPT 启发游戏创意｜基于 AI 5 天创建一个农场游戏，第 2 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AI 制作 3D 素材｜基于 AI 5 天创建一个农场游戏，第 3 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-4/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    制作 2D 素材｜基于 AI 5 天创建一个农场游戏，第 4 天
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ml-for-games-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 设计游戏剧情 | 基于 AI 5 天创建一个农场游戏，完结篇！
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../mms_adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    微调用于多语言 ASR 的 MMS 适配器模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../moe/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    混合专家模型（MoE）详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../multi-lora-serving/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 多-LoRA：部署一次，搞定 30 个模型的推理服务
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../noob_intro_transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face Transformers 萌新完全指南
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-drop/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开放 LLM 排行榜：深入研究 DROP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-mmlu/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Open LLM 排行榜近况
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-llm-leaderboard-rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基础大模型能像人类一样标注数据吗？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../open-source-llms-as-agents/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源大语言模型作为 LangChain 智能体
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimize-llm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    面向生产的 LLM 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimizing-bark/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 优化 Bark
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../optimum-onnxruntime-training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Optimum + ONNX Runtime: 更容易、更快地训练你的 Hugging Face 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../os-llms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 的文本生成和大语言模型的开源生态
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview-quantization-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 Transformers 中原生支持的量化方案概述
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../packing-with-FA2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通过打包 Flash Attention 来提升 Hugging Face 训练效率
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../paligemma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PaliGemma 正式发布 — Google 最新发布的前沿开放视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../password-git-deprecation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hub 上的 Git 操作不再支持使用密码验证
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    🤗 PEFT：在低资源硬件上对十亿规模模型进行参数高效微调
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../personal-copilot/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    个人编程助手：训练你自己的编码助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../phi2-intel-meteor-lake/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    笔记本电脑上的聊天机器人：在英特尔 Meteor Lake 上运行 Phi-2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../presidio-pii-detection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hub 上使用 Presidio 进行自动 PII 检测实验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../putting_rl_back_in_rlhf_with_rloo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    将强化学习重新引入 RLHF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pycharm-integration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 PyCharm 深度集成：轻松引入丰富的 AI 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-ddp-accelerate-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    从 PyTorch DDP 到 Accelerate 到 Trainer，轻松掌握分布式训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch 完全分片数据并行技术加速大模型训练
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-diffusers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 Quanto 和 Diffusers 的内存高效 transformer 扩散模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../quanto-introduction/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quanto：PyTorch 量化工具包
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ram-efficient-pytorch-fsdp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 PyTorch FSDP 微调 Llama 2 70B
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../red-teaming/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为大语言模型建立红队对抗
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reformer 模型 - 突破语言建模的极限
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../regions/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HF Hub 现已加入存储区域功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../researcher-dataset-sharing/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 Hugging Face Hub 分享你的开源数据集
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rlhf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ChatGPT 背后的“功臣”——RLHF 技术详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../rwkv/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RWKV -- transformer 与 RNN 的强强联合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ryght-case-study/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ryght 在 Hugging Face 专家助力下赋能医疗保健和生命科学之旅
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../safecoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    推介 SafeCoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sc2-instruct/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2-Instruct: 完全透明和可自我对齐的代码生成
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3-5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3.5 Large 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    欢迎 Stable Diffusion 3 加入 🧨 Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sd_distillation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    开源 SD-Small 和 SD-Tiny 知识蒸馏代码与权重
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sdxl_lora_advanced_script/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    全世界 LoRA 训练脚本，联合起来!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-absa/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFitABSA：基于 SetFit 的少样本、方面级情感分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit-optimum-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔至强 CPU 上使用 🤗 Optimum Intel 实现超快 SetFit 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../setfit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SetFit: 高效的无提示少样本学习
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../smollm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SmolLM：一个超快速、超高性能的小模型集合
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../speecht5/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 SpeechT5 进行语音合成、识别和更多功能
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../sql-console/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    为数据集而生的 SQL 控制台
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-finetuning-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable-diffusion-inference-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在英特尔 CPU 上加速 Stable Diffusion 推理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用Diffusers来实现Stable Diffusion 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stackllama/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    “StackLLaMA”: 用 RLHF 训练 LLaMA 的手把手教程
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starchat-alpha/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 StarCoder 创建一个编程助手
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder：最先进的代码大模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../starcoder2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    StarCoder2 及 The Stack v2 数据集正式发布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthetic-data-save-costs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    合成数据：利用开源技术节约资金、时间和减少碳排放
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../synthid-text/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SynthID Text：在 AI 生成文本中应用不可见水印的新技术
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../t2i-sdxl-adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 SDXL 上用 T2I-Adapter 实现高效可控的文生图
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../text-to-video/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入理解文生视频模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../textgen-pipe-gaudi/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于英特尔® Gaudi® 2 AI 加速器的文本生成流水线
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../tgi-benchmarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TGI 基准测试
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../the-age-of-ml-as-code/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    机器学习即代码的时代已经到来
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    使用 PPO 算法进行 RLHF 的 N 步实现细节
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../time-series-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 🤗 Transformers 进行概率时间序列预测
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-dgx-cloud/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在 NVIDIA DGX Cloud上使用 H100 GPU 轻松训练模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-optimize-sd-intel/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    基于 NNCF 和 🤗 Optimum 面向 Intel CPU 对 Stable Diffusion 优化
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-sentence-transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    用 Sentence Transformers v3 训练和微调嵌入模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../train-your-controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 diffusers 训练你自己的 ControlNet 🧨
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../transformers-design-philosophy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    〜不要〜重复自己
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-ddpo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用 DDPO 在 TRL 中微调 Stable Diffusion 模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trl-peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    在一张 24 GB 的消费级显卡上用 RLHF 微调 20B LLMs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../trufflesecurity-partnership/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hugging Face 与 TruffleHog 成为合作伙伴，实现风险信息预警
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unified-tool-use/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    对 LLM 工具使用进行统一
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-api/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何安装和使用 Hugging Face Unity API
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-asr/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 Unity 游戏中集成 AI 语音识别？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unity-in-spaces/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    如何在 🤗 Space 上托管 Unity 游戏
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../universal_assisted_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    通用辅助生成：使用任意辅助模型加速解码
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vertex-colored-to-textured-mesh/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    顶点着色网格转换为 UV 映射的纹理化网格
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vision_language_pretraining/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    深入了解视觉语言模型
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vit-align/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kakao Brain 的开源 ViT、ALIGN 和 COYO 文字
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../vlms/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    视觉语言模型详解
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../watermarking/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    人工智能水印技术入门：工具与技巧
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../whisper-speculative-decoding/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    使用推测解码使 Whisper 实现 2 倍的推理加速
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../winning-aimo-progress-prize/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    NuminaMath 是如何荣膺首届 AIMO 进步奖的？
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../xethub-joins-hf/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    XetHub 加入 Hugging Face!
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../zero-shot-vqa-docmatix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LAVE：使用 LLM 对 Docmatix 进行零样本 VQA 评估 - 我们还需要微调吗？
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../ops/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    运维
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
    <a href="../../blog/" class="md-nav__link">
      
  
  <span class="md-ellipsis">
    博客
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../resume/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简历模板
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/C-L-STARK/C-L-STARK.github.io/edit/master/docs/ml/the_n_implementation_details_of_rlhf_with_ppo.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2zm-2.3 6.35c.22-.21.22-.56 0-.77L15.42 7.3a.53.53 0 0 0-.77 0l-1 1 2.05 2.05zM7 14.94V17h2.06l6.06-6.06-2.06-2.06z"/></svg>
    </a>
  
  


<h1 id="ppo-rlhf-n">使用 PPO 算法进行 RLHF 的 N 步实现细节<a class="headerlink" href="#ppo-rlhf-n" title="Permanent link">&para;</a></h1>
<p>当下，RLHF/ChatGPT 已经变成了一个非常流行的话题。我们正在致力于更多有关 RLHF 的研究，这篇博客尝试复现 OpenAI 在 2019 年开源的原始 RLHF 代码库，其仓库位置位于 <a href="https://github.com/openai/lm-human-preferences"><em>openai/lm-human-preferences</em></a>。尽管它具有 “tensorflow-1.x” 的特性，但 OpenAI 的原始代码库评估和基准测试非常完善，使其成为研究 RLHF 实现工程细节的好地方。</p>
<p>我们的目标是:</p>
<ol>
<li>复现 OAI 在风格化任务中的结果，并匹配 <a href="https://github.com/openai/lm-human-preferences"><em>openai/lm-human-preferences</em></a> 的学习曲线。</li>
<li>提供一个实现细节的清单，类似于 <a href="https://iclr-blog-track.github.io/2022/03/25/ppo-implementation-details/">近端优化策略的 37 个实施细节 (<em>The 37 Implementation Details of Proximal Policy Optimization</em>)</a> 和 <a href="https://andyljones.com/posts/rl-debugging.html">没有痛苦折磨的调试 RL (<em>Debugging RL, Without the Agonizing Pain</em>)</a> 的风格;</li>
<li>提供一个易于阅读且简洁的 RLHF 参考实现;</li>
</ol>
<p>这项工作仅适用于以教育/学习为目的的。对于需要更多功能的高级用户，例如使用 PEFT 运行更大的模型， <a href="https://github.com/huggingface/trl"><em>huggingface/trl</em></a> 将是一个不错的选择。</p>
<ul>
<li>在 <a href="#匹配学习曲线">匹配学习曲线</a> 中，我们展示了我们的主要贡献: 创建一个代码库，能够在风格化任务中复现 OAI 的结果，并且与 <a href="https://github.com/openai/lm-human-preferences"><em>openai/lm-human-preferences</em></a> 的学习曲线非常接近地匹配。</li>
<li>
<p>然后我们深入探讨了与复现 OAI 的工作相关的实现细节。在 <a href="#总体实现细节">总体实现细节</a> 中，我们讨论了基本细节，像如何生成奖励/值和如何生成响应。在 <a href="#奖励模型实现细节">奖励模型实现细节</a> 中，我们讨论了诸如奖励标准化之类的细节。在 <a href="#策略训练实现细节">策略训练实现细节</a> 中，我们讨论了拒绝采样和奖励“白化”等细节。</p>
<ul>
<li>在 <a href="https://www.notion.so/PyTorch-Adam-optimizer-numerical-issues-w-r-t-RLHF-c48b1335349941c6992a04a2c8069f2b?pvs=21"><strong>PyTorch Adam 优化器在处理 RLHF 时的数值问题</strong></a> 中，我们强调了 TensorFlow 和 PyTorch 之间 Adam 的一个非常有趣的实现区别，其导致了模型训练中的激进更新。</li>
</ul>
</li>
<li>
<p>接下来，我们检查了在奖励标签由 <code>gpt2-large</code> 生成的情况下，训练不同基础模型 (例如 gpt2-xl, falcon-1b) 的效果。</p>
</li>
<li>最后，我们通过讨论一些限制来总结我们的研究工作。</li>
</ul>
<p><strong>以下是一些重要链接:</strong></p>
<ul>
<li>💾 我们的复现代码库 <a href="https://github.com/vwxyzjn/lm-human-preference-details"><em>https://github.com/vwxyzjn/lm-human-preference-details</em></a></li>
<li>🤗 RLHF 模型比较示例: <a href="https://huggingface.co/spaces/lm-human-preference-details/rlhf-demo"><em>https://huggingface.co/spaces/lm-human-preference-details/rlhf-demo</em></a></li>
<li>🐝 所有的 w&amp;b 训练日志 <a href="https://wandb.ai/openrlbenchmark/lm_human_preference_details"><em>https://wandb.ai/openrlbenchmark/lm_human_preference_details</em></a></li>
</ul>
<h1 id="_1">匹配学习曲线<a class="headerlink" href="#_1" title="Permanent link">&para;</a></h1>
<p>我们的主要贡献是在风格化任务中复现 OAI 的结果，例如情感和描述性。如下图所示，我们的代码库 (橙色曲线) 能够产生与 OAI 的代码库 (蓝色曲线) 几乎相同的学习曲线。</p>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/Untitled.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/Untitled.png" /></a></p>
<h2 id="openailm-human-preferences">关于运行 openai/lm-human-preferences 的说明<a class="headerlink" href="#openailm-human-preferences" title="Permanent link">&para;</a></h2>
<p>为了直观比较，我们运行了原始的 RLHF 代码，其仓库位置位于 <a href="https://github.com/openai/lm-human-preferences"><em>openai/lm-human-preferences</em></a>，它将提供宝贵的指标，以帮助验证和诊断我们的复现。我们能够设置原始的 TensorFlow 1.x 代码，但它需要一个非常特定的设置:</p>
<ul>
<li>OAI 的数据集部分损坏/丢失 (所以我们用类似的 HF 数据集替换了它们，这可能会或可能不会导致性能差异)</li>
<li>
<p>具体来说，它的书籍数据集在 OpenAI 的 GCP - Azure 迁移过程中丢失了 (<a href="https://github.com/openai/lm-human-preferences/issues/17#issuecomment-1044051496">https://github.com/openai/lm-human-preferences/issues/17#issuecomment-1044051496</a>)。我用 Hugging Face 的 <code>bookcorpus</code> 数据集替换了书籍数据集，原则上，这是类似 OAI 使用的数据集。</p>
</li>
<li>
<p>它不能在 1 个 V100 上运行，因为它没有实现梯度累积。相反，它使用一个大的 BS (批量大小)，并在 8 个 GPU 上分割 batch (批量)，仅在 1 个 GPU 上就会出现 OOM (内存溢出)。</p>
</li>
<li>它不能在 8 个 A100 上运行，因为它使用的是 TensorFlow 1.x，与 Cuda 8+ 不兼容。</li>
<li>它不能在 8 个 V100 (16GB) 上运行，因为它会 OOM (内存溢出)。</li>
<li>它只能在 8 个 V100 (32GB) 上运行，这种配置仅由 AWS 以 <code>p3dn.24xlarge</code> 实例的形式提供。</li>
</ul>
<h1 id="_2">总体实现细节<a class="headerlink" href="#_2" title="Permanent link">&para;</a></h1>
<p>我们现在深入探讨与复现 OAI 工作相关的技术实现细节。在这个部分，我们讨论了一些基本细节，例如奖励/值是如何生成的，以及响应是如何生成的。以下是这些细节，不按特定顺序列出:</p>
<ol>
<li>
<p><strong>奖励模型和策略的价值头将 <code>query</code> 和 <code>response</code> 的连接作为输入</strong></p>
<ol>
<li>奖励模型和策略的价值头 <em>不</em> 仅仅查看响应。相反，它将 <code>query</code> 和 <code>response</code> 连接在一起，作为 <code>query_response</code> (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/rewards.py#L105-L107">lm_human_preferences/rewards.py#L105-L107</a>)。</li>
<li>举例来说，如果 <code>query = "他在想某事，但他的眼神很难读懂"。</code> ，和 <code>response = "他看着他的左手，手臂伸在他的前面。"</code> ，那么奖励模型和策略的价值会对<code>query_response = "他在想某事，但他的眼神很难读懂。他看着他的左手，手臂伸在他的前面。"</code> 进行前向传递，并产生形状为 <code>(B, T, 1)</code> 的奖励和价值，其中 <code>B</code> 是 BS (批量大小)，<code>T</code> 是序列长度，而 <code>1</code> 代表奖励头的输出结构的维度为 1 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/rewards.py#L105-L107">lm_human_preferences/rewards.py#L105-L107</a>, <a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/policy.py#L111">lm_human_preferences/policy.py#L111</a>)。</li>
<li><code>T</code> 意味着每个 token 都有与其和前文关联的奖励。例如，<code>eyes</code> token 将有一个与<code>他在想某事，但他的眼神很难读懂</code> 相对应的奖励。</li>
</ol>
</li>
<li>
<p><strong>使用特殊的填充 token 来填充和截断输入。</strong></p>
<ol>
<li>
<p>OAI 为查询 <code>query_length</code> 设置了固定的输入长度; 它使用 <code>pad_token</code> <strong>填充</strong> 过短的序列 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/datasets.py#L66-L67">lm_human_preferences/language/datasets.py#L66-L67</a>)，并 <strong>截断</strong> 过长的序列 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/datasets.py#L57">lm_human_preferences/language/datasets.py#L57</a>)。详见 <a href="https://huggingface.co/docs/transformers/pad_truncation">此处</a> 以获取该概念的通用介绍。在填充输入时，OAI 使用了词汇表之外的 token (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/encodings.py#L56">lm_human_preferences/language/encodings.py#L56</a>)。</p>
<ol>
<li><strong>关于 HF 的 transformers — 填充 token 的注解。</strong> 根据 (<a href="https://github.com/huggingface/transformers/issues/2630#issuecomment-578159876">transformers#2630#issuecomment-578159876</a>)，在 GPT 和 GPT-2 的预训练期间没有使用填充 token; 因此，transformer 的 gpt2 模型与其分词器没有关联的官方填充 token。通常的做法是设置 <code>tokenizer.pad_token = tokenizer.eos_token</code> ，但在这项工作中，我们将区分这两个特殊 token 以匹配 OAI 的原始设置，所以我们将使用 <code>tokenizer.add_special_tokens({"pad_token": "[PAD]"})</code> 。</li>
</ol>
<p>注意，没有填充 token 是解码器模型的默认设置，因为它们在预训练期间使用“打包”训练，这意味着许多序列被连接并由 EOS token 分隔，这些序列的块在预训练期间始终具有最大长度并被馈送到模型中。</p>
</li>
<li>
<p>当把所有事物放在一起时，这里有一个例子</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-0-1"><a id="__codelineno-0-1" name="__codelineno-0-1" href="#__codelineno-0-1"></a><span class="kn">import</span> <span class="nn">transformers</span>
</span><span id="__span-0-2"><a id="__codelineno-0-2" name="__codelineno-0-2" href="#__codelineno-0-2"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
</span><span id="__span-0-3"><a id="__codelineno-0-3" name="__codelineno-0-3" href="#__codelineno-0-3"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s2">&quot;pad_token&quot;</span><span class="p">:</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">})</span>
</span><span id="__span-0-4"><a id="__codelineno-0-4" name="__codelineno-0-4" href="#__codelineno-0-4"></a><span class="n">query_length</span> <span class="o">=</span> <span class="mi">5</span>
</span><span id="__span-0-5"><a id="__codelineno-0-5" name="__codelineno-0-5" href="#__codelineno-0-5"></a><span class="n">texts</span> <span class="o">=</span> <span class="p">[</span>
</span><span id="__span-0-6"><a id="__codelineno-0-6" name="__codelineno-0-6" href="#__codelineno-0-6"></a>    <span class="s2">&quot;usually, he would&quot;</span><span class="p">,</span>
</span><span id="__span-0-7"><a id="__codelineno-0-7" name="__codelineno-0-7" href="#__codelineno-0-7"></a>    <span class="s2">&quot;she thought about it&quot;</span><span class="p">,</span>
</span><span id="__span-0-8"><a id="__codelineno-0-8" name="__codelineno-0-8" href="#__codelineno-0-8"></a><span class="p">]</span>
</span><span id="__span-0-9"><a id="__codelineno-0-9" name="__codelineno-0-9" href="#__codelineno-0-9"></a><span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-10"><a id="__codelineno-0-10" name="__codelineno-0-10" href="#__codelineno-0-10"></a><span class="k">for</span> <span class="n">text</span> <span class="ow">in</span> <span class="n">texts</span><span class="p">:</span>
</span><span id="__span-0-11"><a id="__codelineno-0-11" name="__codelineno-0-11" href="#__codelineno-0-11"></a>    <span class="n">tokens</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">text</span><span class="p">)[:</span><span class="n">query_length</span><span class="p">])</span>
</span><span id="__span-0-12"><a id="__codelineno-0-12" name="__codelineno-0-12" href="#__codelineno-0-12"></a>
</span><span id="__span-0-13"><a id="__codelineno-0-13" name="__codelineno-0-13" href="#__codelineno-0-13"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;tokens&quot;</span><span class="p">,</span> <span class="n">tokens</span><span class="p">)</span>
</span><span id="__span-0-14"><a id="__codelineno-0-14" name="__codelineno-0-14" href="#__codelineno-0-14"></a><span class="n">inputs</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span>
</span><span id="__span-0-15"><a id="__codelineno-0-15" name="__codelineno-0-15" href="#__codelineno-0-15"></a>    <span class="p">{</span><span class="s2">&quot;input_ids&quot;</span><span class="p">:</span> <span class="n">tokens</span><span class="p">},</span>
</span><span id="__span-0-16"><a id="__codelineno-0-16" name="__codelineno-0-16" href="#__codelineno-0-16"></a>    <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
</span><span id="__span-0-17"><a id="__codelineno-0-17" name="__codelineno-0-17" href="#__codelineno-0-17"></a>    <span class="n">max_length</span><span class="o">=</span><span class="n">query_length</span><span class="p">,</span>
</span><span id="__span-0-18"><a id="__codelineno-0-18" name="__codelineno-0-18" href="#__codelineno-0-18"></a>    <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;pt&quot;</span><span class="p">,</span>
</span><span id="__span-0-19"><a id="__codelineno-0-19" name="__codelineno-0-19" href="#__codelineno-0-19"></a>    <span class="n">return_attention_mask</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-20"><a id="__codelineno-0-20" name="__codelineno-0-20" href="#__codelineno-0-20"></a><span class="p">)</span>
</span><span id="__span-0-21"><a id="__codelineno-0-21" name="__codelineno-0-21" href="#__codelineno-0-21"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;inputs&quot;</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span>
</span><span id="__span-0-22"><a id="__codelineno-0-22" name="__codelineno-0-22" href="#__codelineno-0-22"></a>
</span><span id="__span-0-23"><a id="__codelineno-0-23" name="__codelineno-0-23" href="#__codelineno-0-23"></a><span class="sd">&quot;&quot;&quot;prints are</span>
</span><span id="__span-0-24"><a id="__codelineno-0-24" name="__codelineno-0-24" href="#__codelineno-0-24"></a><span class="sd">tokens [[23073, 11, 339, 561], [7091, 1807, 546, 340]]</span>
</span><span id="__span-0-25"><a id="__codelineno-0-25" name="__codelineno-0-25" href="#__codelineno-0-25"></a><span class="sd">inputs {&#39;input_ids&#39;: tensor([[23073, 11, 339, 561, 50257],</span>
</span><span id="__span-0-26"><a id="__codelineno-0-26" name="__codelineno-0-26" href="#__codelineno-0-26"></a><span class="sd">        [ 7091, 1807, 546, 340, 50257]]), &#39;attention_mask&#39;: tensor([[1, 1, 1, 1, 0],</span>
</span><span id="__span-0-27"><a id="__codelineno-0-27" name="__codelineno-0-27" href="#__codelineno-0-27"></a><span class="sd">        [1, 1, 1, 1, 0]])}</span>
</span><span id="__span-0-28"><a id="__codelineno-0-28" name="__codelineno-0-28" href="#__codelineno-0-28"></a><span class="sd">&quot;&quot;&quot;</span>
</span></code></pre></div>
</li>
</ol>
</li>
<li>
<p><strong>相应地调整填充 token 的位置索引</strong></p>
<ol>
<li>在计算 logits 时，OAI 的代码通过适当地屏蔽填充 token 来工作。这是通过找出与填充 token 相对应的 token 索引来实现的 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L296-L297">lm_human_preferences/language/model.py#L296-L297</a>)，然后相应地调整它们的位置索引 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L320">lm_human_preferences/language/model.py#L320</a>)。</li>
<li>
<p>例如，如果 <code>query=[23073, 50259, 50259]</code> 和 <code>response=[11, 339, 561]</code> ，其中 ( <code>50259</code> 是 OAI 的填充 token)，它会创建位置索引为 <code>[[0 1 1 1 2 3]]</code> 并且如下的 logits。注意填充 token 对应的 logits 如何保持不变！这是我们在复制过程中应该追求的效果。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-1-1"><a id="__codelineno-1-1" name="__codelineno-1-1" href="#__codelineno-1-1"></a><span class="n">all_logits</span> <span class="p">[[[</span> <span class="o">-</span><span class="mf">35.28693</span> <span class="o">-</span><span class="mf">34.2875</span> <span class="o">-</span><span class="mf">38.16074</span> <span class="o">...</span> <span class="o">-</span><span class="mf">41.595802</span> <span class="o">-</span><span class="mf">41.082108</span>
</span><span id="__span-1-2"><a id="__codelineno-1-2" name="__codelineno-1-2" href="#__codelineno-1-2"></a>    <span class="o">-</span><span class="mf">35.36577</span> <span class="p">]</span>
</span><span id="__span-1-3"><a id="__codelineno-1-3" name="__codelineno-1-3" href="#__codelineno-1-3"></a><span class="p">[</span> <span class="o">-</span><span class="mf">35.28693</span> <span class="o">-</span><span class="mf">34.2875</span> <span class="o">-</span><span class="mf">38.16074</span> <span class="o">...</span> <span class="o">-</span><span class="mf">41.595802</span> <span class="o">-</span><span class="mf">41.082108</span>
</span><span id="__span-1-4"><a id="__codelineno-1-4" name="__codelineno-1-4" href="#__codelineno-1-4"></a>    <span class="o">-</span><span class="mf">35.36577</span> <span class="p">]</span>
</span><span id="__span-1-5"><a id="__codelineno-1-5" name="__codelineno-1-5" href="#__codelineno-1-5"></a><span class="p">[</span> <span class="o">-</span><span class="mf">35.28693</span> <span class="o">-</span><span class="mf">34.2875</span> <span class="o">-</span><span class="mf">38.16074</span> <span class="o">...</span> <span class="o">-</span><span class="mf">41.595802</span> <span class="o">-</span><span class="mf">41.082108</span>
</span><span id="__span-1-6"><a id="__codelineno-1-6" name="__codelineno-1-6" href="#__codelineno-1-6"></a>    <span class="o">-</span><span class="mf">35.36577</span> <span class="p">]</span>
</span><span id="__span-1-7"><a id="__codelineno-1-7" name="__codelineno-1-7" href="#__codelineno-1-7"></a><span class="p">[</span><span class="o">-</span><span class="mf">111.303955</span> <span class="o">-</span><span class="mf">110.94471</span> <span class="o">-</span><span class="mf">112.90624</span> <span class="o">...</span> <span class="o">-</span><span class="mf">113.13064</span> <span class="o">-</span><span class="mf">113.7788</span>
</span><span id="__span-1-8"><a id="__codelineno-1-8" name="__codelineno-1-8" href="#__codelineno-1-8"></a><span class="o">-</span><span class="mf">109.17345</span> <span class="p">]</span>
</span><span id="__span-1-9"><a id="__codelineno-1-9" name="__codelineno-1-9" href="#__codelineno-1-9"></a><span class="p">[</span><span class="o">-</span><span class="mf">111.51512</span> <span class="o">-</span><span class="mf">109.61077</span> <span class="o">-</span><span class="mf">114.90231</span> <span class="o">...</span> <span class="o">-</span><span class="mf">118.43514</span> <span class="o">-</span><span class="mf">111.56671</span>
</span><span id="__span-1-10"><a id="__codelineno-1-10" name="__codelineno-1-10" href="#__codelineno-1-10"></a><span class="o">-</span><span class="mf">112.12478</span> <span class="p">]</span>
</span><span id="__span-1-11"><a id="__codelineno-1-11" name="__codelineno-1-11" href="#__codelineno-1-11"></a><span class="p">[</span><span class="o">-</span><span class="mf">122.69775</span> <span class="o">-</span><span class="mf">121.84468</span> <span class="o">-</span><span class="mf">128.27417</span> <span class="o">...</span> <span class="o">-</span><span class="mf">132.28055</span> <span class="o">-</span><span class="mf">130.39604</span>
</span><span id="__span-1-12"><a id="__codelineno-1-12" name="__codelineno-1-12" href="#__codelineno-1-12"></a><span class="o">-</span><span class="mf">125.707756</span><span class="p">]]]</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">50257</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p><strong>关于 HF 的 transformers — <code>position_ids</code> 和 <code>padding_side</code> 的注解。</strong> 我们可以通过 1) 左填充和 2) 传入适当的 <code>position_ids</code> ，使用 Hugging Face 的 transformer 复制精确的 logits:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-2-1"><a id="__codelineno-2-1" name="__codelineno-2-1" href="#__codelineno-2-1"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-2-2"><a id="__codelineno-2-2" name="__codelineno-2-2" href="#__codelineno-2-2"></a><span class="kn">import</span> <span class="nn">transformers</span>
</span><span id="__span-2-3"><a id="__codelineno-2-3" name="__codelineno-2-3" href="#__codelineno-2-3"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
</span><span id="__span-2-4"><a id="__codelineno-2-4" name="__codelineno-2-4" href="#__codelineno-2-4"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s2">&quot;pad_token&quot;</span><span class="p">:</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">})</span>
</span><span id="__span-2-5"><a id="__codelineno-2-5" name="__codelineno-2-5" href="#__codelineno-2-5"></a><span class="n">pad_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
</span><span id="__span-2-6"><a id="__codelineno-2-6" name="__codelineno-2-6" href="#__codelineno-2-6"></a><span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
</span><span id="__span-2-7"><a id="__codelineno-2-7" name="__codelineno-2-7" href="#__codelineno-2-7"></a>    <span class="p">[</span><span class="n">pad_id</span><span class="p">,</span> <span class="n">pad_id</span><span class="p">,</span> <span class="mi">23073</span><span class="p">],</span>
</span><span id="__span-2-8"><a id="__codelineno-2-8" name="__codelineno-2-8" href="#__codelineno-2-8"></a><span class="p">])</span>
</span><span id="__span-2-9"><a id="__codelineno-2-9" name="__codelineno-2-9" href="#__codelineno-2-9"></a><span class="n">response</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
</span><span id="__span-2-10"><a id="__codelineno-2-10" name="__codelineno-2-10" href="#__codelineno-2-10"></a>    <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">339</span><span class="p">,</span> <span class="mi">561</span><span class="p">],</span>
</span><span id="__span-2-11"><a id="__codelineno-2-11" name="__codelineno-2-11" href="#__codelineno-2-11"></a><span class="p">])</span>
</span><span id="__span-2-12"><a id="__codelineno-2-12" name="__codelineno-2-12" href="#__codelineno-2-12"></a><span class="n">temperature</span> <span class="o">=</span> <span class="mf">1.0</span>
</span><span id="__span-2-13"><a id="__codelineno-2-13" name="__codelineno-2-13" href="#__codelineno-2-13"></a>
</span><span id="__span-2-14"><a id="__codelineno-2-14" name="__codelineno-2-14" href="#__codelineno-2-14"></a><span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</span><span id="__span-2-15"><a id="__codelineno-2-15" name="__codelineno-2-15" href="#__codelineno-2-15"></a><span class="n">response</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">response</span><span class="p">)</span><span class="o">.</span><span class="n">long</span><span class="p">()</span>
</span><span id="__span-2-16"><a id="__codelineno-2-16" name="__codelineno-2-16" href="#__codelineno-2-16"></a><span class="n">context_length</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-2-17"><a id="__codelineno-2-17" name="__codelineno-2-17" href="#__codelineno-2-17"></a><span class="n">query_response</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">query</span><span class="p">,</span> <span class="n">response</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
</span><span id="__span-2-18"><a id="__codelineno-2-18" name="__codelineno-2-18" href="#__codelineno-2-18"></a><span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</span><span id="__span-2-19"><a id="__codelineno-2-19" name="__codelineno-2-19" href="#__codelineno-2-19"></a><span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">query_responses</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">):</span>
</span><span id="__span-2-20"><a id="__codelineno-2-20" name="__codelineno-2-20" href="#__codelineno-2-20"></a>    <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">query_responses</span> <span class="o">!=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
</span><span id="__span-2-21"><a id="__codelineno-2-21" name="__codelineno-2-21" href="#__codelineno-2-21"></a>    <span class="n">position_ids</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">long</span><span class="p">()</span> <span class="c1"># exclusive cumsum</span>
</span><span id="__span-2-22"><a id="__codelineno-2-22" name="__codelineno-2-22" href="#__codelineno-2-22"></a>    <span class="n">input_ids</span> <span class="o">=</span> <span class="n">query_responses</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="__span-2-23"><a id="__codelineno-2-23" name="__codelineno-2-23" href="#__codelineno-2-23"></a>    <span class="n">input_ids</span><span class="p">[</span><span class="o">~</span><span class="n">attention_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-2-24"><a id="__codelineno-2-24" name="__codelineno-2-24" href="#__codelineno-2-24"></a>    <span class="k">return</span> <span class="n">policy</span><span class="p">(</span>
</span><span id="__span-2-25"><a id="__codelineno-2-25" name="__codelineno-2-25" href="#__codelineno-2-25"></a>        <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
</span><span id="__span-2-26"><a id="__codelineno-2-26" name="__codelineno-2-26" href="#__codelineno-2-26"></a>        <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
</span><span id="__span-2-27"><a id="__codelineno-2-27" name="__codelineno-2-27" href="#__codelineno-2-27"></a>        <span class="n">position_ids</span><span class="o">=</span><span class="n">position_ids</span><span class="p">,</span>
</span><span id="__span-2-28"><a id="__codelineno-2-28" name="__codelineno-2-28" href="#__codelineno-2-28"></a>        <span class="n">return_dict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-2-29"><a id="__codelineno-2-29" name="__codelineno-2-29" href="#__codelineno-2-29"></a>        <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-2-30"><a id="__codelineno-2-30" name="__codelineno-2-30" href="#__codelineno-2-30"></a>    <span class="p">)</span>
</span><span id="__span-2-31"><a id="__codelineno-2-31" name="__codelineno-2-31" href="#__codelineno-2-31"></a><span class="n">output</span> <span class="o">=</span> <span class="n">forward</span><span class="p">(</span><span class="n">pretrained_model</span><span class="p">,</span> <span class="n">query_response</span><span class="p">,</span> <span class="n">tokenizer</span><span class="p">)</span>
</span><span id="__span-2-32"><a id="__codelineno-2-32" name="__codelineno-2-32" href="#__codelineno-2-32"></a><span class="n">logits</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">logits</span>
</span><span id="__span-2-33"><a id="__codelineno-2-33" name="__codelineno-2-33" href="#__codelineno-2-33"></a><span class="n">logits</span> <span class="o">/=</span> <span class="n">temperature</span>
</span><span id="__span-2-34"><a id="__codelineno-2-34" name="__codelineno-2-34" href="#__codelineno-2-34"></a><span class="nb">print</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
</span><span id="__span-2-35"><a id="__codelineno-2-35" name="__codelineno-2-35" href="#__codelineno-2-35"></a>
</span><span id="__span-2-36"><a id="__codelineno-2-36" name="__codelineno-2-36" href="#__codelineno-2-36"></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-2-37"><a id="__codelineno-2-37" name="__codelineno-2-37" href="#__codelineno-2-37"></a><span class="sd">tensor([[[ -26.9395, -26.4709, -30.0456, ..., -33.2208, -33.2884,</span>
</span><span id="__span-2-38"><a id="__codelineno-2-38" name="__codelineno-2-38" href="#__codelineno-2-38"></a><span class="sd">        -27.4360],</span>
</span><span id="__span-2-39"><a id="__codelineno-2-39" name="__codelineno-2-39" href="#__codelineno-2-39"></a><span class="sd">        [ -27.1677, -26.7330, -30.2386, ..., -33.6813, -33.6931,</span>
</span><span id="__span-2-40"><a id="__codelineno-2-40" name="__codelineno-2-40" href="#__codelineno-2-40"></a><span class="sd">        -27.5928],</span>
</span><span id="__span-2-41"><a id="__codelineno-2-41" name="__codelineno-2-41" href="#__codelineno-2-41"></a><span class="sd">        [ -35.2869, -34.2875, -38.1608, ..., -41.5958, -41.0821,</span>
</span><span id="__span-2-42"><a id="__codelineno-2-42" name="__codelineno-2-42" href="#__codelineno-2-42"></a><span class="sd">        -35.3658],</span>
</span><span id="__span-2-43"><a id="__codelineno-2-43" name="__codelineno-2-43" href="#__codelineno-2-43"></a><span class="sd">        [-111.3040, -110.9447, -112.9062, ..., -113.1306, -113.7788,</span>
</span><span id="__span-2-44"><a id="__codelineno-2-44" name="__codelineno-2-44" href="#__codelineno-2-44"></a><span class="sd">        -109.1734],</span>
</span><span id="__span-2-45"><a id="__codelineno-2-45" name="__codelineno-2-45" href="#__codelineno-2-45"></a><span class="sd">        [-111.5152, -109.6108, -114.9024, ..., -118.4352, -111.5668,</span>
</span><span id="__span-2-46"><a id="__codelineno-2-46" name="__codelineno-2-46" href="#__codelineno-2-46"></a><span class="sd">        -112.1248],</span>
</span><span id="__span-2-47"><a id="__codelineno-2-47" name="__codelineno-2-47" href="#__codelineno-2-47"></a><span class="sd">        [-122.6978, -121.8447, -128.2742, ..., -132.2805, -130.3961,</span>
</span><span id="__span-2-48"><a id="__codelineno-2-48" name="__codelineno-2-48" href="#__codelineno-2-48"></a><span class="sd">        -125.7078]]], grad_fn=&lt;DivBackward0&gt;)</span>
</span><span id="__span-2-49"><a id="__codelineno-2-49" name="__codelineno-2-49" href="#__codelineno-2-49"></a><span class="sd">&quot;&quot;&quot;</span>
</span></code></pre></div>
</li>
<li>
<p><strong>关于 HF 的 transformers ——在 <code>生成</code> 过程中的 <code>position_ids</code> 的注解:</strong> 在生成过程中，我们不应传入 <code>position_ids</code> ，因为在 <code>transformers</code> 中， <code>position_ids</code> 已经以某种方式被调整了。当我在生成过程中也传入 <code>position_ids</code> 时，性能会灾难性地恶化。</p>
</li>
</ol>
<p>通常情况下，我们几乎从不在 transformers 中传递 <code>position_ids</code> 。所有的遮蔽 (masking) 和移位 (shifting) logic 已经实现，例如，在 <code>generate</code> 函数中 (需要永久的代码链接)。
4. <strong>生成固定长度响应的响应生成不需要填充。</strong></p>
<ol>
<li>在响应生成期间，OAI 使用 <code>top_k=0, top_p=1.0</code> 并仅在词汇表上做分类样本 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/sample.py#L43">lm_human_preferences/language/sample.py#L43</a>)，代码会一直采样，直到生成固定长度的响应 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/policy.py#L103">lm_human_preferences/policy.py#L103</a>)。值得注意的是，即使遇到 EOS (序列结束) token ，它也会继续采样。</li>
<li>
<p><strong>关于 HF 的 transformers 的注解 — 在 <code>eos_token</code> 处采样可能会停止:</strong> 在 <code>transformers</code> 中，生成可能会在 <code>eos_token</code> 处停止 (<a href="https://github.com/huggingface/transformers/blob/67b85f24def79962ce075353c2627f78e0e53e9f/src/transformers/generation/utils.py#L2248-L2256">src/transformers/generation/utils.py#L2248-L2256</a>)，这与 OAI 的设置不同。为了对齐设置，我们需要设置 <code>pretrained_model.generation_config.eos_token_id = None, pretrained_model.generation_config.pad_token_id = None</code> 。请注意， <code>transformers.GenerationConfig(eos_token_id=None, pad_token_id=None, ...)</code> 不起作用，因为 <code>pretrained_model.generation_config</code> 会覆盖并设置一个 <code>eos_token</code> 。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-3-1"><a id="__codelineno-3-1" name="__codelineno-3-1" href="#__codelineno-3-1"></a><span class="kn">import</span> <span class="nn">torch</span>
</span><span id="__span-3-2"><a id="__codelineno-3-2" name="__codelineno-3-2" href="#__codelineno-3-2"></a><span class="kn">import</span> <span class="nn">transformers</span>
</span><span id="__span-3-3"><a id="__codelineno-3-3" name="__codelineno-3-3" href="#__codelineno-3-3"></a><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">,</span> <span class="n">padding_side</span><span class="o">=</span><span class="s2">&quot;right&quot;</span><span class="p">)</span>
</span><span id="__span-3-4"><a id="__codelineno-3-4" name="__codelineno-3-4" href="#__codelineno-3-4"></a><span class="n">tokenizer</span><span class="o">.</span><span class="n">add_special_tokens</span><span class="p">({</span><span class="s2">&quot;pad_token&quot;</span><span class="p">:</span> <span class="s2">&quot;[PAD]&quot;</span><span class="p">})</span>
</span><span id="__span-3-5"><a id="__codelineno-3-5" name="__codelineno-3-5" href="#__codelineno-3-5"></a><span class="n">pad_id</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
</span><span id="__span-3-6"><a id="__codelineno-3-6" name="__codelineno-3-6" href="#__codelineno-3-6"></a><span class="n">query</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
</span><span id="__span-3-7"><a id="__codelineno-3-7" name="__codelineno-3-7" href="#__codelineno-3-7"></a>    <span class="p">[</span><span class="n">pad_id</span><span class="p">,</span> <span class="n">pad_id</span><span class="p">,</span> <span class="mi">23073</span><span class="p">],</span>
</span><span id="__span-3-8"><a id="__codelineno-3-8" name="__codelineno-3-8" href="#__codelineno-3-8"></a><span class="p">])</span>
</span><span id="__span-3-9"><a id="__codelineno-3-9" name="__codelineno-3-9" href="#__codelineno-3-9"></a><span class="n">response</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span>
</span><span id="__span-3-10"><a id="__codelineno-3-10" name="__codelineno-3-10" href="#__codelineno-3-10"></a>    <span class="p">[</span><span class="mi">11</span><span class="p">,</span> <span class="mi">339</span><span class="p">,</span> <span class="mi">561</span><span class="p">],</span>
</span><span id="__span-3-11"><a id="__codelineno-3-11" name="__codelineno-3-11" href="#__codelineno-3-11"></a><span class="p">])</span>
</span><span id="__span-3-12"><a id="__codelineno-3-12" name="__codelineno-3-12" href="#__codelineno-3-12"></a><span class="n">response_length</span> <span class="o">=</span> <span class="mi">4</span>
</span><span id="__span-3-13"><a id="__codelineno-3-13" name="__codelineno-3-13" href="#__codelineno-3-13"></a><span class="n">temperature</span> <span class="o">=</span> <span class="mf">0.7</span>
</span><span id="__span-3-14"><a id="__codelineno-3-14" name="__codelineno-3-14" href="#__codelineno-3-14"></a><span class="n">pretrained_model</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;gpt2&quot;</span><span class="p">)</span>
</span><span id="__span-3-15"><a id="__codelineno-3-15" name="__codelineno-3-15" href="#__codelineno-3-15"></a><span class="n">pretrained_model</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">eos_token_id</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># disable `pad_token_id` and `eos_token_id` because we just want to</span>
</span><span id="__span-3-16"><a id="__codelineno-3-16" name="__codelineno-3-16" href="#__codelineno-3-16"></a><span class="n">pretrained_model</span><span class="o">.</span><span class="n">generation_config</span><span class="o">.</span><span class="n">pad_token_id</span> <span class="o">=</span> <span class="kc">None</span> <span class="c1"># generate tokens without truncation / padding</span>
</span><span id="__span-3-17"><a id="__codelineno-3-17" name="__codelineno-3-17" href="#__codelineno-3-17"></a><span class="n">generation_config</span> <span class="o">=</span> <span class="n">transformers</span><span class="o">.</span><span class="n">GenerationConfig</span><span class="p">(</span>
</span><span id="__span-3-18"><a id="__codelineno-3-18" name="__codelineno-3-18" href="#__codelineno-3-18"></a>    <span class="n">max_new_tokens</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
</span><span id="__span-3-19"><a id="__codelineno-3-19" name="__codelineno-3-19" href="#__codelineno-3-19"></a>    <span class="n">min_new_tokens</span><span class="o">=</span><span class="n">response_length</span><span class="p">,</span>
</span><span id="__span-3-20"><a id="__codelineno-3-20" name="__codelineno-3-20" href="#__codelineno-3-20"></a>    <span class="n">temperature</span><span class="o">=</span><span class="n">temperature</span><span class="p">,</span>
</span><span id="__span-3-21"><a id="__codelineno-3-21" name="__codelineno-3-21" href="#__codelineno-3-21"></a>    <span class="n">top_k</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-3-22"><a id="__codelineno-3-22" name="__codelineno-3-22" href="#__codelineno-3-22"></a>    <span class="n">top_p</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
</span><span id="__span-3-23"><a id="__codelineno-3-23" name="__codelineno-3-23" href="#__codelineno-3-23"></a>    <span class="n">do_sample</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-3-24"><a id="__codelineno-3-24" name="__codelineno-3-24" href="#__codelineno-3-24"></a><span class="p">)</span>
</span><span id="__span-3-25"><a id="__codelineno-3-25" name="__codelineno-3-25" href="#__codelineno-3-25"></a><span class="n">context_length</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span><span id="__span-3-26"><a id="__codelineno-3-26" name="__codelineno-3-26" href="#__codelineno-3-26"></a><span class="n">attention_mask</span> <span class="o">=</span> <span class="n">query</span> <span class="o">!=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">pad_token_id</span>
</span><span id="__span-3-27"><a id="__codelineno-3-27" name="__codelineno-3-27" href="#__codelineno-3-27"></a><span class="n">input_ids</span> <span class="o">=</span> <span class="n">query</span><span class="o">.</span><span class="n">clone</span><span class="p">()</span>
</span><span id="__span-3-28"><a id="__codelineno-3-28" name="__codelineno-3-28" href="#__codelineno-3-28"></a><span class="n">input_ids</span><span class="p">[</span><span class="o">~</span><span class="n">attention_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># set padding tokens to 0</span>
</span><span id="__span-3-29"><a id="__codelineno-3-29" name="__codelineno-3-29" href="#__codelineno-3-29"></a><span class="n">output</span> <span class="o">=</span> <span class="n">pretrained_model</span><span class="o">.</span><span class="n">generate</span><span class="p">(</span>
</span><span id="__span-3-30"><a id="__codelineno-3-30" name="__codelineno-3-30" href="#__codelineno-3-30"></a>    <span class="n">input_ids</span><span class="o">=</span><span class="n">input_ids</span><span class="p">,</span>
</span><span id="__span-3-31"><a id="__codelineno-3-31" name="__codelineno-3-31" href="#__codelineno-3-31"></a>    <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
</span><span id="__span-3-32"><a id="__codelineno-3-32" name="__codelineno-3-32" href="#__codelineno-3-32"></a>    <span class="c1"># position_ids=attention_mask.cumsum(1) - attention_mask.long(), # generation collapsed if this was turned on. TODO: why does generation collapse with this?</span>
</span><span id="__span-3-33"><a id="__codelineno-3-33" name="__codelineno-3-33" href="#__codelineno-3-33"></a>    <span class="n">generation_config</span><span class="o">=</span><span class="n">generation_config</span><span class="p">,</span>
</span><span id="__span-3-34"><a id="__codelineno-3-34" name="__codelineno-3-34" href="#__codelineno-3-34"></a>    <span class="n">return_dict_in_generate</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-3-35"><a id="__codelineno-3-35" name="__codelineno-3-35" href="#__codelineno-3-35"></a><span class="p">)</span>
</span><span id="__span-3-36"><a id="__codelineno-3-36" name="__codelineno-3-36" href="#__codelineno-3-36"></a><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">sequences</span><span class="p">)</span>
</span><span id="__span-3-37"><a id="__codelineno-3-37" name="__codelineno-3-37" href="#__codelineno-3-37"></a>
</span><span id="__span-3-38"><a id="__codelineno-3-38" name="__codelineno-3-38" href="#__codelineno-3-38"></a><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-3-39"><a id="__codelineno-3-39" name="__codelineno-3-39" href="#__codelineno-3-39"></a><span class="sd">tensor([[ 0, 0, 23073, 16851, 11, 475, 991]])</span>
</span><span id="__span-3-40"><a id="__codelineno-3-40" name="__codelineno-3-40" href="#__codelineno-3-40"></a><span class="sd">&quot;&quot;&quot;</span>
</span></code></pre></div>
</li>
<li>
<p>请注意，在较新的代码库 https://github.com/openai/summarize-from-feedback 中，当遇到 EOS token 时，OAI 确实会停止采样 (<a href="https://github.com/openai/summarize-from-feedback/blob/8af822a428c93432aa80ffbe5b065a8f93895669/summarize_from_feedback/utils/experiment_helpers.py#L19">summarize_from_feedback/utils/experiment_helpers.py#L19</a>)。然而，在这项工作中，我们的目标是进行 1:1 的复刻，所以我们调整了设置，即使遇到 eos_token 也可以继续采样。</p>
</li>
</ol>
</li>
<li>
<p><strong>奖励模型和策略训练的学习率退火。</strong></p>
<ol>
<li>正如 Ziegler 等人 (2019) 建议的，奖励模型只训练一个 epcho，以避免过度拟合有限量的人类注释数据 (例如，<code>descriptiveness</code> 任务只有大约 5000 个标签)。在这个单一的 epcho 中，学习率会退火至零 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_reward.py#L249">lm_human_preferences/train_reward.py#L249</a>)。</li>
<li>类似于奖励模型训练，策略训练的学习率也会退火至零 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L172-L173">lm_human_preferences/train_policy.py#L172-L173</a>)。</li>
</ol>
</li>
<li>
<p><strong>为不同的进程使用不同的种子</strong></p>
<ol>
<li>
<p>在生成 8 个 GPU 进程进行数据并行时，OAI 为每个进程设置了不同的随机种子 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/utils/core.py#L108-L111">lm_human_preferences/utils/core.py#L108-L111</a>)。在实现上，这是通过 <code>local_seed = args.seed + process_rank * 100003</code> 完成的。种子会让模型产生不同的响应并得到不同的分数，例如。</p>
<ol>
<li>注: 我认为数据集的洗牌 (shuffling) 存在一个错误——由于某种原因，数据集是使用相同的种子进行洗牌的 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/lm_tasks.py#L94-L97">lm_human_preferences/lm_tasks.py#L94-L97</a>)。</li>
</ol>
</li>
</ol>
</li>
</ol>
<h1 id="_3">奖励模型实现细节<a class="headerlink" href="#_3" title="Permanent link">&para;</a></h1>
<p>在本节中，我们讨论了奖励模型特定的实现细节。我们讨论了诸如奖励归一化和层初始化等细节。以下是这些细节，不按特定顺序排列:</p>
<ol>
<li>
<p><strong>奖励模型只输出最后一个 token 的值。</strong></p>
<ol>
<li>请注意，在对 <code>query</code> 和 <code>response</code> 的连接进行前向传递后获得的奖励将具有形状 <code>(B, T, 1)</code> ，其中 <code>B</code> 是 BS(批量大小)，<code>T</code> 是序列长度 (始终相同; 在 OAI 的设置中，它是 <code>query_length + response_length = 64 + 24 = 88</code> ，用于风格任务，参见 <a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/launch.py#L9-L11">launch.py#L9-L11</a>)，<code>1</code> 是奖励头其维度为 1。对于 RLHF (Reinforcement Learning from Human Feedback，通过人类反馈进行强化学习) 的目的，原始代码库提取最后一个 token 的奖励 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/rewards.py#L132">lm_human_preferences/rewards.py#L132</a>)，因此奖励将只具有形状 <code>(B, 1)</code> 。</li>
<li>请注意，在较新的代码库 <a href="https://github.com/openai/summarize-from-feedback"><em>openai/summarize-from-feedback</em></a> 中，OAI 在遇到 EOS token 时停止采样 (<a href="https://github.com/openai/summarize-from-feedback/blob/8af822a428c93432aa80ffbe5b065a8f93895669/summarize_from_feedback/utils/experiment_helpers.py#L19">summarize_from_feedback/utils/experiment_helpers.py#L19</a>)。在提取奖励时，它将确定 <code>last_response_index</code> ，即 EOS token 之前的索引 (<a href="https://github.com/openai/summarize-from-feedback/blob/8af822a428c93432aa80ffbe5b065a8f93895669/summarize_from_feedback/reward_model.py#L11-L13">#L11-L13</a>)，并在该索引处提取奖励 (<a href="https://github.com/openai/summarize-from-feedback/blob/8af822a428c93432aa80ffbe5b065a8f93895669/summarize_from_feedback/reward_model.py#L59">summarize_from_feedback/reward_model.py#L59</a>)。但在此工作中，我们只是坚持原始设置。</li>
</ol>
</li>
<li>
<p><strong>奖励头层初始化</strong></p>
<ol>
<li>奖励头的权重是根据 <span class="arithmatex">\( \mathcal{N}\left(0,1 /\left(\sqrt{d_{\text {model }}+1}\right)\right) \)</span> 初始化的 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L368">lm_human_preferences/language/model.py#L368,</a> <a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L251-L252">lm_human_preferences/language/model.py#L251-L252</a>)。这与 Stiennon 等人的设置相符，2020 年 (<a href="https://github.com/openai/summarize-from-feedback/blob/8af822a428c93432aa80ffbe5b065a8f93895669/summarize_from_feedback/query_response_model.py#L106-L107">summarize_from_feedback/query_response_model.py#L106-L107</a>) (附注，Stiennon 等人，2020 年在第 17 页上有一个错字，表示分布是 <span class="arithmatex">\( \mathcal{N}\left(0,1 /\left(d_{\text {model }}+1\right)\right) \)</span> 没有平方根)</li>
<li>奖励头的 bias (偏置) 设为 0 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L254">lm_human_preferences/language/model.py#L254</a>)。</li>
</ol>
</li>
<li>
<p><strong>奖励模型的前后归一化</strong></p>
<ol>
<li>在论文中，Ziegler 等人 (2019) 提到“为了保持训练过程中奖励模型的规模一致，我们将其归一化，使其在 <span class="arithmatex">\( x \sim \mathcal{D}, y \sim \rho(·|x) \)</span> 的情况下，均值为 0，方差为 1”。为了执行归一化过程，代码首先创建了 <code>reward_gain</code> 和 <code>reward_bias</code> ，以便可以通过 <code>reward = reward * reward_gain + reward_bias</code> 来计算奖励值 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/rewards.py#L50-L51">lm_human_preferences/rewards.py#L50-L51</a>)。</li>
<li>在执行归一化过程时，代码首先设置 <code>reward_gain=1, reward_bias=0</code> (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_reward.py#L211">lm_human_preferences/train_reward.py#L211</a>)，然后从目标数据集 (例如，<code>bookcorpus, tldr, cnndm</code> ) 中收集采样查询、完成的响应和评估的奖励。接着，它得到评估奖励的 <strong>实证均值和标准差</strong> (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_reward.py#L162-L167">lm_human_preferences/train_reward.py#L162-L167</a>)，并尝试计算 <code>reward_gain</code> 和 <code>reward_bias</code> 应该是什么。</li>
<li>
<p>我们用<span class="arithmatex">\( \mu_{\mathcal{D}} \)</span> 来表示实证均值，用<span class="arithmatex">\( \sigma_{\mathcal{D}} \)</span> 表示实证标准差，用<span class="arithmatex">\(g\)</span> 表示 <code>reward_gain</code> ，用<span class="arithmatex">\(b\)</span> 表示 <code>reward_bias</code> ，用<span class="arithmatex">\( \mu_{\mathcal{T}} = 0\)</span> 表示 <strong>目标均值</strong>，用<span class="arithmatex">\( \sigma_{\mathcal{T}}=1\)</span> 表示 <strong>目标标准差</strong>。然后我们有以下公式。</p>
<div class="arithmatex">\[
\begin{aligned}g*\mathcal{N}(\mu_{\mathcal{D}}, \sigma_{\mathcal{D}}) + b &amp;= \mathcal{N}(g*\mu_{\mathcal{D}}, g*\sigma_{\mathcal{D}}) + b\\&amp;= \mathcal{N}(g*\mu_{\mathcal{D}} + b, g*\sigma_{\mathcal{D}}) \\&amp;= \mathcal{N}(\mu_{\mathcal{T}}, \sigma_{\mathcal{T}}) \\g &amp;= \frac{\sigma_{\mathcal{T}}}{\sigma_{\mathcal{D}}} \\b &amp;= \mu_{\mathcal{T}} - g*\mu_{\mathcal{D}}\end{aligned}
\]</div>
</li>
<li>
<p>然后在奖励模型训练的 <strong>前</strong> 和 <strong>后</strong> 应用归一化过程 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_reward.py#L232-L234">lm_human_preferences/train_reward.py#L232-L234</a>，<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_reward.py#L252-L254">lm_human_preferences/train_reward.py#L252-L254</a>)。</p>
</li>
<li>请注意，我们为归一化目的生成的响应 <span class="arithmatex">\( y \sim \rho(·|x) \)</span> 来自预训练的语言模型 <span class="arithmatex">\(\rho \)</span>。模型 <span class="arithmatex">\(\rho \)</span> 被固定为参考，并且在奖励学习中不会更新 (<a href="https://github.com/openai/lm-human-preferences/blob/master/lm_human_preferences/train_reward.py#L286C1-L286C31">lm_human_preferences/train_reward.py#L286C1-L286C31</a>)。</li>
</ol>
</li>
</ol>
<h1 id="_4">策略训练实现细节<a class="headerlink" href="#_4" title="Permanent link">&para;</a></h1>
<p>在本节中，我们将深入探讨诸如层初始化、数据后处理和 dropout 设置等细节。我们还将探讨一些技术，如拒绝采样和奖励 “白化”，以及自适应 KL。以下是这些细节，排列不分先后:</p>
<ol>
<li>
<p><strong>通过采样温度来缩放 logits</strong></p>
<ol>
<li>在计算响应的对数概率时，模型首先输出响应中 token 的 logits，然后用采样温度除以这些 logits (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/policy.py#L121">lm_human_preferences/policy.py#L121</a>)。即 <code>logits /= self.temperature</code></li>
<li>在一个非正式的测试中，我们发现如果不进行此缩放，KL 散度会比预期更快地上升，性能会下降。</li>
</ol>
</li>
<li>
<p><strong>价值头层的初始化</strong></p>
<ol>
<li>价值头的权重是根据 <span class="arithmatex">\(\mathcal{N}(0,0)\)</span> 进行初始化的 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L368">lm_human_preferences/language/model.py#L368</a>、<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L251-L252">lm_human_preferences/language/model.py#L251-L252</a>)。</li>
<li>奖励头的 bias (偏置) 设置为 0 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/model.py#L254">lm_human_preferences/language/model.py#L254</a>)。</li>
</ol>
</li>
<li>
<p><strong>选择以句号开始和结束的查询文本</strong></p>
<ol>
<li>
<p>这是数据预处理的一部分:</p>
<ol>
<li>尝试仅在 <code>start_text="."</code> 之后选择文本 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/datasets.py#L51">lm_human_preferences/language/datasets.py#L51</a>)</li>
<li>尝试在 <code>end_text="."</code> 之前选择文本 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/datasets.py#L61">lm_human_preferences/language/datasets.py#L61</a>)</li>
<li>然后填充文本 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/language/datasets.py#L66-L67">lm_human_preferences/language/datasets.py#L66-L67</a>)</li>
</ol>
</li>
<li>
<p>在运行 <code>openai/lm-human-preferences</code> 时，OAI 的数据集部分损坏/丢失 (<a href="https://github.com/openai/lm-human-preferences/issues/17#issuecomment-1044051496">openai/lm-human-preferences/issues/17#issuecomment-104405149</a>)，因此我们不得不用类似的 HF 数据集替换它们，这可能会或可能不会导致性能差异。</p>
</li>
<li>对于书籍数据集，我们使用 <a href="https://huggingface.co/datasets/bookcorpus">https://huggingface.co/datasets/bookcorpus</a>，我们发现没有必要提取以句号开始和结束的句子，因为数据集已经是这样预处理过的 (例如，<code>"usually , he would be tearing around the living room , playing with his toys."</code> ) 为此，我们为 <code>sentiment</code> 和 <code>descriptiveness</code> 任务设置 <code>start_text=None, end_text=None</code> 。</li>
</ol>
</li>
<li>
<p><strong>禁用 dropout</strong></p>
<ol>
<li>Ziegler 等人 (2019) 建议，“我们在策略训练中不使用 dropout。” 这也在代码中实现了 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/policy.py#L48">lm_human_preferences/policy.py#L48</a>)。</li>
</ol>
</li>
<li>
<p><strong>拒绝采样</strong></p>
<ol>
<li>Ziegler 等人 (2019) 建议: “我们使用拒绝采样来确保在第 16 和 24 个 token 之间有一个句号，然后在那个句号处截断 (这是‘句子结束’的粗略近似。我们选择它是因为它很容易集成到 RL 循环中，即使是粗略的近似也足以使人类评估任务变得稍微容易一些)。在 RL 微调期间，我们对没有这样的句号的延续给予固定奖励 -1。”</li>
<li>
<p>具体来说，通过以下步骤实现此目的:</p>
<ol>
<li>
<p><strong>token 截断</strong>: 我们想要在第一个出现在响应的 <code>truncate_after</code> 位置之后的 <code>truncate_token</code> 处截断 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L378">lm_human_preferences/train_policy.py#L378</a>)。</p>
<ol>
<li>代码注释: “中心示例: 将截断 token 后的所有 token 替换为填充 token”</li>
</ol>
</li>
<li>
<p><strong>在截断响应上运行奖励模型</strong>: 在 token 截断过程将响应截断后，代码然后在 <strong>截断的响应</strong> 上运行奖励模型。</p>
</li>
<li>
<p><strong>拒绝采样</strong>: 如果在第 16 和 24 个 token 之间没有句号，那么将响应的分数替换为固定的低值 (例如 -1) (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L384">lm_human_preferences/train_policy.py#L384</a>、<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L384-L402">lm_human_preferences/train_policy.py#L384-L402</a>)。</p>
<ol>
<li>代码注释: “中心示例: 确保样本包含 <code>truncate_token</code> “</li>
<li>代码注释: “只对通过该功能的响应进行人类查询”</li>
</ol>
</li>
<li>
<p>在 <code>descriptiveness</code> 中举一些例子:</p>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/Untitled%201.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/Untitled%201.png" /></a></p>
<p>从我们的复制中提取的样本 <a href="https://wandb.ai/openrlbenchmark/lm_human_preference_details/runs/djf8yymv/logs?workspace=user-costa-huang">https://wandb.ai/openrlbenchmark/lm_human_preference_details/runs/djf8yymv/logs</a>。请注意，第 1 和第 3 个示例在句号后有太多 token，因此其分数被替换为 -1。</p>
</li>
</ol>
</li>
</ol>
</li>
<li>
<p><strong>折现因子 (discount factor) = 1</strong></p>
<ol>
<li>折现因子 <span class="arithmatex">\(\gamma\)</span> 设置为 1 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L56">lm_human_preferences/train_policy.py#L56</a>)，这意味着未来的奖励与即时奖励具有相同的权重。</li>
</ol>
</li>
<li>
<p><strong>训练循环的术语: PPO 中的批次和小批次</strong></p>
<ol>
<li>
<p>OAI 使用以下训练循环 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L184-L192">lm_human_preferences/train_policy.py#L184-L192</a>)。注意: 我们额外添加了 <code>micro_batch_size</code> 来帮助处理梯度累积的情况。在每个时期，它都会洗牌批次索引。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-4-1"><a id="__codelineno-4-1" name="__codelineno-4-1" href="#__codelineno-4-1"></a><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</span><span id="__span-4-2"><a id="__codelineno-4-2" name="__codelineno-4-2" href="#__codelineno-4-2"></a><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">8</span>
</span><span id="__span-4-3"><a id="__codelineno-4-3" name="__codelineno-4-3" href="#__codelineno-4-3"></a><span class="n">nminibatches</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="__span-4-4"><a id="__codelineno-4-4" name="__codelineno-4-4" href="#__codelineno-4-4"></a><span class="n">gradient_accumulation_steps</span> <span class="o">=</span> <span class="mi">2</span>
</span><span id="__span-4-5"><a id="__codelineno-4-5" name="__codelineno-4-5" href="#__codelineno-4-5"></a><span class="n">mini_batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="n">nminibatches</span>
</span><span id="__span-4-6"><a id="__codelineno-4-6" name="__codelineno-4-6" href="#__codelineno-4-6"></a><span class="n">micro_batch_size</span> <span class="o">=</span> <span class="n">mini_batch_size</span> <span class="o">//</span> <span class="n">gradient_accumulation_steps</span>
</span><span id="__span-4-7"><a id="__codelineno-4-7" name="__codelineno-4-7" href="#__codelineno-4-7"></a><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span><span id="__span-4-8"><a id="__codelineno-4-8" name="__codelineno-4-8" href="#__codelineno-4-8"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;data:&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</span><span id="__span-4-9"><a id="__codelineno-4-9" name="__codelineno-4-9" href="#__codelineno-4-9"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;batch_size:&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</span><span id="__span-4-10"><a id="__codelineno-4-10" name="__codelineno-4-10" href="#__codelineno-4-10"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;mini_batch_size:&quot;</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">)</span>
</span><span id="__span-4-11"><a id="__codelineno-4-11" name="__codelineno-4-11" href="#__codelineno-4-11"></a><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;micro_batch_size:&quot;</span><span class="p">,</span> <span class="n">micro_batch_size</span><span class="p">)</span>
</span><span id="__span-4-12"><a id="__codelineno-4-12" name="__codelineno-4-12" href="#__codelineno-4-12"></a><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4</span><span class="p">):</span>
</span><span id="__span-4-13"><a id="__codelineno-4-13" name="__codelineno-4-13" href="#__codelineno-4-13"></a>    <span class="n">batch_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</span><span id="__span-4-14"><a id="__codelineno-4-14" name="__codelineno-4-14" href="#__codelineno-4-14"></a>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch:&quot;</span><span class="p">,</span> <span class="n">epoch</span><span class="p">,</span> <span class="s2">&quot;batch_inds:&quot;</span><span class="p">,</span> <span class="n">batch_inds</span><span class="p">)</span>
</span><span id="__span-4-15"><a id="__codelineno-4-15" name="__codelineno-4-15" href="#__codelineno-4-15"></a>    <span class="k">for</span> <span class="n">mini_batch_start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">):</span>
</span><span id="__span-4-16"><a id="__codelineno-4-16" name="__codelineno-4-16" href="#__codelineno-4-16"></a>        <span class="n">mini_batch_end</span> <span class="o">=</span> <span class="n">mini_batch_start</span> <span class="o">+</span> <span class="n">mini_batch_size</span>
</span><span id="__span-4-17"><a id="__codelineno-4-17" name="__codelineno-4-17" href="#__codelineno-4-17"></a>        <span class="n">mini_batch_inds</span> <span class="o">=</span> <span class="n">batch_inds</span><span class="p">[</span><span class="n">mini_batch_start</span><span class="p">:</span><span class="n">mini_batch_end</span><span class="p">]</span>
</span><span id="__span-4-18"><a id="__codelineno-4-18" name="__codelineno-4-18" href="#__codelineno-4-18"></a>
</span><span id="__span-4-19"><a id="__codelineno-4-19" name="__codelineno-4-19" href="#__codelineno-4-19"></a>        <span class="c1"># `optimizer.zero_grad()` set optimizer to zero for gradient accumulation</span>
</span><span id="__span-4-20"><a id="__codelineno-4-20" name="__codelineno-4-20" href="#__codelineno-4-20"></a>        <span class="k">for</span> <span class="n">micro_batch_start</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mini_batch_size</span><span class="p">,</span> <span class="n">micro_batch_size</span><span class="p">):</span>
</span><span id="__span-4-21"><a id="__codelineno-4-21" name="__codelineno-4-21" href="#__codelineno-4-21"></a>            <span class="n">micro_batch_end</span> <span class="o">=</span> <span class="n">micro_batch_start</span> <span class="o">+</span> <span class="n">micro_batch_size</span>
</span><span id="__span-4-22"><a id="__codelineno-4-22" name="__codelineno-4-22" href="#__codelineno-4-22"></a>            <span class="n">micro_batch_inds</span> <span class="o">=</span> <span class="n">mini_batch_inds</span><span class="p">[</span><span class="n">micro_batch_start</span><span class="p">:</span><span class="n">micro_batch_end</span><span class="p">]</span>
</span><span id="__span-4-23"><a id="__codelineno-4-23" name="__codelineno-4-23" href="#__codelineno-4-23"></a>            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;____⏩ a forward pass on&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">micro_batch_inds</span><span class="p">])</span>
</span><span id="__span-4-24"><a id="__codelineno-4-24" name="__codelineno-4-24" href="#__codelineno-4-24"></a>        <span class="c1"># `optimizer.step()`</span>
</span><span id="__span-4-25"><a id="__codelineno-4-25" name="__codelineno-4-25" href="#__codelineno-4-25"></a>        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;⏪ a backward pass on&quot;</span><span class="p">,</span> <span class="n">data</span><span class="p">[</span><span class="n">mini_batch_inds</span><span class="p">])</span>
</span><span id="__span-4-26"><a id="__codelineno-4-26" name="__codelineno-4-26" href="#__codelineno-4-26"></a>
</span><span id="__span-4-27"><a id="__codelineno-4-27" name="__codelineno-4-27" href="#__codelineno-4-27"></a><span class="c1"># data: [0. 1. 2. 3. 4. 5. 6. 7.]</span>
</span><span id="__span-4-28"><a id="__codelineno-4-28" name="__codelineno-4-28" href="#__codelineno-4-28"></a><span class="c1"># batch_size: 8</span>
</span><span id="__span-4-29"><a id="__codelineno-4-29" name="__codelineno-4-29" href="#__codelineno-4-29"></a><span class="c1"># mini_batch_size: 4</span>
</span><span id="__span-4-30"><a id="__codelineno-4-30" name="__codelineno-4-30" href="#__codelineno-4-30"></a><span class="c1"># micro_batch_size: 2</span>
</span><span id="__span-4-31"><a id="__codelineno-4-31" name="__codelineno-4-31" href="#__codelineno-4-31"></a><span class="c1"># epoch: 0 batch_inds: [6 4 0 7 3 5 1 2]</span>
</span><span id="__span-4-32"><a id="__codelineno-4-32" name="__codelineno-4-32" href="#__codelineno-4-32"></a><span class="c1"># ____⏩ a forward pass on [6. 4.]</span>
</span><span id="__span-4-33"><a id="__codelineno-4-33" name="__codelineno-4-33" href="#__codelineno-4-33"></a><span class="c1"># ____⏩ a forward pass on [0. 7.]</span>
</span><span id="__span-4-34"><a id="__codelineno-4-34" name="__codelineno-4-34" href="#__codelineno-4-34"></a><span class="c1"># ⏪ a backward pass on [6. 4. 0. 7.]</span>
</span><span id="__span-4-35"><a id="__codelineno-4-35" name="__codelineno-4-35" href="#__codelineno-4-35"></a><span class="c1"># ____⏩ a forward pass on [3. 5.]</span>
</span><span id="__span-4-36"><a id="__codelineno-4-36" name="__codelineno-4-36" href="#__codelineno-4-36"></a><span class="c1"># ____⏩ a forward pass on [1. 2.]</span>
</span><span id="__span-4-37"><a id="__codelineno-4-37" name="__codelineno-4-37" href="#__codelineno-4-37"></a><span class="c1"># ⏪ a backward pass on [3. 5. 1. 2.]</span>
</span><span id="__span-4-38"><a id="__codelineno-4-38" name="__codelineno-4-38" href="#__codelineno-4-38"></a><span class="c1"># epoch: 1 batch_inds: [6 7 3 2 0 4 5 1]</span>
</span><span id="__span-4-39"><a id="__codelineno-4-39" name="__codelineno-4-39" href="#__codelineno-4-39"></a><span class="c1"># ____⏩ a forward pass on [6. 7.]</span>
</span><span id="__span-4-40"><a id="__codelineno-4-40" name="__codelineno-4-40" href="#__codelineno-4-40"></a><span class="c1"># ____⏩ a forward pass on [3. 2.]</span>
</span><span id="__span-4-41"><a id="__codelineno-4-41" name="__codelineno-4-41" href="#__codelineno-4-41"></a><span class="c1"># ⏪ a backward pass on [6. 7. 3. 2.]</span>
</span><span id="__span-4-42"><a id="__codelineno-4-42" name="__codelineno-4-42" href="#__codelineno-4-42"></a><span class="c1"># ____⏩ a forward pass on [0. 4.]</span>
</span><span id="__span-4-43"><a id="__codelineno-4-43" name="__codelineno-4-43" href="#__codelineno-4-43"></a><span class="c1"># ____⏩ a forward pass on [5. 1.]</span>
</span><span id="__span-4-44"><a id="__codelineno-4-44" name="__codelineno-4-44" href="#__codelineno-4-44"></a><span class="c1"># ⏪ a backward pass on [0. 4. 5. 1.]</span>
</span><span id="__span-4-45"><a id="__codelineno-4-45" name="__codelineno-4-45" href="#__codelineno-4-45"></a><span class="c1"># epoch: 2 batch_inds: [1 4 5 6 0 7 3 2]</span>
</span><span id="__span-4-46"><a id="__codelineno-4-46" name="__codelineno-4-46" href="#__codelineno-4-46"></a><span class="c1"># ____⏩ a forward pass on [1. 4.]</span>
</span><span id="__span-4-47"><a id="__codelineno-4-47" name="__codelineno-4-47" href="#__codelineno-4-47"></a><span class="c1"># ____⏩ a forward pass on [5. 6.]</span>
</span><span id="__span-4-48"><a id="__codelineno-4-48" name="__codelineno-4-48" href="#__codelineno-4-48"></a><span class="c1"># ⏪ a backward pass on [1. 4. 5. 6.]</span>
</span><span id="__span-4-49"><a id="__codelineno-4-49" name="__codelineno-4-49" href="#__codelineno-4-49"></a><span class="c1"># ____⏩ a forward pass on [0. 7.]</span>
</span><span id="__span-4-50"><a id="__codelineno-4-50" name="__codelineno-4-50" href="#__codelineno-4-50"></a><span class="c1"># ____⏩ a forward pass on [3. 2.]</span>
</span><span id="__span-4-51"><a id="__codelineno-4-51" name="__codelineno-4-51" href="#__codelineno-4-51"></a><span class="c1"># ⏪ a backward pass on [0. 7. 3. 2.]</span>
</span><span id="__span-4-52"><a id="__codelineno-4-52" name="__codelineno-4-52" href="#__codelineno-4-52"></a><span class="c1"># epoch: 3 batch_inds: [7 2 4 1 3 0 6 5]</span>
</span><span id="__span-4-53"><a id="__codelineno-4-53" name="__codelineno-4-53" href="#__codelineno-4-53"></a><span class="c1"># ____⏩ a forward pass on [7. 2.]</span>
</span><span id="__span-4-54"><a id="__codelineno-4-54" name="__codelineno-4-54" href="#__codelineno-4-54"></a><span class="c1"># ____⏩ a forward pass on [4. 1.]</span>
</span><span id="__span-4-55"><a id="__codelineno-4-55" name="__codelineno-4-55" href="#__codelineno-4-55"></a><span class="c1"># ⏪ a backward pass on [7. 2. 4. 1.]</span>
</span><span id="__span-4-56"><a id="__codelineno-4-56" name="__codelineno-4-56" href="#__codelineno-4-56"></a><span class="c1"># ____⏩ a forward pass on [3. 0.]</span>
</span><span id="__span-4-57"><a id="__codelineno-4-57" name="__codelineno-4-57" href="#__codelineno-4-57"></a><span class="c1"># ____⏩ a forward pass on [6. 5.]</span>
</span><span id="__span-4-58"><a id="__codelineno-4-58" name="__codelineno-4-58" href="#__codelineno-4-58"></a><span class="c1"># ⏪ a backward pass on [3. 0. 6. 5.]</span>
</span></code></pre></div>
</li>
</ol>
</li>
<li>
<p><strong>基于每个标记的 KL 惩罚</strong></p>
<ul>
<li>代码为奖励添加了每个标记的 KL 惩罚 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L150-L153">lm_human_preferences/train_policy.py#L150-L153</a>)，以阻止策略与原始策略差异过大。</li>
<li>
<p>以 “usually, he would” 为例，它被标记化为 <code>[23073, 11, 339, 561]</code> 。假设我们使用 <code>[23073]</code> 作为查询，<code>[11, 339, 561]</code> 作为响应。然后在默认的 <code>gpt2</code> 参数下，响应标记将具有参考策略的对数概率 <code>logprobs=[-3.3213, -4.9980, -3.8690]</code> 。</p>
<ul>
<li>在第一个 PPO 更新时期和小批次更新时，激活策略将具有相同的对数概率<code>new_logprobs=[-3.3213, -4.9980, -3.8690]</code> 。因此，每个标记的 KL 惩罚将为 <code>kl = new_logprobs - logprobs = [0., 0., 0.]</code> 。</li>
<li>但是，在第一个梯度反向传播后，我们可能会得到 <code>new_logprob=[3.3213, -4.9980, -3.8690]</code> ，因此每个标记的 KL 惩罚变为 <code>kl = new_logprobs - logprobs = [-0.3315, -0.0426, 0.6351]</code> 。</li>
<li>随后，<code>non_score_reward = beta * kl</code> ，其中 <code>beta</code> 是 KL 惩罚系数 <span class="arithmatex">\(\beta\)</span>，它被添加到从奖励模型获得的 <code>score</code> 中，以创建用于训练的 <code>rewards</code> 。<code>score</code> 仅在每个回合 ( episode ) 结束时给出，可能类似于 <code>[0.4]</code> ，然后我们有 <code>rewards = [beta * -0.3315, beta * -0.0426, beta * 0.6351 + 0.4]</code> 。</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>每个小批次的奖励和优势白化，可选择均值平移</strong></p>
<ol>
<li>
<p>OAI 实现了一个名为 <code>whiten</code> 的函数，如下所示，基本上通过减去其均值然后除以其标准差来对 <code>values</code> 进行归一化。可选地，<code>whiten</code> 可以通过 <code>shift_mean=True</code> 将白化后的 <code>values</code> 平移到均值。</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-5-1"><a id="__codelineno-5-1" name="__codelineno-5-1" href="#__codelineno-5-1"></a><span class="k">def</span> <span class="nf">whiten</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">shift_mean</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
</span><span id="__span-5-2"><a id="__codelineno-5-2" name="__codelineno-5-2" href="#__codelineno-5-2"></a>    <span class="n">mean</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span><span id="__span-5-3"><a id="__codelineno-5-3" name="__codelineno-5-3" href="#__codelineno-5-3"></a>    <span class="n">whitened</span> <span class="o">=</span> <span class="p">(</span><span class="n">values</span> <span class="o">-</span> <span class="n">mean</span><span class="p">)</span><span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">rsqrt</span><span class="p">(</span><span class="n">var</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
</span><span id="__span-5-4"><a id="__codelineno-5-4" name="__codelineno-5-4" href="#__codelineno-5-4"></a>    <span class="k">if</span> <span class="ow">not</span> <span class="n">shift_mean</span><span class="p">:</span>
</span><span id="__span-5-5"><a id="__codelineno-5-5" name="__codelineno-5-5" href="#__codelineno-5-5"></a>        <span class="n">whitened</span> <span class="o">+=</span> <span class="n">mean</span>
</span><span id="__span-5-6"><a id="__codelineno-5-6" name="__codelineno-5-6" href="#__codelineno-5-6"></a>    <span class="k">return</span> <span class="n">whitened</span>
</span></code></pre></div>
</li>
<li>
<p>在每个小批次中，OAI 使用 <code>whiten(rewards, shift_mean=False)</code> 对奖励进行白化，不对均值进行平移处理 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L325">lm_human_preferences/train_policy.py#L325</a>)，并使用平移后的均值对优势进行白化 <code>whiten(advantages)</code> (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L338">lm_human_preferences/train_policy.py#L338</a>)。</p>
</li>
<li><strong>优化注意事项:</strong> 如果小批次的数量为一 (在此复现中是这种情况)，我们只需要对奖励进行白化、计算并对优势进行一次白化，因为它们的值不会改变。</li>
<li>
<p><strong>TensorFlow vs PyTorch 注意事项:</strong> <code>tf.moments</code> 与 <code>torch.var</code> 的不同行为: 由于方差计算方式不同，Torch 和 TensorFlow 中的白化行为不同:</p>
<div class="language-jsx highlight"><pre><span></span><code><span id="__span-6-1"><a id="__codelineno-6-1" name="__codelineno-6-1" href="#__codelineno-6-1"></a><span class="k">import</span><span class="w"> </span><span class="nx">numpy</span><span class="w"> </span><span class="kr">as</span><span class="w"> </span><span class="nx">np</span>
</span><span id="__span-6-2"><a id="__codelineno-6-2" name="__codelineno-6-2" href="#__codelineno-6-2"></a><span class="k">import</span><span class="w"> </span><span class="nx">tensorflow</span><span class="w"> </span><span class="kr">as</span><span class="w"> </span><span class="nx">tf</span>
</span><span id="__span-6-3"><a id="__codelineno-6-3" name="__codelineno-6-3" href="#__codelineno-6-3"></a><span class="k">import</span><span class="w"> </span><span class="nx">torch</span>
</span><span id="__span-6-4"><a id="__codelineno-6-4" name="__codelineno-6-4" href="#__codelineno-6-4"></a>
</span><span id="__span-6-5"><a id="__codelineno-6-5" name="__codelineno-6-5" href="#__codelineno-6-5"></a><span class="nx">def</span><span class="w"> </span><span class="nx">whiten_tf</span><span class="p">(</span><span class="nx">values</span><span class="p">,</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">=</span><span class="nx">True</span><span class="p">)</span><span class="o">:</span>
</span><span id="__span-6-6"><a id="__codelineno-6-6" name="__codelineno-6-6" href="#__codelineno-6-6"></a><span class="w">    </span><span class="nx">mean</span><span class="p">,</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">tf</span><span class="p">.</span><span class="nx">nn</span><span class="p">.</span><span class="nx">moments</span><span class="p">(</span><span class="nx">values</span><span class="p">,</span><span class="w"> </span><span class="nx">axes</span><span class="o">=</span><span class="nx">list</span><span class="p">(</span><span class="nx">range</span><span class="p">(</span><span class="nx">values</span><span class="p">.</span><span class="nx">shape</span><span class="p">.</span><span class="nx">rank</span><span class="p">)))</span>
</span><span id="__span-6-7"><a id="__codelineno-6-7" name="__codelineno-6-7" href="#__codelineno-6-7"></a><span class="w">    </span><span class="nx">mean</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">tf</span><span class="p">.</span><span class="nx">Print</span><span class="p">(</span><span class="nx">mean</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="nx">mean</span><span class="p">],</span><span class="w"> </span><span class="s1">&#39;mean&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">summarize</span><span class="o">=</span><span class="mf">100</span><span class="p">)</span>
</span><span id="__span-6-8"><a id="__codelineno-6-8" name="__codelineno-6-8" href="#__codelineno-6-8"></a><span class="w">    </span><span class="kd">var</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">tf</span><span class="p">.</span><span class="nx">Print</span><span class="p">(</span><span class="kd">var</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="kd">var</span><span class="p">],</span><span class="w"> </span><span class="s1">&#39;var&#39;</span><span class="p">,</span><span class="w"> </span><span class="nx">summarize</span><span class="o">=</span><span class="mf">100</span><span class="p">)</span>
</span><span id="__span-6-9"><a id="__codelineno-6-9" name="__codelineno-6-9" href="#__codelineno-6-9"></a><span class="w">    </span><span class="nx">whitened</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">values</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nx">mean</span><span class="p">)</span><span class="o">*</span><span class="w"> </span><span class="nx">tf</span><span class="p">.</span><span class="nx">rsqrt</span><span class="p">(</span><span class="kd">var</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1e-8</span><span class="p">)</span>
</span><span id="__span-6-10"><a id="__codelineno-6-10" name="__codelineno-6-10" href="#__codelineno-6-10"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nx">not</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">:</span>
</span><span id="__span-6-11"><a id="__codelineno-6-11" name="__codelineno-6-11" href="#__codelineno-6-11"></a><span class="w">        </span><span class="nx">whitened</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">mean</span>
</span><span id="__span-6-12"><a id="__codelineno-6-12" name="__codelineno-6-12" href="#__codelineno-6-12"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">whitened</span>
</span><span id="__span-6-13"><a id="__codelineno-6-13" name="__codelineno-6-13" href="#__codelineno-6-13"></a>
</span><span id="__span-6-14"><a id="__codelineno-6-14" name="__codelineno-6-14" href="#__codelineno-6-14"></a><span class="nx">def</span><span class="w"> </span><span class="nx">whiten_pt</span><span class="p">(</span><span class="nx">values</span><span class="p">,</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">=</span><span class="nx">True</span><span class="p">,</span><span class="w"> </span><span class="nx">unbiased</span><span class="o">=</span><span class="nx">True</span><span class="p">)</span><span class="o">:</span>
</span><span id="__span-6-15"><a id="__codelineno-6-15" name="__codelineno-6-15" href="#__codelineno-6-15"></a><span class="w">    </span><span class="nx">mean</span><span class="p">,</span><span class="w"> </span><span class="kd">var</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">torch</span><span class="p">.</span><span class="nx">mean</span><span class="p">(</span><span class="nx">values</span><span class="p">),</span><span class="w"> </span><span class="nx">torch</span><span class="p">.</span><span class="kd">var</span><span class="p">(</span><span class="nx">values</span><span class="p">,</span><span class="w"> </span><span class="nx">unbiased</span><span class="o">=</span><span class="nx">unbiased</span><span class="p">)</span>
</span><span id="__span-6-16"><a id="__codelineno-6-16" name="__codelineno-6-16" href="#__codelineno-6-16"></a><span class="w">    </span><span class="nx">print</span><span class="p">(</span><span class="s2">&quot;mean&quot;</span><span class="p">,</span><span class="w"> </span><span class="nx">mean</span><span class="p">)</span>
</span><span id="__span-6-17"><a id="__codelineno-6-17" name="__codelineno-6-17" href="#__codelineno-6-17"></a><span class="w">    </span><span class="nx">print</span><span class="p">(</span><span class="s2">&quot;var&quot;</span><span class="p">,</span><span class="w"> </span><span class="kd">var</span><span class="p">)</span>
</span><span id="__span-6-18"><a id="__codelineno-6-18" name="__codelineno-6-18" href="#__codelineno-6-18"></a><span class="w">    </span><span class="nx">whitened</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="nx">values</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nx">mean</span><span class="p">)</span><span class="o">*</span><span class="w"> </span><span class="nx">torch</span><span class="p">.</span><span class="nx">rsqrt</span><span class="p">(</span><span class="kd">var</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">1e-8</span><span class="p">)</span>
</span><span id="__span-6-19"><a id="__codelineno-6-19" name="__codelineno-6-19" href="#__codelineno-6-19"></a><span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nx">not</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">:</span>
</span><span id="__span-6-20"><a id="__codelineno-6-20" name="__codelineno-6-20" href="#__codelineno-6-20"></a><span class="w">        </span><span class="nx">whitened</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nx">mean</span>
</span><span id="__span-6-21"><a id="__codelineno-6-21" name="__codelineno-6-21" href="#__codelineno-6-21"></a><span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nx">whitened</span>
</span><span id="__span-6-22"><a id="__codelineno-6-22" name="__codelineno-6-22" href="#__codelineno-6-22"></a>
</span><span id="__span-6-23"><a id="__codelineno-6-23" name="__codelineno-6-23" href="#__codelineno-6-23"></a><span class="nx">rewards</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nx">np</span><span class="p">.</span><span class="nx">array</span><span class="p">([</span>
</span><span id="__span-6-24"><a id="__codelineno-6-24" name="__codelineno-6-24" href="#__codelineno-6-24"></a><span class="w">    </span><span class="p">[</span><span class="mf">1.2</span><span class="p">,</span><span class="w"> </span><span class="mf">1.3</span><span class="p">,</span><span class="w"> </span><span class="mf">1.4</span><span class="p">],</span>
</span><span id="__span-6-25"><a id="__codelineno-6-25" name="__codelineno-6-25" href="#__codelineno-6-25"></a><span class="w">    </span><span class="p">[</span><span class="mf">1.5</span><span class="p">,</span><span class="w"> </span><span class="mf">1.6</span><span class="p">,</span><span class="w"> </span><span class="mf">1.7</span><span class="p">],</span>
</span><span id="__span-6-26"><a id="__codelineno-6-26" name="__codelineno-6-26" href="#__codelineno-6-26"></a><span class="w">    </span><span class="p">[</span><span class="mf">1.8</span><span class="p">,</span><span class="w"> </span><span class="mf">1.9</span><span class="p">,</span><span class="w"> </span><span class="mf">2.0</span><span class="p">],</span>
</span><span id="__span-6-27"><a id="__codelineno-6-27" name="__codelineno-6-27" href="#__codelineno-6-27"></a><span class="p">])</span>
</span><span id="__span-6-28"><a id="__codelineno-6-28" name="__codelineno-6-28" href="#__codelineno-6-28"></a>
</span><span id="__span-6-29"><a id="__codelineno-6-29" name="__codelineno-6-29" href="#__codelineno-6-29"></a><span class="kd">with</span><span class="w"> </span><span class="nx">tf</span><span class="p">.</span><span class="nx">Session</span><span class="p">()</span><span class="w"> </span><span class="kr">as</span><span class="w"> </span><span class="nx">sess</span><span class="o">:</span>
</span><span id="__span-6-30"><a id="__codelineno-6-30" name="__codelineno-6-30" href="#__codelineno-6-30"></a><span class="w">    </span><span class="nx">print</span><span class="p">(</span><span class="nx">sess</span><span class="p">.</span><span class="nx">run</span><span class="p">(</span><span class="nx">whiten_tf</span><span class="p">(</span><span class="nx">tf</span><span class="p">.</span><span class="nx">constant</span><span class="p">(</span><span class="nx">rewards</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">tf</span><span class="p">.</span><span class="nx">float32</span><span class="p">),</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">=</span><span class="nx">False</span><span class="p">)))</span>
</span><span id="__span-6-31"><a id="__codelineno-6-31" name="__codelineno-6-31" href="#__codelineno-6-31"></a><span class="w">    </span><span class="nx">print</span><span class="p">(</span><span class="nx">whiten_pt</span><span class="p">(</span><span class="nx">torch</span><span class="p">.</span><span class="nx">tensor</span><span class="p">(</span><span class="nx">rewards</span><span class="p">),</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">=</span><span class="nx">False</span><span class="p">,</span><span class="w"> </span><span class="nx">unbiased</span><span class="o">=</span><span class="nx">True</span><span class="p">))</span>
</span><span id="__span-6-32"><a id="__codelineno-6-32" name="__codelineno-6-32" href="#__codelineno-6-32"></a><span class="w">    </span><span class="nx">print</span><span class="p">(</span><span class="nx">whiten_pt</span><span class="p">(</span><span class="nx">torch</span><span class="p">.</span><span class="nx">tensor</span><span class="p">(</span><span class="nx">rewards</span><span class="p">),</span><span class="w"> </span><span class="nx">shift_mean</span><span class="o">=</span><span class="nx">False</span><span class="p">,</span><span class="w"> </span><span class="nx">unbiased</span><span class="o">=</span><span class="nx">False</span><span class="p">))</span>
</span></code></pre></div>
<div class="language-jsx highlight"><pre><span></span><code><span id="__span-7-1"><a id="__codelineno-7-1" name="__codelineno-7-1" href="#__codelineno-7-1"></a><span class="nx">mean</span><span class="p">[</span><span class="mf">1.5999999</span><span class="p">]</span>
</span><span id="__span-7-2"><a id="__codelineno-7-2" name="__codelineno-7-2" href="#__codelineno-7-2"></a><span class="kd">var</span><span class="p">[</span><span class="mf">0.0666666627</span><span class="p">]</span>
</span><span id="__span-7-3"><a id="__codelineno-7-3" name="__codelineno-7-3" href="#__codelineno-7-3"></a><span class="p">[[</span><span class="mf">0.05080712</span><span class="w"> </span><span class="mf">0.4381051</span><span class="w"> </span><span class="mf">0.8254035</span><span class="w"> </span><span class="p">]</span>
</span><span id="__span-7-4"><a id="__codelineno-7-4" name="__codelineno-7-4" href="#__codelineno-7-4"></a><span class="p">[</span><span class="mf">1.2127019</span><span class="w"> </span><span class="mf">1.6000004</span><span class="w"> </span><span class="mf">1.9872988</span><span class="w"> </span><span class="p">]</span>
</span><span id="__span-7-5"><a id="__codelineno-7-5" name="__codelineno-7-5" href="#__codelineno-7-5"></a><span class="p">[</span><span class="mf">2.3745968</span><span class="w"> </span><span class="mf">2.7618952</span><span class="w"> </span><span class="mf">3.1491938</span><span class="w"> </span><span class="p">]]</span>
</span><span id="__span-7-6"><a id="__codelineno-7-6" name="__codelineno-7-6" href="#__codelineno-7-6"></a><span class="nx">mean</span><span class="w"> </span><span class="nx">tensor</span><span class="p">(</span><span class="mf">1.6000</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">torch</span><span class="p">.</span><span class="nx">float64</span><span class="p">)</span>
</span><span id="__span-7-7"><a id="__codelineno-7-7" name="__codelineno-7-7" href="#__codelineno-7-7"></a><span class="kd">var</span><span class="w"> </span><span class="nx">tensor</span><span class="p">(</span><span class="mf">0.0750</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">torch</span><span class="p">.</span><span class="nx">float64</span><span class="p">)</span>
</span><span id="__span-7-8"><a id="__codelineno-7-8" name="__codelineno-7-8" href="#__codelineno-7-8"></a><span class="nx">tensor</span><span class="p">([[</span><span class="mf">0.1394</span><span class="p">,</span><span class="w"> </span><span class="mf">0.5046</span><span class="p">,</span><span class="w"> </span><span class="mf">0.8697</span><span class="p">],</span>
</span><span id="__span-7-9"><a id="__codelineno-7-9" name="__codelineno-7-9" href="#__codelineno-7-9"></a><span class="w">        </span><span class="p">[</span><span class="mf">1.2349</span><span class="p">,</span><span class="w"> </span><span class="mf">1.6000</span><span class="p">,</span><span class="w"> </span><span class="mf">1.9651</span><span class="p">],</span>
</span><span id="__span-7-10"><a id="__codelineno-7-10" name="__codelineno-7-10" href="#__codelineno-7-10"></a><span class="w">        </span><span class="p">[</span><span class="mf">2.3303</span><span class="p">,</span><span class="w"> </span><span class="mf">2.6954</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0606</span><span class="p">]],</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">torch</span><span class="p">.</span><span class="nx">float64</span><span class="p">)</span>
</span><span id="__span-7-11"><a id="__codelineno-7-11" name="__codelineno-7-11" href="#__codelineno-7-11"></a><span class="nx">mean</span><span class="w"> </span><span class="nx">tensor</span><span class="p">(</span><span class="mf">1.6000</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">torch</span><span class="p">.</span><span class="nx">float64</span><span class="p">)</span>
</span><span id="__span-7-12"><a id="__codelineno-7-12" name="__codelineno-7-12" href="#__codelineno-7-12"></a><span class="kd">var</span><span class="w"> </span><span class="nx">tensor</span><span class="p">(</span><span class="mf">0.0667</span><span class="p">,</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">torch</span><span class="p">.</span><span class="nx">float64</span><span class="p">)</span>
</span><span id="__span-7-13"><a id="__codelineno-7-13" name="__codelineno-7-13" href="#__codelineno-7-13"></a><span class="nx">tensor</span><span class="p">([[</span><span class="mf">0.0508</span><span class="p">,</span><span class="w"> </span><span class="mf">0.4381</span><span class="p">,</span><span class="w"> </span><span class="mf">0.8254</span><span class="p">],</span>
</span><span id="__span-7-14"><a id="__codelineno-7-14" name="__codelineno-7-14" href="#__codelineno-7-14"></a><span class="w">        </span><span class="p">[</span><span class="mf">1.2127</span><span class="p">,</span><span class="w"> </span><span class="mf">1.6000</span><span class="p">,</span><span class="w"> </span><span class="mf">1.9873</span><span class="p">],</span>
</span><span id="__span-7-15"><a id="__codelineno-7-15" name="__codelineno-7-15" href="#__codelineno-7-15"></a><span class="w">        </span><span class="p">[</span><span class="mf">2.3746</span><span class="p">,</span><span class="w"> </span><span class="mf">2.7619</span><span class="p">,</span><span class="w"> </span><span class="mf">3.1492</span><span class="p">]],</span><span class="w"> </span><span class="nx">dtype</span><span class="o">=</span><span class="nx">torch</span><span class="p">.</span><span class="nx">float64</span><span class="p">)</span>
</span></code></pre></div>
</li>
</ol>
</li>
<li>
<p><strong>裁剪值函数</strong></p>
<ol>
<li>与原始的 PPO 一样 (<a href="https://github.com/openai/baselines/blob/ea25b9e8b234e6ee1bca43083f8f3cf974143998/baselines/ppo2/model.py#L68-L75">baselines/ppo2/model.py#L68-L75</a>)，值函数被裁剪 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L343-L348">lm_human_preferences/train_policy.py#L343-L348</a>)，方式与策略目标类似。</li>
</ol>
</li>
<li>
<p><strong>自适应 KL 散度</strong></p>
<ul>
<li>
<p>KL 散度惩罚系数 <span class="arithmatex">\(\beta\)</span> 根据当前策略与先前策略之间的 KL 散度自适应修改。如果 KL 散度超出预定的目标范围，则调整惩罚系数以使其更接近目标范围 (<a href="https://github.com/openai/lm-human-preferences/blob/cbfd210bb8b08f6bc5c26878c10984b90f516c66/lm_human_preferences/train_policy.py#L115-L124">lm_human_preferences/train_policy.py#L115-L124</a>)。它的实现如下:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-8-1"><a id="__codelineno-8-1" name="__codelineno-8-1" href="#__codelineno-8-1"></a><span class="k">class</span> <span class="nc">AdaptiveKLController</span><span class="p">:</span>
</span><span id="__span-8-2"><a id="__codelineno-8-2" name="__codelineno-8-2" href="#__codelineno-8-2"></a>    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_kl_coef</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
</span><span id="__span-8-3"><a id="__codelineno-8-3" name="__codelineno-8-3" href="#__codelineno-8-3"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">=</span> <span class="n">init_kl_coef</span>
</span><span id="__span-8-4"><a id="__codelineno-8-4" name="__codelineno-8-4" href="#__codelineno-8-4"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span> <span class="o">=</span> <span class="n">hparams</span>
</span><span id="__span-8-5"><a id="__codelineno-8-5" name="__codelineno-8-5" href="#__codelineno-8-5"></a>
</span><span id="__span-8-6"><a id="__codelineno-8-6" name="__codelineno-8-6" href="#__codelineno-8-6"></a>    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">current</span><span class="p">,</span> <span class="n">n_steps</span><span class="p">):</span>
</span><span id="__span-8-7"><a id="__codelineno-8-7" name="__codelineno-8-7" href="#__codelineno-8-7"></a>        <span class="n">target</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">target</span>
</span><span id="__span-8-8"><a id="__codelineno-8-8" name="__codelineno-8-8" href="#__codelineno-8-8"></a>        <span class="n">proportional_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">current</span> <span class="o">/</span> <span class="n">target</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">)</span>
</span><span id="__span-8-9"><a id="__codelineno-8-9" name="__codelineno-8-9" href="#__codelineno-8-9"></a>        <span class="n">mult</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">proportional_error</span> <span class="o">*</span> <span class="n">n_steps</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">hparams</span><span class="o">.</span><span class="n">horizon</span>
</span><span id="__span-8-10"><a id="__codelineno-8-10" name="__codelineno-8-10" href="#__codelineno-8-10"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">value</span> <span class="o">*=</span> <span class="n">mult</span>
</span></code></pre></div>
</li>
<li>
<p>对于本工作中研究的 <code>sentiment</code> 和 <code>descriptiveness</code> 任务，我们使用了 <code>init_kl_coef=0.15, hparams.target=6, hparams.horizon=10000</code> 。</p>
</li>
</ul>
</li>
</ol>
<h2 id="pytorch-adam-rlhf"><strong>PyTorch Adam 优化器与 RLHF 相关的数值问题</strong><a class="headerlink" href="#pytorch-adam-rlhf" title="Permanent link">&para;</a></h2>
<ul>
<li>这个实现细节非常有趣，值得专门一节来讨论。</li>
<li>
<p>PyTorch 的 Adam 优化器 (<a href="https://pytorch.org/docs/stable/generated/torch.optim.Adam.html">torch.optim.Adam.html</a>) 与 TensorFlow 的 Adam 优化器 (TF1 Adam 在 <a href="https://github.com/tensorflow/tensorflow/blob/v1.15.2/tensorflow/python/training/adam.py">tensorflow/v1.15.2/adam.py</a>，TF2 Adam 在 <a href="https://github.com/keras-team/keras/blob/v2.13.1/keras/optimizers/adam.py#L26-L220">keras/adam.py#L26-L220</a>) 有不同的实现方式。具体来说， <strong>PyTorch 遵循了 Kingma 和 Ba 的 Adam 论文中的算法 1</strong> (<a href="https://arxiv.org/pdf/1412.6980.pdf">arxiv/1412.6980</a>)，而 <strong>TensorFlow 使用了该论文第 2.1 节前的公式</strong>，这里提到的 <code>epsilon</code> 在论文中称为 <code>epsilon hat</code> 。在伪代码比较中，我们有以下内容:</p>
<div class="language-python highlight"><pre><span></span><code><span id="__span-9-1"><a id="__codelineno-9-1" name="__codelineno-9-1" href="#__codelineno-9-1"></a><span class="c1">### pytorch adam implementation:</span>
</span><span id="__span-9-2"><a id="__codelineno-9-2" name="__codelineno-9-2" href="#__codelineno-9-2"></a><span class="n">bias_correction1</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span> <span class="o">**</span> <span class="n">step</span>
</span><span id="__span-9-3"><a id="__codelineno-9-3" name="__codelineno-9-3" href="#__codelineno-9-3"></a><span class="n">bias_correction2</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span> <span class="o">**</span> <span class="n">step</span>
</span><span id="__span-9-4"><a id="__codelineno-9-4" name="__codelineno-9-4" href="#__codelineno-9-4"></a><span class="n">step_size</span> <span class="o">=</span> <span class="n">lr</span> <span class="o">/</span> <span class="n">bias_correction1</span>
</span><span id="__span-9-5"><a id="__codelineno-9-5" name="__codelineno-9-5" href="#__codelineno-9-5"></a><span class="n">bias_correction2_sqrt</span> <span class="o">=</span> <span class="n">_dispatch_sqrt</span><span class="p">(</span><span class="n">bias_correction2</span><span class="p">)</span>
</span><span id="__span-9-6"><a id="__codelineno-9-6" name="__codelineno-9-6" href="#__codelineno-9-6"></a><span class="n">denom</span> <span class="o">=</span> <span class="p">(</span><span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span> <span class="o">/</span> <span class="n">bias_correction2_sqrt</span><span class="p">)</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">eps</span><span class="p">)</span>
</span><span id="__span-9-7"><a id="__codelineno-9-7" name="__codelineno-9-7" href="#__codelineno-9-7"></a><span class="n">param</span><span class="o">.</span><span class="n">addcdiv_</span><span class="p">(</span><span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="n">step_size</span><span class="p">)</span>
</span><span id="__span-9-8"><a id="__codelineno-9-8" name="__codelineno-9-8" href="#__codelineno-9-8"></a>
</span><span id="__span-9-9"><a id="__codelineno-9-9" name="__codelineno-9-9" href="#__codelineno-9-9"></a><span class="c1">### tensorflow adam implementation:</span>
</span><span id="__span-9-10"><a id="__codelineno-9-10" name="__codelineno-9-10" href="#__codelineno-9-10"></a><span class="n">lr_t</span> <span class="o">=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">_dispatch_sqrt</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta2</span> <span class="o">**</span> <span class="n">step</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">beta1</span> <span class="o">**</span> <span class="n">step</span><span class="p">)</span>
</span><span id="__span-9-11"><a id="__codelineno-9-11" name="__codelineno-9-11" href="#__codelineno-9-11"></a><span class="n">denom</span> <span class="o">=</span> <span class="n">exp_avg_sq</span><span class="o">.</span><span class="n">sqrt</span><span class="p">()</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">eps</span><span class="p">)</span>
</span><span id="__span-9-12"><a id="__codelineno-9-12" name="__codelineno-9-12" href="#__codelineno-9-12"></a><span class="n">param</span><span class="o">.</span><span class="n">addcdiv_</span><span class="p">(</span><span class="n">exp_avg</span><span class="p">,</span> <span class="n">denom</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="n">lr_t</span><span class="p">)</span>
</span></code></pre></div>
</li>
<li>
<p>让我们比较一下 PyTorch 风格和 TensorFlow 风格 Adam 的更新方程。按照 Adam 论文 <a href="https://arxiv.org/abs/1412.6980">(Kingma 和 Ba，2014)</a> 的符号表示，我们可以得到 PyTorch Adam (Kingma 和 Ba 论文的算法 1) 和 TensorFlow 风格 Adam (Kingma 和 Ba 论文第 2.1 节前的公式) 的梯度更新规则如下:</p>
<div class="arithmatex">\[\begin{aligned}\text{pytorch adam :}\quad \theta_t &amp; =\theta_{t-1}-\alpha \cdot \hat{m} _t /\left(\sqrt{\hat{v} _t}+\varepsilon\right) \&amp; =\theta_ {t-1}- \alpha \underbrace{\left[m_t /\left(1-\beta_1^t\right)\right]}_ {=\hat{m} _t} /\left[\sqrt{\underbrace{v_t /\left(1-\beta_2^t\right)}_ {=\hat{v} _t} }+\varepsilon\right]\&amp; =\theta_ {t-1}- \alpha\left[m_t /\left(1-\beta_1^t\right)\right]\frac{\sqrt{1-\beta_2^t}}{\sqrt{v_t}+\color{green}{\varepsilon \sqrt{1-\beta_2^t}}}\end{aligned}\]</div>
<div class="arithmatex">\[\begin{aligned}\text{tensorflow adam:}\quad \theta_t &amp; =\theta_{t-1}-\alpha_t m_t /\left(\sqrt{v_t}+\hat{\varepsilon}\right) \&amp; =\theta_{t-1}-\underbrace{\left[\alpha \sqrt{1-\beta_2^t} /\left(1-\beta_1^t\right)\right]} _{=\alpha_t} m_t /\left(\sqrt{v_t}+\hat{\varepsilon}\right) \&amp; =\theta_ {t-1}- \alpha\left[m_t /\left(1-\beta_1^t\right)\right] \frac{\sqrt{1-\beta_2^t}}{\sqrt{v_t}+\color{green}{\hat{\varepsilon}}} \end{aligned}\]</div>
</li>
<li>
<p>上面的方程强调了 PyTorch 和 TensorFlow 实现之间的区别在于它们的 <strong>归一化项</strong>，即 <span class="arithmatex">\(\color{green}{\varepsilon \sqrt{1-\beta_2^t}}\)</span> 和  <span class="arithmatex">\(\color{green}{\hat{\varepsilon}}\)</span>。如果我们设置 <span class="arithmatex">\(\hat{\varepsilon} = \varepsilon \sqrt{1-\beta_2^t}\)</span>，则这两个版本是等价的。然而，在 PyTorch 和 TensorFlow 的 API 中，我们只能通过 <code>eps</code> 参数设置 <span class="arithmatex">\(\varepsilon\)</span> (PyTorch) 和  <span class="arithmatex">\(\hat{\varepsilon}\)</span> (TensorFlow)，从而导致它们的更新方程存在差异。如果我们将 <span class="arithmatex">\(\varepsilon\)</span> 和  <span class="arithmatex">\(\hat{\varepsilon}\)</span> 都设置为相同的值，比如 1e-5 会发生什么？那么对于 TensorFlow Adam，归一化项 <span class="arithmatex">\(\hat{\varepsilon} = \text{1e-5}\)</span> 就是一个常数。但对于 PyTorch Adam，归一化项 <span class="arithmatex">\({\varepsilon \sqrt{1-\beta_2^t}}\)</span> 随着时间的推移而变化。重要的是，当时间步 <span class="arithmatex">\(t\)</span> 较小时，该项 <span class="arithmatex">\({\varepsilon \sqrt{1-\beta_2^t}}\)</span> 明显小于 1e-5，随着时间步增加，逐渐接近 1e-5。下面的图表比较了这两个归一化项随着时间步的变化情况:</p>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/norma_const_comparison.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="norma_const_comparison.png" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/norma_const_comparison.png" /></a></p>
</li>
<li>
<p>上图显示，如果我们在 PyTorch Adam 和 TensorFlow Adam 中设置相同的 <code>eps</code> ，那么在训练的早期阶段，PyTorch Adam 使用的归一化项要比 TensorFlow Adam 小得多。换句话说，PyTorch Adam 在训练的早期采用了 <strong>更激进的梯度更新</strong>。我们的实验证明了这一发现，如下所示。</p>
</li>
<li>
<p>这对复现性和性能有何影响？为了保持设置一致，我们记录了来自 <a href="https://github.com/openai/lm-human-preferences">https://github.com/openai/lm-human-preferences</a> 的原始查询、响应和奖励，并将它们保存在 <a href="https://huggingface.co/datasets/vwxyzjn/lm-human-preferences-debug/tree/main">https://huggingface.co/datasets/vwxyzjn/lm-human-preferences-debug/tree/main</a> 中。我还记录了使用 TF1 的 <code>AdamOptimizer</code> 优化器的前两个训练周期的指标作为基准。以下是一些关键指标:</p>
<table>
<thead>
<tr>
<th></th>
<th>OAI 的 TF1 Adam</th>
<th>PyTorch 的 Adam</th>
<th>我们自定义的类似 TensorFlow 风格的 Adam</th>
</tr>
</thead>
<tbody>
<tr>
<td>policy/approxkl</td>
<td>0.00037167023</td>
<td>0.0023672834504395723</td>
<td>0.000374998344341293</td>
</tr>
<tr>
<td>policy/clipfrac</td>
<td>0.0045572915</td>
<td>0.02018229104578495</td>
<td>0.0052083334885537624</td>
</tr>
<tr>
<td>ratio_mean</td>
<td>1.0051285</td>
<td>1.0105520486831665</td>
<td>1.0044583082199097</td>
</tr>
<tr>
<td>ratio_var</td>
<td>0.0007716546</td>
<td>0.005374275613576174</td>
<td>0.0007942612282931805</td>
</tr>
<tr>
<td>ratio_max</td>
<td>1.227216</td>
<td>1.8121057748794556</td>
<td>1.250215768814087</td>
</tr>
<tr>
<td>ratio_min</td>
<td>0.7400441</td>
<td>0.4011387825012207</td>
<td>0.7299948930740356</td>
</tr>
<tr>
<td>logprob_diff_mean</td>
<td>0.0047487603</td>
<td>0.008101251907646656</td>
<td>0.004073789343237877</td>
</tr>
<tr>
<td>logprob_diff_var</td>
<td>0.0007207897</td>
<td>0.004668936599045992</td>
<td>0.0007334011606872082</td>
</tr>
<tr>
<td>logprob_diff_max</td>
<td>0.20474821</td>
<td>0.594489574432373</td>
<td>0.22331619262695312</td>
</tr>
<tr>
<td>logprob_diff_min</td>
<td>-0.30104542</td>
<td>-0.9134478569030762</td>
<td>-0.31471776962280273</td>
</tr>
</tbody>
</table>
</li>
<li>
<p>由于某种原因， <strong>PyTorch 的 Adam 生成了更激进的更新</strong>。以下是一些证据:</p>
<ul>
<li><strong>PyTorch 的 Adam 的 logprob_diff_var 高出 6 倍</strong>。这里的 <code>logprobs_diff = new_logprobs - logprobs</code> 是经过两个训练周期后，初始策略和当前策略之间的标记对数概率差异。具有更大的 <code>logprob_diff_var</code> 意味着对数概率变化的幅度比 OAI 的 TF1 Adam 大。</li>
<li><strong>PyTorch 的 Adam 呈现更极端的最大和最小比率</strong>。这里的 <code>ratio = torch.exp(logprobs_diff)</code> 。具有 <code>ratio_max=1.8121057748794556</code> 意味着对于某些标记，在当前策略下抽取该标记的概率要比 OAI 的 TF1 Adam 高 1.8 倍，而后者仅为 1.2 倍。</li>
<li><strong>更大的 <code>policy/approxkl</code> 和 <code>policy/clipfrac</code></strong>。由于激进的更新，比率被剪切的次数 <strong>多 4.4 倍，近似的 KL 散度大 6 倍</strong>。</li>
<li>这种激进的更新可能会导致进一步的问题。例如，PyTorch 的 <code>Adam</code> 中的<code>logprob_diff_mean</code> 要大 1.7 倍，这将对下一个奖励计算中的 KL 惩罚产生 1.7 倍大的影响; 这可能会被累积。实际上，这可能与著名的 KL 散度问题有关—— KL 惩罚远大于它应该的值，模型可能会更多地关注它并进行更多优化，从而导致负的 KL 散度。</li>
</ul>
</li>
<li>
<p><strong>更大的模型受到更多影响</strong>。我们进行了一些实验，比较了 PyTorch 的 <code>Adam</code> (代号 <code>pt_adam</code> ) 和我们自定义的类似 TensorFlow 风格的 Adam (代号 <code>tf_adam</code> ) 在 <code>gpt2</code> 和 <code>gpt2-xl</code> 上的性能。我们发现在 <code>gpt2</code> 下性能大致相似; 但是在 <code>gpt2-xl</code> 下，我们观察到了更激进的更新，这意味着更大的模型受到了更多的影响。</p>
<ul>
<li>当在 <code>gpt2-xl</code> 中初始策略更新更为激进时，训练动态会受到影响。例如，我们发现使用 <code>pt_adam</code> 时，<code>sentiment</code> 的 <code>objective/kl</code> 和 <code>objective/scores</code> 峰值要大得多， <em>在其中一个随机种子中，最大的 KL 值达到了 17.5</em> ，这表明了不希望的过度优化。</li>
<li>此外，由于 KL 更大，许多其他训练指标也受到影响。例如，我们观察到更大的 <code>clipfrac</code> (<code>ratio</code> 被 PPO 的目标裁剪系数 0.2 裁剪的时间比例) 和 <code>approxkl</code> 。</li>
</ul>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/adam_gpt2.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="adam_gpt2.png" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/adam_gpt2.png" /></a></p>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/adam_gpt2_xl.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="adam_gpt2_xl.png" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/adam_gpt2_xl.png" /></a></p>
</li>
</ul>
<h1 id="_5">局限性<a class="headerlink" href="#_5" title="Permanent link">&para;</a></h1>
<p>注意到这项工作没有尝试复现 CNN DM 中的摘要工作。这是因为我们发现训练耗时且不稳定。</p>
<p>我们的特定训练运行显示 GPU 利用率较低 (约 30%)，因此一个训练运行需要近 4 天的时间，这非常昂贵 (只有 AWS 销售 p3dn.24xlarge，每小时费用为 31.212 美元)。</p>
<p>此外，训练也很不稳定。虽然奖励值上升，但我们发现难以复现 Ziegler 等人 (2019 年) 报告的“智能复制”行为。以下是一些样本输出 — 显然，智能体出现了某种程度的过拟合。请查看 <a href="https://wandb.ai/openrlbenchmark/lm-human-preferences/runs/1ab47rqi/logs?workspace=user-costa-huang">https://wandb.ai/openrlbenchmark/lm-human-preferences/runs/1ab47rqi/logs</a> 以获取更完整的日志。</p>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/tldr1.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="tldr1.png" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/tldr1.png" /></a></p>
<p><a class="glightbox" href="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/tldr2.png" data-type="image" data-width="auto" data-height="auto" data-desc-position="bottom"><img alt="tldr2.png" src="https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/rlhf_implementation_details/tldr2.png" /></a></p>
<h1 id="_6">总结<a class="headerlink" href="#_6" title="Permanent link">&para;</a></h1>
<p>在这项工作中，我们深入研究了 OpenAI 的原始 RLHF (Reinforcement Learning from Human Feedback) 代码库，并编制了其实施细节的列表。我们还创建了一个最小的基础版本，当数据集和超参数受控制时，可以复现与 OpenAI 原始 RLHF 代码库相同的学习曲线。此外，我们还识别了一些令人惊讶的实施细节，比如 Adam 优化器的设置，它会导致在 RLHF 训练的早期出现激进的更新。</p>
<h1 id="_7">致谢<a class="headerlink" href="#_7" title="Permanent link">&para;</a></h1>
<p>这项工作得到了 Hugging Face 的 Big Science 集群的支持 🤗。我们还感谢 @lewtun 和 @natolambert 的建设性讨论。</p>
<h1 id="bibtex">Bibtex<a class="headerlink" href="#bibtex" title="Permanent link">&para;</a></h1>
<div class="language-bibtex highlight"><pre><span></span><code><span id="__span-10-1"><a id="__codelineno-10-1" name="__codelineno-10-1" href="#__codelineno-10-1"></a><span class="nc">@article</span><span class="p">{</span><span class="nl">Huang2023implementation</span><span class="p">,</span>
</span><span id="__span-10-2"><a id="__codelineno-10-2" name="__codelineno-10-2" href="#__codelineno-10-2"></a><span class="w">  </span><span class="na">author</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Huang, Shengyi and Liu, Tianlin and von Werra, Leandro}</span><span class="p">,</span>
</span><span id="__span-10-3"><a id="__codelineno-10-3" name="__codelineno-10-3" href="#__codelineno-10-3"></a><span class="w">  </span><span class="na">title</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{The N Implementation Details of RLHF with PPO}</span><span class="p">,</span>
</span><span id="__span-10-4"><a id="__codelineno-10-4" name="__codelineno-10-4" href="#__codelineno-10-4"></a><span class="w">  </span><span class="na">journal</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{Hugging Face Blog}</span><span class="p">,</span>
</span><span id="__span-10-5"><a id="__codelineno-10-5" name="__codelineno-10-5" href="#__codelineno-10-5"></a><span class="w">  </span><span class="na">year</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{2023}</span><span class="p">,</span>
</span><span id="__span-10-6"><a id="__codelineno-10-6" name="__codelineno-10-6" href="#__codelineno-10-6"></a><span class="w">  </span><span class="na">note</span><span class="w"> </span><span class="p">=</span><span class="w"> </span><span class="s">{https://huggingface.co/blog/the_n_implementation_details_of_rlhf_with_ppo}</span><span class="p">,</span>
</span><span id="__span-10-7"><a id="__codelineno-10-7" name="__codelineno-10-7" href="#__codelineno-10-7"></a><span class="p">}</span>
</span></code></pre></div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 5.5A3.5 3.5 0 0 1 15.5 9a3.5 3.5 0 0 1-3.5 3.5A3.5 3.5 0 0 1 8.5 9 3.5 3.5 0 0 1 12 5.5M5 8c.56 0 1.08.15 1.53.42-.15 1.43.27 2.85 1.13 3.96C7.16 13.34 6.16 14 5 14a3 3 0 0 1-3-3 3 3 0 0 1 3-3m14 0a3 3 0 0 1 3 3 3 3 0 0 1-3 3c-1.16 0-2.16-.66-2.66-1.62a5.54 5.54 0 0 0 1.13-3.96c.45-.27.97-.42 1.53-.42M5.5 18.25c0-2.07 2.91-3.75 6.5-3.75s6.5 1.68 6.5 3.75V20h-13zM0 20v-1.5c0-1.39 1.89-2.56 4.45-2.9-.59.68-.95 1.62-.95 2.65V20zm24 0h-3.5v-1.75c0-1.03-.36-1.97-.95-2.65 2.56.34 4.45 1.51 4.45 2.9z"/></svg>
      
    </span>
    <nav>
      
    </nav>
  </span>

    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              Thanks for your feedback! Help us improve this page by using our <a href="..." target="_blank" rel="noopener">feedback form</a>.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../the-age-of-ml-as-code/" class="md-footer__link md-footer__link--prev" aria-label="Previous: 机器学习即代码的时代已经到来">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256l137.3-137.4c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                机器学习即代码的时代已经到来
              </div>
            </div>
          </a>
        
        
          
          <a href="../time-series-transformers/" class="md-footer__link md-footer__link--next" aria-label="Next: 使用 🤗 Transformers 进行概率时间序列预测">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                使用 🤗 Transformers 进行概率时间序列预测
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2020 - 2024 FastX-AI
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
    
    
    
    <a href="https://fastx-ai.com" target="_blank" rel="noopener me" title="fastx-ai" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.5 102.5 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5m-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
    </a>
  
    
    
    
    
    <a href="mailto:x.stark.dylan@gmail.com" target="_blank" rel="noopener" title="send me an email" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.7.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M64 112c-8.8 0-16 7.2-16 16v22.1l172.5 141.6c20.7 17 50.4 17 71.1 0L464 150.1V128c0-8.8-7.2-16-16-16zM48 212.2V384c0 8.8 7.2 16 16 16h384c8.8 0 16-7.2 16-16V212.2L322 328.8c-38.4 31.5-93.7 31.5-132 0zM0 128c0-35.3 28.7-64 64-64h384c35.3 0 64 28.7 64 64v256c0 35.3-28.7 64-64 64H64c-35.3 0-64-28.7-64-64z"/></svg>
    </a>
  
    
    
    
    
    <a href="/contact" target="_blank" rel="noopener" title="contact us" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 4H7a5 5 0 0 0-5 5v11h18a2 2 0 0 0 2-2V9a5 5 0 0 0-5-5m-7 14H4V9a3 3 0 0 1 3-3 3 3 0 0 1 3 3zm9-3h-2v-2h-4v-2h6zM9 11H5V9h4z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
    <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.indexes", "navigation.instant.progress", "navigation.tracking", "navigation.tabs", "navigation.top", "navigation.footer", "navigation.prune", "content.action.edit", "content.code.copy", "content.code.annotate", "content.tabs.link", "content.tooltips", "header.autohide", "announce.dismiss", "search.suggest", "search.highlight", "search.share", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
<!-- Add scripts that need to run before here -->

      <script src="../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
        <script src="../../javascripts/extra.js"></script>
      
        <script src="../../javascripts/mathjax.js"></script>
      
        <script src="https://unpkg.com/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
<!-- Add scripts that need to run afterwards here -->

  <script id="init-glightbox">const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(() => { lightbox.reload() });
</script></body>
</html>